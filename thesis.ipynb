{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Xi9z2tGsLgV_OMGB36wWYdspsBzsG8Sb","authorship_tag":"ABX9TyPua6D/VG55KQLJKEi/Yp89"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":69587,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":58064},{"sourceId":69588,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":58065}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook contains the empirical study regarding the attention mechanism.","metadata":{}},{"cell_type":"markdown","source":"______________\n# FINAL STEPS:\n* Train networks on MNIST for X epochs\n* Train networks for augmented MNIST for X epochs\n* Ablation Study (VAN without LKA)\n* Compare Computational Costs (Deepspeed Profiler?)\n - Training time\n - Number of Modules\n - Number of parameters\n - FLOPs\n ","metadata":{}},{"cell_type":"markdown","source":"# Relevant information about the training run\n\n- OS: Linux-5.15.133+-x86_64-with-glibc2.31\n- GPU: Tesla P100-PCIE-16GB\n- PyTorch: 2.1.2\n- CUDA: 12.1\n- cudnn: 8900\n- Python Version: 3.10.13","metadata":{}},{"cell_type":"markdown","source":"# Relevant information about the external package versions\n- matplotlib==3.7.5\n- numpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\n- torch @ file:///tmp/torch/torch-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=ae3259980b8d6551608b32fde2695baca64c72ed15ab2332023a248c113815a8\n- torchvision @ file:///tmp/torch/torchvision-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=105901a20924f652ee62df0bb57580c67725eb21f11a349658952c4be2050d94\n","metadata":{}},{"cell_type":"code","source":"# Installation and import of relevant packages\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nimport platform\nimport random\nimport time\nimport torch\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import v2\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.profiler import profile, record_function, ProfilerActivity","metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1711009733593,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"hj481hNsaSLk","execution":{"iopub.status.busy":"2024-06-26T15:40:21.669700Z","iopub.execute_input":"2024-06-26T15:40:21.670421Z","iopub.status.idle":"2024-06-26T15:40:21.677061Z","shell.execute_reply.started":"2024-06-26T15:40:21.670383Z","shell.execute_reply":"2024-06-26T15:40:21.675914Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Get information about current runtime and package versions.\n\n# Check if CUDA is available\ncuda_available = torch.cuda.is_available()\n\n# Get CUDA device count\ncuda_device_count = torch.cuda.device_count() if cuda_available else 0\n\n# Get current CUDA device index\ncuda_device_index = torch.cuda.current_device() if cuda_available else None\n\n# Get name of current CUDA device\ncuda_device_name = torch.cuda.get_device_name(cuda_device_index) if cuda_available else None\n\n# Get CUDA capability of the device\ncuda_capability = torch.cuda.get_device_capability(cuda_device_index) if cuda_available else None\n\n# Get CUDA version\ncuda_version = torch.version.cuda if cuda_available else None\n\n# Get cuDNN version\ncudnn_version = torch.backends.cudnn.version() if cuda_available else None\n\n# Get PyTorch version\npytorch_version = torch.__version__\n\n# Get OS information\nos_info = platform.platform()\n\npython_version = platform.python_version()\n\n# Print the information\nenvironment_dict = {\"OS:\", os_info,\n                    \"GPU:\", cuda_device_name,\n                    \"PyTorch:\", pytorch_version,\n                    \"CUDA:\", cuda_version,\n                    \"cudnn:\", cudnn_version,\n                    \"Python Version:\", python_version\n                   }\nprint(\"OS:\", os_info)\nprint(\"GPU:\", cuda_device_name)\nprint(\"PyTorch:\", pytorch_version)\nprint(\"CUDA:\", cuda_version)\nprint(\"cudnn:\", cudnn_version)\nprint(\"Python Version:\", python_version)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:40:23.381654Z","iopub.execute_input":"2024-06-26T15:40:23.382034Z","iopub.status.idle":"2024-06-26T15:40:23.392536Z","shell.execute_reply.started":"2024-06-26T15:40:23.382004Z","shell.execute_reply":"2024-06-26T15:40:23.391516Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"OS: Linux-5.15.133+-x86_64-with-glibc2.31\nGPU: Tesla P100-PCIE-16GB\nPyTorch: 2.1.2\nCUDA: 12.1\ncudnn: 8900\nPython Version: 3.10.13\n","output_type":"stream"}]},{"cell_type":"code","source":"# List package versions\n!pip freeze","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:40:24.759974Z","iopub.execute_input":"2024-06-26T15:40:24.760363Z","iopub.status.idle":"2024-06-26T15:40:27.261230Z","shell.execute_reply.started":"2024-06-26T15:40:24.760331Z","shell.execute_reply":"2024-06-26T15:40:27.260115Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"absl-py==1.4.0\naccelerate==0.27.2\naccess==1.1.9\naffine==2.4.0\naiobotocore==2.11.2\naiofiles==22.1.0\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1701099469104/work\naiohttp-cors==0.7.0\naioitertools==0.11.0\naiorwlock==1.3.0\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1667935791922/work\naiosqlite==0.19.0\nalbumentations==1.4.0\nalembic==1.13.1\naltair==5.2.0\nannotated-types @ file:///home/conda/feedstock_root/build_artifacts/annotated-types_1696634205638/work\nannoy==1.17.3\nanyio @ file:///home/conda/feedstock_root/build_artifacts/anyio_1702909220329/work\napache-beam==2.46.0\naplus==0.11.0\nappdirs==1.4.4\narchspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386546427/work\narray-record==0.5.0\narrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\narviz==0.17.0\nastroid==3.0.3\nastropy==6.0.0\nastropy-iers-data==0.2024.2.19.0.28.47\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\nastunparse==1.6.3\nasync-lru==2.0.4\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1691763562544/work\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1704011227531/work\naudioread==3.0.1\nautopep8==2.0.4\nBabel==2.14.0\nbackoff==2.2.1\nbayesian-optimization==1.4.3\nbayespy==0.5.28\nbeatrix_jupyterlab @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-gpu_1704941576253/work/packages/beatrix_jupyterlab-2023.128.151533.tar.gz#sha256=8c6941d08ce18f5b9ea7719574d611c18163074ff8254e0734342014eb064a48\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1680888073205/work\nbidict==0.23.1\nbiopython==1.83\nblake3==0.2.1\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\nblessed==1.20.0\nblinker==1.7.0\nblis @ file:///home/conda/feedstock_root/build_artifacts/cython-blis_1696148805003/work\nblosc2==2.5.1\nbokeh @ file:///home/conda/feedstock_root/build_artifacts/bokeh_1706215790147/work\nboltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\nBoruta==0.3\nboto3==1.26.100\nbotocore==1.34.34\nbq_helper==0.4.1\nbqplot==0.12.43\nbranca==0.7.1\nbrewer2mpl==1.4.1\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work\nbrotlipy==0.7.0\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\ncachetools==4.2.4\nCartopy @ file:///home/conda/feedstock_root/build_artifacts/cartopy_1698172724393/work\ncatalogue @ file:///home/conda/feedstock_root/build_artifacts/catalogue_1695626339626/work\ncatalyst @ git+https://github.com/Philmod/catalyst.git@9420384a98c4b9d3b17b959e66f845b98457b545\ncatboost==1.2.2\ncategory-encoders==2.6.3\ncertifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1707022139797/work/certifi\ncesium==0.12.1\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\nchex==0.1.85\ncleverhans==4.0.0\nclick @ file:///home/conda/feedstock_root/build_artifacts/click_1692311806742/work\nclick-plugins==1.1.1\ncligj==0.7.2\ncloud-tpu-client==0.10\ncloud-tpu-profiler==2.4.0\ncloudpathlib @ file:///home/conda/feedstock_root/build_artifacts/cloudpathlib-meta_1697837790453/work\ncloudpickle==2.2.1\ncmdstanpy==1.2.1\ncmudict==1.0.18\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\ncolorcet==3.0.1\ncolorful==0.5.6\ncolorlog==6.8.2\ncolorlover==0.3.0\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1704278392174/work\nconda @ file:///home/conda/feedstock_root/build_artifacts/conda_1694556045812/work\nconda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1690880668143/work/src\nconda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\nconda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\nconfection @ file:///home/conda/feedstock_root/build_artifacts/confection_1701179074719/work\ncontextily==1.5.0\ncontourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1699041363598/work\nconvertdate==2.4.0\ncrcmod==1.7\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1701563205069/work\ncuda-python @ file:///opt/conda/conda-bld/cuda-python_1696638333144/work\ncudf @ file:///opt/conda/conda-bld/work/python/cudf\ncufflinks==0.17.3\ncuml @ file:///opt/conda/conda-bld/work/python\ncupy @ file:///home/conda/feedstock_root/build_artifacts/cupy-split_1707093121318/work\nCVXcanon==0.1.2\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\ncymem @ file:///home/conda/feedstock_root/build_artifacts/cymem_1695443485440/work\ncysignals==1.11.4\nCython==3.0.8\ncytoolz @ file:///home/conda/feedstock_root/build_artifacts/cytoolz_1706897049115/work\ndaal==2024.1.0\ndaal4py==2024.1.0\ndacite==1.8.1\ndask==2024.2.0\ndask-cuda @ file:///opt/conda/conda-bld/work\ndask-cudf @ file:///opt/conda/conda-bld/work/python/dask_cudf\ndataclasses-json==0.6.4\ndataproc_jupyter_plugin==0.1.66\ndatasets==2.1.0\ndatashader==0.16.0\ndatatile==1.0.3\ndb-dtypes==1.2.0\ndeap==1.4.1\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1695534290310/work\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\ndeepdiff==6.7.1\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\nDelorean==1.0.0\nDeprecated==1.2.14\ndeprecation==2.1.0\ndescartes==1.1.0\ndill==0.3.8\ndipy==1.8.0\ndistlib==0.3.8\ndistributed @ file:///home/conda/feedstock_root/build_artifacts/distributed_1689891044039/work\ndistro @ file:///home/conda/feedstock_root/build_artifacts/distro_1704321475663/work\ndm-tree==0.1.8\ndocker==7.0.0\ndocker-pycreds==0.4.0\ndocopt==0.6.2\ndocstring-parser==0.15\ndocstring-to-markdown==0.15\ndocutils==0.20.1\nearthengine-api==0.1.391\neasydict==1.12\neasyocr==1.7.1\necos==2.0.13\neli5==0.13.0\nemoji==2.10.1\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl#sha256=ab70aeb6172cde82508f7739f35ebc9918a3d07debeed637403c8f794ba3d3dc\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\nephem==4.1.5\nesda==2.5.1\nessentia==2.1b6.dev1110\net-xmlfile==1.1.0\netils==1.6.0\nexceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\nexplainable-ai-sdk==1.3.3\nFarama-Notifications==0.0.4\nfastai==2.7.14\nfastapi==0.108.0\nfastavro==1.9.3\nfastcore==1.5.29\nfastdownload==0.0.7\nfasteners==0.19\nfastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1703780968325/work/dist\nfastprogress==1.0.3\nfastrlock @ file:///home/conda/feedstock_root/build_artifacts/fastrlock_1702696298817/work\nfasttext==0.9.2\nfbpca==1.0\nfeather-format==0.4.1\nfeaturetools==1.29.0\nfilelock==3.13.1\nfiona==1.9.5\nfitter==1.7.0\nflake8==7.0.0\nflashtext==2.7\nFlask==3.0.2\nflatbuffers==23.5.26\nflax==0.8.1\nfolium==0.15.1\nfonttools==4.47.0\nfqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\nfrozendict==2.4.0\nfrozenlist @ file:///home/conda/feedstock_root/build_artifacts/frozenlist_1702645481127/work\nfsspec @ file:///home/conda/feedstock_root/build_artifacts/fsspec_1707102468451/work\nfuncy==2.0\nfury==0.9.0\nfuture==1.0.0\nfuzzywuzzy==0.18.0\ngast==0.5.4\ngatspy==0.3\ngcsfs==2023.12.2.post1\ngensim==4.3.2\ngeographiclib==2.0\nGeohash==1.0\ngeojson==3.1.0\ngeopandas==0.14.3\ngeoplot==0.5.1\ngeopy==2.4.1\ngeoviews==1.11.1\nggplot @ https://github.com/hbasria/ggpy/archive/0.11.5.zip#sha256=7df947ba3fd86d3757686afec264785ad8df38dc50ffb2d2d31064fb355f69b1\ngiddy==2.3.5\ngitdb==4.0.11\nGitPython==3.1.41\ngoogle-ai-generativelanguage==0.4.0\ngoogle-api-core==2.11.1\ngoogle-api-python-client==2.118.0\ngoogle-apitools==0.5.31\ngoogle-auth==2.26.1\ngoogle-auth-httplib2==0.1.1\ngoogle-auth-oauthlib==1.2.0\ngoogle-cloud-aiplatform==0.6.0a1\ngoogle-cloud-artifact-registry==1.10.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==2.34.4\ngoogle-cloud-bigtable==1.7.3\ngoogle-cloud-core==2.4.1\ngoogle-cloud-datastore==2.19.0\ngoogle-cloud-dlp==3.14.0\ngoogle-cloud-jupyter-config==0.0.5\ngoogle-cloud-language==2.13.1\ngoogle-cloud-monitoring==2.18.0\ngoogle-cloud-pubsub==2.19.0\ngoogle-cloud-pubsublite==1.9.0\ngoogle-cloud-recommendations-ai==0.7.1\ngoogle-cloud-resource-manager==1.11.0\ngoogle-cloud-spanner==3.40.1\ngoogle-cloud-storage==1.44.0\ngoogle-cloud-translate==3.12.1\ngoogle-cloud-videointelligence==2.13.1\ngoogle-cloud-vision==2.8.0\ngoogle-crc32c==1.5.0\ngoogle-generativeai==0.3.2\ngoogle-pasta==0.2.0\ngoogle-resumable-media==2.7.0\ngoogleapis-common-protos==1.62.0\ngplearn==0.4.2\ngpustat==1.0.0\ngpxpy==1.6.2\ngraphviz==0.20.1\ngreenlet==3.0.3\ngrpc-google-iam-v1==0.12.7\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpc-split_1677499296072/work\ngrpcio-status @ file:///home/conda/feedstock_root/build_artifacts/grpcio-status_1662108958711/work\ngviz-api==1.10.0\ngym==0.26.2\ngym-notices==0.0.8\ngymnasium==0.29.0\nh11==0.14.0\nh2o==3.44.0.3\nh5netcdf==1.3.0\nh5py==3.10.0\nhaversine==2.8.1\nhdfs==2.7.3\nhep-ml==0.7.2\nhijri-converter==2.3.1\nhmmlearn==0.3.0\nholidays==0.24\nholoviews==1.18.3\nhpsklearn==0.1.0\nhtml5lib==1.1\nhtmlmin==0.1.12\nhttpcore==1.0.4\nhttplib2==0.21.0\nhttptools==0.6.1\nhttpx==0.27.0\nhuggingface-hub==0.20.3\nhumanize==4.9.0\nhunspell==0.5.5\nhusl==4.0.3\nhydra-slayer==0.5.0\nhyperopt==0.2.7\nhypertools==0.8.0\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1701026962277/work\nigraph==0.11.4\nimagecodecs==2024.1.1\nImageHash==4.3.1\nimageio==2.33.1\nimbalanced-learn==0.12.0\nimgaug==0.4.0\nimportlib-metadata==6.11.0\nimportlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1699364556997/work\ninequality==1.0.1\niniconfig==2.0.0\nipydatawidgets==4.3.5\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1703631723894/work\nipyleaflet==0.18.2\nipympl==0.7.0\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1704718870316/work\nipython-genutils==0.2.0\nipython-sql==0.5.0\nipyvolume==0.6.3\nipyvue==1.10.1\nipyvuetify==1.8.10\nipywebrtc==0.6.0\nipywidgets==7.7.1\nisoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\nisort==5.13.2\nisoweek==1.3.3\nitsdangerous==2.1.2\nJanome==0.5.0\njaraco.classes==3.3.0\njax==0.4.23\njax-jumpy==1.0.0\njaxlib @ file:///tmp/jax/jaxlib-0.4.23.dev20240116-cp310-cp310-manylinux2014_x86_64.whl#sha256=2adde6b0fff8a64af0b461e617ac514b80d8ee4aa52f1b1cf9a9139f427be8ba\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\njeepney==0.8.0\njieba==0.42.1\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1654302431367/work\njmespath==1.0.1\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1691577114857/work\njson5==0.9.14\njsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\njsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1700159890288/work\njsonschema-specifications @ file:///tmp/tmpkv1z7p57/src\njupyter-console==6.6.3\njupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1699285872613/work\njupyter-http-over-ws==0.0.8\njupyter-lsp==1.5.1\njupyter-server-mathjax==0.2.6\njupyter-ydoc==0.2.5\njupyter_client==7.4.9\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1704727030956/work\njupyter_server==2.12.5\njupyter_server_fileid==0.9.1\njupyter_server_proxy==4.1.0\njupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1703611053195/work\njupyter_server_ydoc==0.8.0\njupyterlab==4.1.2\njupyterlab-lsp==5.0.3\njupyterlab-widgets==3.0.9\njupyterlab_git==0.44.0\njupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1700744013163/work\njupyterlab_server==2.25.2\njupytext==1.16.0\nkaggle==1.6.6\nkaggle-environments==1.14.3\nkagglehub==0.1.9\nkeras==3.0.5\nkeras-cv==0.8.2\nkeras-nlp==0.8.1\nkeras-tuner==1.4.6\nkernels-mixer==0.0.7\nkeyring==24.3.0\nkeyrings.google-artifactregistry-auth==1.1.2\nkfp==2.5.0\nkfp-pipeline-spec==0.2.2\nkfp-server-api==2.0.5\nkiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379902431/work\nkmapper==2.0.1\nkmodes==0.12.2\nkorean-lunar-calendar==0.3.1\nkornia==0.7.1\nkt-legacy==1.0.5\nkubernetes==26.1.0\nlangcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1636741340529/work\nlangid==1.1.6\nlazy_loader==0.3\nlearntools @ git+https://github.com/Kaggle/learntools@183cdad0530e7c898cd4658a63b579c54e91f056\nleven==1.0.4\nLevenshtein==0.25.0\nlibclang==16.0.6\nlibmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1692866066721/work/libmambapy\nlibpysal==4.9.2\nlibrosa==0.10.1\nlightgbm @ file:///tmp/lightgbm/lightgbm-4.2.0-py3-none-manylinux_2_31_x86_64.whl#sha256=26ed21477c12bb26edc4d6d51336cd43d5a8f7daf55ebbe27b0faf50ce96db23\nlightning-utilities==0.10.1\nlime==0.2.0.1\nline-profiler==4.1.2\nlinkify-it-py==2.0.3\nllvmlite==0.41.1\nlml==0.1.0\nlocket @ file:///home/conda/feedstock_root/build_artifacts/locket_1650660393415/work\nloguru==0.7.2\nLunarCalendar==0.0.9\nlxml==5.1.0\nlz4 @ file:///home/conda/feedstock_root/build_artifacts/lz4_1704831084136/work\nMako==1.3.2\nmamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1692866066721/work/mamba\nmapclassify==2.6.1\nmarisa-trie==1.1.0\nMarkdown==3.5.2\nmarkdown-it-py @ file:///home/conda/feedstock_root/build_artifacts/markdown-it-py_1686175045316/work\nmarkovify==0.9.4\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1695367434228/work\nmarshmallow==3.20.2\nmatplotlib==3.7.5\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work\nmatplotlib-venn==0.11.10\nmccabe==0.7.0\nmdit-py-plugins==0.4.0\nmdurl @ file:///home/conda/feedstock_root/build_artifacts/mdurl_1704317613764/work\nmemory-profiler==0.61.0\nmenuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\nmercantile==1.2.1\nmgwr==2.2.1\nmissingno==0.5.2\nmistune==0.8.4\nmizani==0.11.0\nml-dtypes==0.2.0\nmlcrate==0.2.0\nmlens==0.2.3\nmlxtend==0.23.1\nmmh3==4.1.0\nmne==1.6.1\nmnist==0.2.2\nmock==5.1.0\nmomepy==0.7.0\nmore-itertools==10.2.0\nmpld3==0.5.10\nmpmath==1.3.0\nmsgpack @ file:///home/conda/feedstock_root/build_artifacts/msgpack-python_1700926504817/work\nmsgpack-numpy==0.4.8\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1696716075096/work\nmultimethod==1.10\nmultipledispatch==1.0.0\nmultiprocess==0.70.16\nmunkres==1.1.4\nmurmurhash @ file:///home/conda/feedstock_root/build_artifacts/murmurhash_1695449783955/work\nmypy-extensions==1.0.0\nnamex==0.0.7\nnb-conda-kernels @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_kernels_1699980974206/work\nnb_conda @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_1704789357480/work\nnbclassic @ file:///home/conda/feedstock_root/build_artifacts/nbclassic_1683202081046/work\nnbclient==0.5.13\nnbconvert==6.4.5\nnbdime==3.2.0\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1690814868471/work\nndindex==1.8\nnest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1697083700168/work\nnetworkx==3.2.1\nnibabel==5.2.0\nnilearn==0.10.3\nninja==1.11.1.1\nnltk==3.2.4\nnose==1.3.7\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1680870634737/work\nnotebook_executor @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-gpu_1704941576253/work/packages/notebook_executor\nnotebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1682360583588/work\nnumba==0.58.1\nnumexpr==2.9.0\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\nnvidia-ml-py==11.495.46\nnvtx @ file:///home/conda/feedstock_root/build_artifacts/nvtx_1708093799817/work\noauth2client==4.1.3\noauthlib==3.2.2\nobjsize==0.6.1\nodfpy==1.4.1\nolefile==0.47\nonnx==1.15.0\nopencensus==0.11.4\nopencensus-context==0.1.3\nopencv-contrib-python==4.9.0.80\nopencv-python==4.9.0.80\nopencv-python-headless==4.9.0.80\nopenpyxl==3.1.2\nopenslide-python==1.3.1\nopentelemetry-api==1.22.0\nopentelemetry-exporter-otlp==1.22.0\nopentelemetry-exporter-otlp-proto-common==1.22.0\nopentelemetry-exporter-otlp-proto-grpc==1.22.0\nopentelemetry-exporter-otlp-proto-http==1.22.0\nopentelemetry-proto==1.22.0\nopentelemetry-sdk==1.22.0\nopentelemetry-semantic-conventions==0.43b0\nopt-einsum==3.3.0\noptax==0.1.9\noptuna==3.5.0\norbax-checkpoint==0.5.3\nordered-set==4.1.0\norderedmultidict==1.0.1\norjson==3.9.10\nortools==9.4.1874\nosmnx==1.9.1\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1691338815398/work\npackaging==21.3\npandas==2.1.4\npandas-datareader==0.10.0\npandas-profiling==3.6.6\npandas-summary==0.2.0\npandasql==0.7.3\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\npanel==1.3.8\npapermill==2.5.0\nparam==2.0.2\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\npartd @ file:///home/conda/feedstock_root/build_artifacts/partd_1695667515973/work\npath==16.10.0\npath.py==12.5.0\npathos==0.3.2\npathy @ file:///croot/pathy_1703688110387/work\npatsy==0.5.6\npdf2image==1.17.0\npettingzoo==1.24.0\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1667297516076/work\nphik==0.12.4\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\nPillow==9.5.0\npkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\nplatformdirs==4.2.0\nplotly==5.18.0\nplotly-express==0.4.1\nplotnine==0.13.0\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\npointpats==2.4.0\npolars==0.20.10\npolyglot==16.7.4\npooch==1.8.1\npox==0.3.4\nppca==0.0.4\nppft==1.7.6.8\npreprocessing==0.1.13\npreshed @ file:///home/conda/feedstock_root/build_artifacts/preshed_1695644760607/work\nprettytable==3.9.0\nprogressbar2==4.3.2\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1700579315247/work\npromise==2.3\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1702399386289/work\npronouncing==0.2.0\nprophet==1.1.1\nproto-plus @ file:///home/conda/feedstock_root/build_artifacts/proto-plus_1702003338643/work\nprotobuf==3.20.3\npsutil==5.9.3\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\npudb==2024.1\nPuLP==2.8.0\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\npy-cpuinfo==9.0.0\npy-spy==0.3.14\npy4j==0.10.9.7\npyaml==23.12.0\nPyArabic==0.6.15\npyarrow==11.0.0\npyasn1 @ file:///home/conda/feedstock_root/build_artifacts/pyasn1_1701287008248/work\npyasn1-modules @ file:///home/conda/feedstock_root/build_artifacts/pyasn1-modules_1695107857548/work\nPyAstronomy==0.20.0\npybind11==2.11.1\npyclipper==1.3.0.post5\npycodestyle==2.11.1\npycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\npycryptodome==3.20.0\npyct==0.5.0\npycuda==2024.1\npydantic==2.5.3\npydantic_core==2.14.6\npydegensac==0.1.2\npydicom==2.4.4\npydocstyle==6.3.0\npydot==1.4.2\npydub==0.25.1\npyemd==1.0.0\npyerfa==2.0.1.1\npyexcel-io==0.6.6\npyexcel-ods==0.6.0\npyfasttext==0.4.6\npyflakes==3.2.0\npygltflib==1.16.1\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1700607939962/work\nPyJWT==2.8.0\npykalman==0.9.5\npyLDAvis==3.4.1\npylibraft @ file:///opt/conda/conda-bld/work/python/pylibraft\npylint==3.0.3\npymc3==3.11.4\nPyMeeus==0.5.12\npymongo==3.13.0\nPympler==1.0.1\npynndescent==0.5.11\npynvml @ file:///home/conda/feedstock_root/build_artifacts/pynvml_1639061605391/work\npynvrtc==9.2\npyocr==0.8.5\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1698795453264/work\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1690737849915/work\npypdf==4.0.2\npyproj @ file:///home/conda/feedstock_root/build_artifacts/pyproj_1702028071709/work\npysal==24.1\npyshp @ file:///home/conda/feedstock_root/build_artifacts/pyshp_1659002966020/work\nPySocks @ file:///home/builder/ci_310/pysocks_1640793678128/work\npytesseract==0.3.10\npytest==8.0.1\npython-bidi==0.4.2\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\npython-dotenv==1.0.0\npython-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\npython-Levenshtein==0.25.0\npython-louvain==0.16\npython-lsp-jsonrpc==1.1.2\npython-lsp-server==1.10.0\npython-slugify==8.0.4\npython-utils==3.8.2\npythreejs==2.4.2\npytoolconfig==1.3.1\npytools==2023.1.1\npytorch-ignite==0.4.13\npytorch-lightning==2.2.0.post0\npytz==2023.3.post1\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\nPyUpSet==0.1.1.post7\npyviz_comms==3.0.1\nPyWavelets==1.5.0\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1695373428874/work\npyzmq==24.0.1\nqgrid==1.3.1\nqtconsole==5.5.1\nQtPy==2.4.1\nquantecon==0.7.1\nquantities==0.15.0\nqudida==0.0.4\nraft-dask @ file:///opt/conda/conda-bld/work/python/raft-dask\nrapidfuzz==3.6.1\nrasterio==1.3.9\nrasterstats==0.19.0\nray==2.9.0\nray-cpp==2.9.0\nreferencing @ file:///home/conda/feedstock_root/build_artifacts/referencing_1704489226496/work\nregex==2023.12.25\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\nrequests-oauthlib==1.3.1\nrequests-toolbelt==0.10.1\nresponses==0.18.0\nretrying==1.3.3\nrfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\nrfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\nrgf-python==3.12.0\nrich @ file:///home/conda/feedstock_root/build_artifacts/rich-split_1700160075651/work/dist\nrich-click==1.7.3\nrmm @ file:///opt/conda/conda-bld/work/python\nrope==1.12.0\nrpds-py @ file:///home/conda/feedstock_root/build_artifacts/rpds-py_1703822618592/work\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1658328885051/work\nRtree==1.2.0\nruamel-yaml-conda @ file:///home/builder/ci_310/ruamel_yaml_1640794439226/work\nruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1698138615000/work\nruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\ns2sphere==0.2.5\ns3fs==2024.2.0\ns3transfer==0.6.2\nsafetensors==0.4.2\nscattertext==0.1.19\nscikit-image==0.22.0\nscikit-learn==1.2.2\nscikit-learn-intelex==2024.1.0\nscikit-multilearn==0.2.0\nscikit-optimize==0.9.0\nscikit-plot==0.3.7\nscikit-surprise==1.1.3\nscipy==1.11.4\nseaborn==0.12.2\nSecretStorage==3.3.3\nsegment_anything @ git+https://github.com/facebookresearch/segment-anything.git@6fdee8f2727f4506cfbbe553e23b895e27956588\nsegregation==2.5\nsemver==3.0.2\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1682601222253/work\nsentencepiece==0.2.0\nsentry-sdk==1.40.5\nsetproctitle==1.3.3\nsetuptools-git==1.2\nsetuptools-scm==8.0.4\nshap==0.44.1\nShapely==1.8.5.post1\nshellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1698144360966/work\nShimmy==1.3.0\nsimpervisor==1.0.0\nSimpleITK==2.3.1\nsimplejson==3.19.2\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\nsklearn-pandas==2.2.0\nslicer==0.0.7\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_split_1694066705667/work/dist\nsmhasher==0.150.1\nsmmap==5.0.1\nsniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1662051266223/work\nsnowballstemmer==2.2.0\nsnuggs==1.4.7\nsortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1621217038088/work\nsoundfile==0.12.1\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\nsoxr==0.3.7\nspacy @ file:///home/conda/feedstock_root/build_artifacts/spacy_1699194962107/work\nspacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1674550301837/work\nspacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1694527114282/work\nspaghetti==1.7.5.post1\nspectral==0.23.1\nspglm==1.1.0\nsphinx-rtd-theme==0.2.4\nspint==1.0.7\nsplot==1.1.5.post1\nspopt==0.6.0\nspreg==1.4.2\nspvcm==0.3.0\nSQLAlchemy==2.0.25\nsqlparse==0.4.4\nsquarify==0.4.3\nsrsly @ file:///home/conda/feedstock_root/build_artifacts/srsly_1695653949688/work\nstable-baselines3==2.1.0\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\nstanio==0.3.0\nstarlette==0.32.0.post1\nstatsmodels==0.14.1\nstemming==1.0.1\nstop-words==2018.7.23\nstopit==1.1.2\nstumpy==1.12.0\nsympy==1.12\ntables==3.9.2\ntabulate==0.9.0\ntangled-up-in-unicode==0.2.0\ntbb==2021.11.0\ntblib @ file:///home/conda/feedstock_root/build_artifacts/tblib_1702066284995/work\ntenacity==8.2.3\ntensorboard==2.15.1\ntensorboard-data-server==0.7.2\ntensorboard-plugin-profile==2.15.0\ntensorboardX==2.6.2.2\ntensorflow==2.15.0\ntensorflow-cloud==0.1.16\ntensorflow-datasets==4.9.4\ntensorflow-decision-forests==1.8.1\ntensorflow-estimator==2.15.0\ntensorflow-hub==0.16.1\ntensorflow-io==0.35.0\ntensorflow-io-gcs-filesystem==0.35.0\ntensorflow-metadata==0.14.0\ntensorflow-probability==0.23.0\ntensorflow-serving-api==2.14.1\ntensorflow-text==2.15.0\ntensorflow-transform==0.14.0\ntensorpack==0.11\ntensorstore==0.1.53\ntermcolor==2.4.0\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1699810101464/work\ntestpath==0.6.0\ntext-unidecode==1.3\ntextblob==0.18.0.post0\ntexttable==1.7.0\ntf-keras==2.15.0\ntfp-nightly @ git+https://github.com/tensorflow/probability.git@fbc5ebe9b1d343113fb917010096cfd88b32eecf\nTheano==1.0.5\nTheano-PyMC==1.1.2\nthinc @ file:///home/conda/feedstock_root/build_artifacts/thinc_1703842165913/work\nthreadpoolctl==3.2.0\ntifffile==2023.12.9\ntimm==0.9.16\ntinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1666100256010/work\ntobler==0.11.2\ntokenizers==0.15.2\ntoml==0.10.2\ntomli==2.0.1\ntomlkit==0.12.3\ntoolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1706112571092/work\ntorch @ file:///tmp/torch/torch-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=ae3259980b8d6551608b32fde2695baca64c72ed15ab2332023a248c113815a8\ntorchaudio @ file:///tmp/torch/torchaudio-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=10966b20361b49bc41b6c6ba842d3ea842320fb8c589823b4120f24a98013b4a\ntorchdata==0.7.1\ntorchinfo==1.8.0\ntorchmetrics==1.3.1\ntorchtext @ file:///tmp/torch/torchtext-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=a2a382655a08e1f6eeab6a307d0c8d78139cfa04cc329a7dc15a3f7c1e6e7a19\ntorchvision @ file:///tmp/torch/torchvision-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=105901a20924f652ee62df0bb57580c67725eb21f11a349658952c4be2050d94\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1695373560918/work\nTPOT==0.12.1\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1691671248568/work\ntraceml==1.0.8\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1675110562325/work\ntraittypes==0.2.1\ntransformers==4.38.1\ntreelite==3.2.0\ntreelite-runtime==3.2.0\ntrueskill==0.4.5\ntruststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\ntrx-python==0.2.9\ntsfresh==0.20.2\ntypeguard==4.1.5\ntyper @ file:///home/conda/feedstock_root/build_artifacts/typer_1683029246636/work\ntypes-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1704512562698/work\ntyping-inspect==0.9.0\ntyping-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1702176139754/work\ntzdata==2023.4\ntzlocal==5.2\nuc-micro-py==1.0.3\nucx-py @ file:///opt/conda/conda-bld/work\nujson==5.9.0\numap-learn==0.5.5\nunicodedata2 @ file:///home/conda/feedstock_root/build_artifacts/unicodedata2_1695847980273/work\nUnidecode==1.3.8\nupdate-checker==0.18.0\nuri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\nuritemplate==3.0.1\nurllib3==1.26.18\nurwid==2.6.4\nurwid_readline==0.13\nuvicorn==0.25.0\nuvloop==0.19.0\nvaex==4.17.0\nvaex-astro==0.9.3\nvaex-core==4.17.1\nvaex-hdf5==0.14.1\nvaex-jupyter==0.8.2\nvaex-ml==0.18.3\nvaex-server==0.9.0\nvaex-viz==0.5.4\nvec_noise==1.1.4\nvecstack==0.4.0\nvirtualenv==20.21.0\nvisions==0.7.5\nvowpalwabbit==9.9.0\nvtk==9.3.0\nWand==0.6.13\nwandb==0.16.3\nwasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1686131297168/work\nwatchfiles==0.21.0\nwavio==0.0.8\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\nweasel @ file:///home/conda/feedstock_root/build_artifacts/weasel_1699295455892/work\nwebcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1679900785843/work\nwebencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\nwebsocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1701630677416/work\nwebsockets==12.0\nWerkzeug==3.0.1\nwfdb==4.1.2\nwhatthepatch==1.0.5\nwidgetsnbextension==3.6.6\nwitwidget==1.8.1\nwoodwork==0.28.0\nwordcloud==1.9.3\nwordsegment==1.3.1\nwrapt==1.14.1\nxarray==2024.2.0\nxarray-einstats==0.7.0\nxgboost==2.0.3\nxvfbwrapper==0.2.9\nxxhash==3.4.1\nxyzservices @ file:///home/conda/feedstock_root/build_artifacts/xyzservices_1698325309404/work\ny-py==0.6.2\nyapf==0.40.2\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1701168553642/work\nydata-profiling==4.6.4\nyellowbrick==1.5\nypy-websocket==0.8.4\nzict @ file:///home/conda/feedstock_root/build_artifacts/zict_1681770155528/work\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1695255097490/work\nzstandard==0.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"######################################\n### CREATE CLUTTERED MNIST DATASET ###\n######################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Transformation classes\n\nclass RandomPlacement(object):\n  def __call__(self, img):\n    canvas = torch.zeros(1,100,100)\n    x = torch.randint(0, 73, (1,))\n    y = torch.randint(0, 73, (1,))\n    canvas[:, x:x+28, y:y+28] = img\n\n    return canvas\n\nclass RandomCropAndCombine(object):\n  def __init__(self, dataset):\n    self.dataset = dataset\n\n  def __call__(self, canvas):\n    for _ in range(8):\n      img, _ = random.choice(self.dataset)\n      img = transforms.ToTensor()(img)\n      x = torch.randint(0, 91, (1,))\n      y = torch.randint(0, 91, (1,))\n      patch = transforms.RandomCrop((9,9))(img)\n      canvas[:, x:x+9, y:y+9] += patch\n      canvas = canvas.clamp(0, 1)\n\n    return canvas","metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1711009738485,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"YM6ay7S8Vu6-","execution":{"iopub.status.busy":"2024-06-26T15:40:27.263785Z","iopub.execute_input":"2024-06-26T15:40:27.264238Z","iopub.status.idle":"2024-06-26T15:40:27.275073Z","shell.execute_reply.started":"2024-06-26T15:40:27.264188Z","shell.execute_reply":"2024-06-26T15:40:27.273940Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Create cluttered MNIST dataset, split datasets and create DataLoaders.\n\n# Set seed for reproducability\ntorch.manual_seed(1)\nnp.random.seed(1)\ngenerator = torch.Generator().manual_seed(1)\n\n# Set batch size parameter\nBATCH_SIZE = 128\n\n# Define data transformations\noriginal_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\nmnist_original = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=None)\naugmented_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,)),\n    RandomPlacement(),\n    RandomCropAndCombine(mnist_original),\n])\n\n# Train datasets\nmnist_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=original_transform)\naugmented_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=augmented_transform)\n\n# Test datasets\naugmented_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=augmented_transform)\nmnist_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=original_transform)\n\n# Split train dataset into 90% train and 10% validation data\nmnist_train, mnist_val = torch.utils.data.random_split(dataset=mnist_dataset_train, lengths=[0.9, 0.1], generator=generator)\naugmented_train, augmented_val = torch.utils.data.random_split(dataset=augmented_dataset_train, lengths=[0.9, 0.1], generator=generator)\n\n# Create data loaders for original and augmented datasets\n\n# Load train data\nmnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=BATCH_SIZE, shuffle=True)\ntrain_loader = torch.utils.data.DataLoader(dataset=augmented_train, batch_size=BATCH_SIZE, shuffle=True)\n# Load validation data\nmnist_val_loader = torch.utils.data.DataLoader(dataset=mnist_val, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset=augmented_val, batch_size=BATCH_SIZE, shuffle=True)\n# Load test data\ntest_loader = torch.utils.data.DataLoader(dataset=augmented_dataset_test, batch_size=BATCH_SIZE, shuffle=False)\nmnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_dataset_test, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:40:27.400576Z","iopub.execute_input":"2024-06-26T15:40:27.400940Z","iopub.status.idle":"2024-06-26T15:40:27.674273Z","shell.execute_reply.started":"2024-06-26T15:40:27.400912Z","shell.execute_reply":"2024-06-26T15:40:27.673149Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Plot the original and the augmented dataset\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\nfor i in range(4):\n  original_img, _ = mnist_original[i]\n  original_img = transforms.ToTensor()(original_img).squeeze(0)\n  axes[0, i].imshow(original_img, cmap='gray')\n  axes[0, i].axis('off')\n  axes[0, i].set_title('Original')\n\n  augmented_img, _ = augmented_dataset_train[i]\n  augmented_img = augmented_img.squeeze(0)\n  axes[1, i].imshow(augmented_img, cmap='gray')\n  axes[1, i].axis('off')\n  axes[1, i].set_title('Transformed')\n    \nplt.tight_layout()\nplt.show()","metadata":{"executionInfo":{"elapsed":822,"status":"ok","timestamp":1711014574594,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"kGbbSYiscR-9","outputId":"94d74291-72ba-4227-c66c-289378c48520","execution":{"iopub.status.busy":"2024-06-26T15:40:28.552119Z","iopub.execute_input":"2024-06-26T15:40:28.552798Z","iopub.status.idle":"2024-06-26T15:40:29.622017Z","shell.execute_reply.started":"2024-06-26T15:40:28.552763Z","shell.execute_reply":"2024-06-26T15:40:29.620901Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 8 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"###############################################################\n### Helper Trainer Class to faciliate training the networks ###\n###############################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer():\n    '''\n    Trainer class containing multiple helper functions for training.\n    '''\n    def __init__(self, model, optimizer, train_loader, val_loader, test_loader,\n                 num_epochs, estimate_step=100, save_checkpoints=True, path='model'):\n        \n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n        self.criterion = nn.CrossEntropyLoss()\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.num_epochs = num_epochs\n        self.estimate_step = estimate_step\n        self.model_name = type(self.model).__name__\n        self.path = path\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.save_checkpoints = save_checkpoints\n        self.running_loss_train = []\n        self.running_loss_val = []\n        self.train_time_per_epoch = []\n        self.total_epochs_trained = 0\n        self.test_accuracy = None\n        self.inference_time = None\n\n    \n    def train(self):\n        '''\n        Function to train the model. Trains the model on a training dataset and evaluates the current performance\n        on a validation dataset at the end of each epoch. Reduces the learning rate, if there is no\n        improvement in the validation loss for 10 epochs. \n        '''\n        self.model.to(self.device)\n        self.model.train()\n        for epoch in range(self.num_epochs):\n            # Start timer\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            start_epoch = time.time()\n            \n            # Training process for one epoch\n            self.model.train(True)\n            running_loss_train = 0.00\n            for batch_idx, (data, target) in enumerate(self.train_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                self.optimizer.zero_grad(set_to_none=True)\n                output = self.model(data)\n                loss = self.criterion(output, target)\n                running_loss_train += loss.item()\n                loss.backward()\n                self.optimizer.step()\n                if batch_idx % self.estimate_step == 0:\n                    print(f'Epoch {epoch+1}/{self.num_epochs}, Batch {batch_idx}/{len(self.train_loader)}, Train Loss: {loss.item():.4f}')     \n            avg_loss_train = running_loss_train / len(self.train_loader)\n            self.running_loss_train.append(avg_loss_train)\n            \n            # Validate model at the end of each epoch\n            self.model.eval()\n            running_loss_val = 0.00\n            with torch.no_grad():\n                for i, (data_val, target_val) in enumerate(self.val_loader):\n                    data_val, target_val = data_val.to(self.device), target_val.to(self.device)\n                    output_val = self.model(data_val)\n                    loss_val = self.criterion(output_val, target_val)\n                    running_loss_val += loss_val.item()\n                avg_loss_val = running_loss_val / len(self.val_loader)\n                self.running_loss_val.append(avg_loss_val)\n            \n            # Recuce LR if model does not improve for 10 epochs\n            self.scheduler.step(avg_loss_val)\n            \n            # Track training time for each epoch\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            end_epoch = time.time()\n            self.train_time_per_epoch.append(end_epoch-start_epoch)\n            print(f'Model {self.model_name} at epoch {epoch+1}/{self.num_epochs}: Avg Train Loss: {avg_loss_train:.4f}, Avg Val Loss: {avg_loss_val:.4f}')\n            \n            # Increase epoch counter\n            self.total_epochs_trained += 1\n            \n            # Save checkpoint at the end of each epoch\n            if self.save_checkpoints:\n                self.save_checkpoint(self.path)\n            \n        # Print total training time at the end\n        train_time = \"{:.2f} minutes\".format(sum(self.train_time_per_epoch) / 60)\n        print(f'Model {self.model_name} took {train_time} to run on {self.total_epochs_trained} epochs.')\n        \n                \n    def eval(self):\n        '''\n        Function to evaluate the performance of the model.\n        Therefore, the models accuracy on a test dataset is measured.\n        '''\n        self.model.to(self.device)\n        self.model.eval()\n        correct = 0\n        total = 0\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        start_eval = time.time()\n        with torch.no_grad():\n            for data, target in self.test_loader:\n                data, target = data.to(self.device), target.to(self.device)\n                output = self.model(data)\n                _, predicted = torch.max(output.data, 1)\n                total += target.size(0)\n                correct += (predicted == target).sum().item()\n        self.test_accuracy = correct / total\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        end_eval = time.time()\n        self.inference_time = end_eval - start_eval\n        print(f'Test Accuracy for {self.model_name}: {self.test_accuracy:.4f} - in {self.inference_time} seconds.')\n        # Save checkpoint after evaluation.\n        if self.save_checkpoints:\n                self.save_checkpoint(self.path)\n    def save_checkpoint(self, path):\n        '''\n        Function to save the current state of the model, optimizer and scheduler.\n        Also saves the model metrics training loss, validation loss, accuracy,\n        training and inference time.\n        '''\n        torch.save({'epoch': self.total_epochs_trained,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'scheduler_state_dict': self.scheduler.state_dict(),\n                    'loss': self.running_loss_train[-1],\n                    'running_loss_train': self.running_loss_train,\n                    'running_loss_val': self.running_loss_val,\n                    'test_accuracy': self.test_accuracy,\n                    'train_time': self.train_time_per_epoch,\n                    'inference_time': self.inference_time}, \n                    f'{path}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:40:57.686201Z","iopub.execute_input":"2024-06-26T15:40:57.686607Z","iopub.status.idle":"2024-06-26T15:40:57.711929Z","shell.execute_reply.started":"2024-06-26T15:40:57.686575Z","shell.execute_reply":"2024-06-26T15:40:57.710866Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"###############################################\n### CNN model for MNIST and cluttered MNIST ###\n###############################################\n# NOTE: Only difference if the models is the linear layer fc1. Input features needs adjustment as the size of the input images is different.","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:33:02.153591Z","iopub.execute_input":"2024-06-26T07:33:02.154388Z","iopub.status.idle":"2024-06-26T07:33:02.158641Z","shell.execute_reply.started":"2024-06-26T07:33:02.154355Z","shell.execute_reply":"2024-06-26T07:33:02.157578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n####### CNN Model MNIST #######\n###############################\nclass CNN_MNIST(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(CNN_MNIST, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(9216, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:41:00.582740Z","iopub.execute_input":"2024-06-26T15:41:00.583139Z","iopub.status.idle":"2024-06-26T15:41:00.592916Z","shell.execute_reply.started":"2024-06-26T15:41:00.583110Z","shell.execute_reply":"2024-06-26T15:41:00.591719Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#################################\n####### CNN Model Clutter #######\n#################################\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(147456, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x","metadata":{"id":"Wdk5Gp7tlc4s","executionInfo":{"status":"ok","timestamp":1711019808528,"user_tz":-60,"elapsed":1920959,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"357f0e45-2497-42e1-bb5c-1f23c3ae1434","execution":{"iopub.status.busy":"2024-06-26T15:41:02.322300Z","iopub.execute_input":"2024-06-26T15:41:02.322687Z","iopub.status.idle":"2024-06-26T15:41:02.331508Z","shell.execute_reply.started":"2024-06-26T15:41:02.322659Z","shell.execute_reply":"2024-06-26T15:41:02.330498Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"###############################################\n### VAN model for MNIST and cluttered MNIST ###\n###############################################","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:33:05.324034Z","iopub.execute_input":"2024-06-26T07:33:05.324781Z","iopub.status.idle":"2024-06-26T07:33:05.328748Z","shell.execute_reply.started":"2024-06-26T07:33:05.324749Z","shell.execute_reply":"2024-06-26T07:33:05.327672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n####### VAN Model MNIST #######\n###############################\nclass Downsampling_MNIST(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block_MNIST(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) \n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA_MNIST(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN_MNIST(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN_MNIST(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA_MNIST(nn.Module):\n  def __init__(self, in_channels, out_channels, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=5, groups=in_channels)#DW-Conv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=5,\n                           dilation=3, groups=in_channels, padding=8)#DW-D-Conv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1) #1x1 Conv\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN_MNIST(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling_MNIST(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block_MNIST(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:41:04.969447Z","iopub.execute_input":"2024-06-26T15:41:04.970115Z","iopub.status.idle":"2024-06-26T15:41:04.996011Z","shell.execute_reply.started":"2024-06-26T15:41:04.970079Z","shell.execute_reply":"2024-06-26T15:41:04.995026Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#################################\n####### VAN Model Clutter #######\n#################################\nclass Downsampling(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) \n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW-3x3 Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA(nn.Module):\n  def __init__(self, in_channels, out_channels, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    \n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=5, groups=in_channels)#DW-Conv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=5,\n                           dilation=3, groups=in_channels, padding=8)#DW-D-Conv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1) #1x1 Conv\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:41:06.156969Z","iopub.execute_input":"2024-06-26T15:41:06.157958Z","iopub.status.idle":"2024-06-26T15:41:06.182303Z","shell.execute_reply.started":"2024-06-26T15:41:06.157922Z","shell.execute_reply":"2024-06-26T15:41:06.181309Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING PROCESS DONE. DO NOT TOUCH ANY OF THE TRAINING LINES","metadata":{}},{"cell_type":"code","source":"################################\n### TRAINING OF THE NETWORKS ###\n################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################\n### CNN Training ###\n####################","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:01:23.701726Z","iopub.execute_input":"2024-06-26T10:01:23.702091Z","iopub.status.idle":"2024-06-26T10:01:23.706071Z","shell.execute_reply.started":"2024-06-26T10:01:23.702063Z","shell.execute_reply":"2024-06-26T10:01:23.705146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize CNN on MNIST\ncnn_mnist = CNN_MNIST()\ncnn_mnist_optimizer = optim.AdamW(cnn_mnist.parameters(), lr=1e-3)\ncnn_mnist_trainer = Trainer(model=cnn_mnist, optimizer=cnn_mnist_optimizer,\n                            train_loader=mnist_train_loader, val_loader=mnist_val_loader, test_loader=mnist_test_loader,\n                            num_epochs=25, save_checkpoints=True, path=f'CNN_MNIST()')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:41:09.656962Z","iopub.execute_input":"2024-06-26T15:41:09.657369Z","iopub.status.idle":"2024-06-26T15:41:09.676440Z","shell.execute_reply.started":"2024-06-26T15:41:09.657339Z","shell.execute_reply":"2024-06-26T15:41:09.675667Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train CNN on MNIST\ncnn_mnist_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:41:11.522274Z","iopub.execute_input":"2024-06-26T15:41:11.522629Z","iopub.status.idle":"2024-06-26T15:47:07.982290Z","shell.execute_reply.started":"2024-06-26T15:41:11.522601Z","shell.execute_reply":"2024-06-26T15:47:07.980868Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/25, Batch 0/422, Train Loss: 2.3107\nEpoch 1/25, Batch 100/422, Train Loss: 0.2871\nEpoch 1/25, Batch 200/422, Train Loss: 0.1205\nEpoch 1/25, Batch 300/422, Train Loss: 0.1051\nEpoch 1/25, Batch 400/422, Train Loss: 0.0354\nModel CNN_MNIST at epoch 1/25: Avg Train Loss: 0.2281, Avg Val Loss: 0.0629\nEpoch 2/25, Batch 0/422, Train Loss: 0.1210\nEpoch 2/25, Batch 100/422, Train Loss: 0.0455\nEpoch 2/25, Batch 200/422, Train Loss: 0.0536\nEpoch 2/25, Batch 300/422, Train Loss: 0.0718\nEpoch 2/25, Batch 400/422, Train Loss: 0.0970\nModel CNN_MNIST at epoch 2/25: Avg Train Loss: 0.0864, Avg Val Loss: 0.0462\nEpoch 3/25, Batch 0/422, Train Loss: 0.0487\nEpoch 3/25, Batch 100/422, Train Loss: 0.0474\nEpoch 3/25, Batch 200/422, Train Loss: 0.0492\nEpoch 3/25, Batch 300/422, Train Loss: 0.0184\nEpoch 3/25, Batch 400/422, Train Loss: 0.0637\nModel CNN_MNIST at epoch 3/25: Avg Train Loss: 0.0635, Avg Val Loss: 0.0412\nEpoch 4/25, Batch 0/422, Train Loss: 0.0759\nEpoch 4/25, Batch 100/422, Train Loss: 0.0917\nEpoch 4/25, Batch 200/422, Train Loss: 0.0454\nEpoch 4/25, Batch 300/422, Train Loss: 0.0489\nEpoch 4/25, Batch 400/422, Train Loss: 0.0231\nModel CNN_MNIST at epoch 4/25: Avg Train Loss: 0.0519, Avg Val Loss: 0.0400\nEpoch 5/25, Batch 0/422, Train Loss: 0.0111\nEpoch 5/25, Batch 100/422, Train Loss: 0.0243\nEpoch 5/25, Batch 200/422, Train Loss: 0.0309\nEpoch 5/25, Batch 300/422, Train Loss: 0.0268\nEpoch 5/25, Batch 400/422, Train Loss: 0.0623\nModel CNN_MNIST at epoch 5/25: Avg Train Loss: 0.0383, Avg Val Loss: 0.0302\nEpoch 6/25, Batch 0/422, Train Loss: 0.0452\nEpoch 6/25, Batch 100/422, Train Loss: 0.0569\nEpoch 6/25, Batch 200/422, Train Loss: 0.0428\nEpoch 6/25, Batch 300/422, Train Loss: 0.0162\nEpoch 6/25, Batch 400/422, Train Loss: 0.0343\nModel CNN_MNIST at epoch 6/25: Avg Train Loss: 0.0349, Avg Val Loss: 0.0320\nEpoch 7/25, Batch 0/422, Train Loss: 0.0165\nEpoch 7/25, Batch 100/422, Train Loss: 0.0108\nEpoch 7/25, Batch 200/422, Train Loss: 0.0124\nEpoch 7/25, Batch 300/422, Train Loss: 0.0261\nEpoch 7/25, Batch 400/422, Train Loss: 0.0197\nModel CNN_MNIST at epoch 7/25: Avg Train Loss: 0.0301, Avg Val Loss: 0.0299\nEpoch 8/25, Batch 0/422, Train Loss: 0.0139\nEpoch 8/25, Batch 100/422, Train Loss: 0.0023\nEpoch 8/25, Batch 200/422, Train Loss: 0.0046\nEpoch 8/25, Batch 300/422, Train Loss: 0.0173\nEpoch 8/25, Batch 400/422, Train Loss: 0.0110\nModel CNN_MNIST at epoch 8/25: Avg Train Loss: 0.0271, Avg Val Loss: 0.0322\nEpoch 9/25, Batch 0/422, Train Loss: 0.0306\nEpoch 9/25, Batch 100/422, Train Loss: 0.0063\nEpoch 9/25, Batch 200/422, Train Loss: 0.0410\nEpoch 9/25, Batch 300/422, Train Loss: 0.0133\nEpoch 9/25, Batch 400/422, Train Loss: 0.0210\nModel CNN_MNIST at epoch 9/25: Avg Train Loss: 0.0241, Avg Val Loss: 0.0335\nEpoch 10/25, Batch 0/422, Train Loss: 0.0073\nEpoch 10/25, Batch 100/422, Train Loss: 0.0256\nEpoch 10/25, Batch 200/422, Train Loss: 0.0018\nEpoch 10/25, Batch 300/422, Train Loss: 0.0075\nEpoch 10/25, Batch 400/422, Train Loss: 0.0093\nModel CNN_MNIST at epoch 10/25: Avg Train Loss: 0.0207, Avg Val Loss: 0.0297\nEpoch 11/25, Batch 0/422, Train Loss: 0.0018\nEpoch 11/25, Batch 100/422, Train Loss: 0.0075\nEpoch 11/25, Batch 200/422, Train Loss: 0.0028\nEpoch 11/25, Batch 300/422, Train Loss: 0.0102\nEpoch 11/25, Batch 400/422, Train Loss: 0.0336\nModel CNN_MNIST at epoch 11/25: Avg Train Loss: 0.0183, Avg Val Loss: 0.0287\nEpoch 12/25, Batch 0/422, Train Loss: 0.0189\nEpoch 12/25, Batch 100/422, Train Loss: 0.0031\nEpoch 12/25, Batch 200/422, Train Loss: 0.0459\nEpoch 12/25, Batch 300/422, Train Loss: 0.0115\nEpoch 12/25, Batch 400/422, Train Loss: 0.0659\nModel CNN_MNIST at epoch 12/25: Avg Train Loss: 0.0176, Avg Val Loss: 0.0351\nEpoch 13/25, Batch 0/422, Train Loss: 0.0112\nEpoch 13/25, Batch 100/422, Train Loss: 0.0085\nEpoch 13/25, Batch 200/422, Train Loss: 0.0141\nEpoch 13/25, Batch 300/422, Train Loss: 0.0054\nEpoch 13/25, Batch 400/422, Train Loss: 0.0190\nModel CNN_MNIST at epoch 13/25: Avg Train Loss: 0.0167, Avg Val Loss: 0.0359\nEpoch 14/25, Batch 0/422, Train Loss: 0.0340\nEpoch 14/25, Batch 100/422, Train Loss: 0.0022\nEpoch 14/25, Batch 200/422, Train Loss: 0.0075\nEpoch 14/25, Batch 300/422, Train Loss: 0.0011\nEpoch 14/25, Batch 400/422, Train Loss: 0.0143\nModel CNN_MNIST at epoch 14/25: Avg Train Loss: 0.0160, Avg Val Loss: 0.0318\nEpoch 15/25, Batch 0/422, Train Loss: 0.0038\nEpoch 15/25, Batch 100/422, Train Loss: 0.0240\nEpoch 15/25, Batch 200/422, Train Loss: 0.0053\nEpoch 15/25, Batch 300/422, Train Loss: 0.0087\nEpoch 15/25, Batch 400/422, Train Loss: 0.0069\nModel CNN_MNIST at epoch 15/25: Avg Train Loss: 0.0148, Avg Val Loss: 0.0358\nEpoch 16/25, Batch 0/422, Train Loss: 0.0224\nEpoch 16/25, Batch 100/422, Train Loss: 0.0074\nEpoch 16/25, Batch 200/422, Train Loss: 0.0036\nEpoch 16/25, Batch 300/422, Train Loss: 0.0167\nEpoch 16/25, Batch 400/422, Train Loss: 0.0117\nModel CNN_MNIST at epoch 16/25: Avg Train Loss: 0.0149, Avg Val Loss: 0.0382\nEpoch 17/25, Batch 0/422, Train Loss: 0.0229\nEpoch 17/25, Batch 100/422, Train Loss: 0.0028\nEpoch 17/25, Batch 200/422, Train Loss: 0.0375\nEpoch 17/25, Batch 300/422, Train Loss: 0.0050\nEpoch 17/25, Batch 400/422, Train Loss: 0.0070\nModel CNN_MNIST at epoch 17/25: Avg Train Loss: 0.0153, Avg Val Loss: 0.0275\nEpoch 18/25, Batch 0/422, Train Loss: 0.0001\nEpoch 18/25, Batch 100/422, Train Loss: 0.0027\nEpoch 18/25, Batch 200/422, Train Loss: 0.0014\nEpoch 18/25, Batch 300/422, Train Loss: 0.0357\nEpoch 18/25, Batch 400/422, Train Loss: 0.0019\nModel CNN_MNIST at epoch 18/25: Avg Train Loss: 0.0109, Avg Val Loss: 0.0290\nEpoch 19/25, Batch 0/422, Train Loss: 0.0195\nEpoch 19/25, Batch 100/422, Train Loss: 0.0034\nEpoch 19/25, Batch 200/422, Train Loss: 0.0335\nEpoch 19/25, Batch 300/422, Train Loss: 0.0167\nEpoch 19/25, Batch 400/422, Train Loss: 0.0156\nModel CNN_MNIST at epoch 19/25: Avg Train Loss: 0.0135, Avg Val Loss: 0.0310\nEpoch 20/25, Batch 0/422, Train Loss: 0.0158\nEpoch 20/25, Batch 100/422, Train Loss: 0.0350\nEpoch 20/25, Batch 200/422, Train Loss: 0.0004\nEpoch 20/25, Batch 300/422, Train Loss: 0.0542\nEpoch 20/25, Batch 400/422, Train Loss: 0.0014\nModel CNN_MNIST at epoch 20/25: Avg Train Loss: 0.0104, Avg Val Loss: 0.0310\nEpoch 21/25, Batch 0/422, Train Loss: 0.0010\nEpoch 21/25, Batch 100/422, Train Loss: 0.0012\nEpoch 21/25, Batch 200/422, Train Loss: 0.0116\nEpoch 21/25, Batch 300/422, Train Loss: 0.0013\nEpoch 21/25, Batch 400/422, Train Loss: 0.0161\nModel CNN_MNIST at epoch 21/25: Avg Train Loss: 0.0116, Avg Val Loss: 0.0327\nEpoch 22/25, Batch 0/422, Train Loss: 0.0042\nEpoch 22/25, Batch 100/422, Train Loss: 0.0350\nEpoch 22/25, Batch 200/422, Train Loss: 0.0147\nEpoch 22/25, Batch 300/422, Train Loss: 0.0007\nEpoch 22/25, Batch 400/422, Train Loss: 0.0061\nModel CNN_MNIST at epoch 22/25: Avg Train Loss: 0.0113, Avg Val Loss: 0.0368\nEpoch 23/25, Batch 0/422, Train Loss: 0.0018\nEpoch 23/25, Batch 100/422, Train Loss: 0.0010\nEpoch 23/25, Batch 200/422, Train Loss: 0.0069\nEpoch 23/25, Batch 300/422, Train Loss: 0.0027\nEpoch 23/25, Batch 400/422, Train Loss: 0.0044\nModel CNN_MNIST at epoch 23/25: Avg Train Loss: 0.0088, Avg Val Loss: 0.0339\nEpoch 24/25, Batch 0/422, Train Loss: 0.0005\nEpoch 24/25, Batch 100/422, Train Loss: 0.0065\nEpoch 24/25, Batch 200/422, Train Loss: 0.0266\nEpoch 24/25, Batch 300/422, Train Loss: 0.0064\nEpoch 24/25, Batch 400/422, Train Loss: 0.0016\nModel CNN_MNIST at epoch 24/25: Avg Train Loss: 0.0109, Avg Val Loss: 0.0392\nEpoch 25/25, Batch 0/422, Train Loss: 0.0037\nEpoch 25/25, Batch 100/422, Train Loss: 0.0004\nEpoch 25/25, Batch 200/422, Train Loss: 0.0005\nEpoch 25/25, Batch 300/422, Train Loss: 0.0179\nEpoch 25/25, Batch 400/422, Train Loss: 0.0176\nModel CNN_MNIST at epoch 25/25: Avg Train Loss: 0.0096, Avg Val Loss: 0.0428\nModel CNN_MNIST took 5.93 minutes to run on 25 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate CNN on MNIST\ncnn_mnist_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:47:07.984590Z","iopub.execute_input":"2024-06-26T15:47:07.985008Z","iopub.status.idle":"2024-06-26T15:47:10.446628Z","shell.execute_reply.started":"2024-06-26T15:47:07.984970Z","shell.execute_reply":"2024-06-26T15:47:10.445648Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Test Accuracy for CNN_MNIST: 0.9905 - in 2.4205944538116455 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize CNN on cluterred MNIST\ncnn_clutter = CNN()\ncnn_clutter_optimizer = optim.AdamW(cnn_clutter.parameters(), lr=1e-3)\ncnn_clutter_trainer = Trainer(model=cnn_clutter, optimizer=cnn_clutter_optimizer,\n                            train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                            num_epochs=50, save_checkpoints=True, path=f'CNN_CLUTTER()')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:54:01.614534Z","iopub.execute_input":"2024-06-26T15:54:01.614864Z","iopub.status.idle":"2024-06-26T15:54:01.820046Z","shell.execute_reply.started":"2024-06-26T15:54:01.614836Z","shell.execute_reply":"2024-06-26T15:54:01.819003Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Train CNN on cluttered MNIST\ncnn_clutter_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:54:01.821551Z","iopub.execute_input":"2024-06-26T15:54:01.821965Z","iopub.status.idle":"2024-06-26T18:39:12.979486Z","shell.execute_reply.started":"2024-06-26T15:54:01.821929Z","shell.execute_reply":"2024-06-26T18:39:12.978113Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/50, Batch 0/422, Train Loss: 2.2997\nEpoch 1/50, Batch 100/422, Train Loss: 2.2975\nEpoch 1/50, Batch 200/422, Train Loss: 2.2279\nEpoch 1/50, Batch 300/422, Train Loss: 2.0602\nEpoch 1/50, Batch 400/422, Train Loss: 2.0498\nModel CNN at epoch 1/50: Avg Train Loss: 2.1655, Avg Val Loss: 1.8681\nEpoch 2/50, Batch 0/422, Train Loss: 1.9239\nEpoch 2/50, Batch 100/422, Train Loss: 1.9253\nEpoch 2/50, Batch 200/422, Train Loss: 1.8369\nEpoch 2/50, Batch 300/422, Train Loss: 1.7575\nEpoch 2/50, Batch 400/422, Train Loss: 1.7953\nModel CNN at epoch 2/50: Avg Train Loss: 1.8113, Avg Val Loss: 1.5357\nEpoch 3/50, Batch 0/422, Train Loss: 1.6107\nEpoch 3/50, Batch 100/422, Train Loss: 1.5694\nEpoch 3/50, Batch 200/422, Train Loss: 1.4097\nEpoch 3/50, Batch 300/422, Train Loss: 1.4955\nEpoch 3/50, Batch 400/422, Train Loss: 1.3941\nModel CNN at epoch 3/50: Avg Train Loss: 1.4918, Avg Val Loss: 1.1647\nEpoch 4/50, Batch 0/422, Train Loss: 1.3061\nEpoch 4/50, Batch 100/422, Train Loss: 1.4351\nEpoch 4/50, Batch 200/422, Train Loss: 1.3048\nEpoch 4/50, Batch 300/422, Train Loss: 1.0671\nEpoch 4/50, Batch 400/422, Train Loss: 1.0595\nModel CNN at epoch 4/50: Avg Train Loss: 1.2157, Avg Val Loss: 0.9456\nEpoch 5/50, Batch 0/422, Train Loss: 1.1176\nEpoch 5/50, Batch 100/422, Train Loss: 1.0764\nEpoch 5/50, Batch 200/422, Train Loss: 1.1603\nEpoch 5/50, Batch 300/422, Train Loss: 0.9229\nEpoch 5/50, Batch 400/422, Train Loss: 0.9728\nModel CNN at epoch 5/50: Avg Train Loss: 1.0582, Avg Val Loss: 0.8066\nEpoch 6/50, Batch 0/422, Train Loss: 1.1147\nEpoch 6/50, Batch 100/422, Train Loss: 1.0614\nEpoch 6/50, Batch 200/422, Train Loss: 1.0904\nEpoch 6/50, Batch 300/422, Train Loss: 1.0075\nEpoch 6/50, Batch 400/422, Train Loss: 0.7755\nModel CNN at epoch 6/50: Avg Train Loss: 0.9480, Avg Val Loss: 0.6774\nEpoch 7/50, Batch 0/422, Train Loss: 0.9149\nEpoch 7/50, Batch 100/422, Train Loss: 0.7697\nEpoch 7/50, Batch 200/422, Train Loss: 0.8050\nEpoch 7/50, Batch 300/422, Train Loss: 0.7393\nEpoch 7/50, Batch 400/422, Train Loss: 0.8812\nModel CNN at epoch 7/50: Avg Train Loss: 0.8721, Avg Val Loss: 0.5981\nEpoch 8/50, Batch 0/422, Train Loss: 0.9021\nEpoch 8/50, Batch 100/422, Train Loss: 0.9549\nEpoch 8/50, Batch 200/422, Train Loss: 0.7146\nEpoch 8/50, Batch 300/422, Train Loss: 0.7931\nEpoch 8/50, Batch 400/422, Train Loss: 0.6308\nModel CNN at epoch 8/50: Avg Train Loss: 0.8159, Avg Val Loss: 0.5794\nEpoch 9/50, Batch 0/422, Train Loss: 0.6934\nEpoch 9/50, Batch 100/422, Train Loss: 0.6193\nEpoch 9/50, Batch 200/422, Train Loss: 0.9045\nEpoch 9/50, Batch 300/422, Train Loss: 0.6853\nEpoch 9/50, Batch 400/422, Train Loss: 0.7950\nModel CNN at epoch 9/50: Avg Train Loss: 0.7646, Avg Val Loss: 0.5280\nEpoch 10/50, Batch 0/422, Train Loss: 0.7683\nEpoch 10/50, Batch 100/422, Train Loss: 0.5875\nEpoch 10/50, Batch 200/422, Train Loss: 0.8747\nEpoch 10/50, Batch 300/422, Train Loss: 0.8219\nEpoch 10/50, Batch 400/422, Train Loss: 0.7312\nModel CNN at epoch 10/50: Avg Train Loss: 0.7329, Avg Val Loss: 0.4889\nEpoch 11/50, Batch 0/422, Train Loss: 0.6378\nEpoch 11/50, Batch 100/422, Train Loss: 0.7219\nEpoch 11/50, Batch 200/422, Train Loss: 0.7132\nEpoch 11/50, Batch 300/422, Train Loss: 0.6136\nEpoch 11/50, Batch 400/422, Train Loss: 0.6746\nModel CNN at epoch 11/50: Avg Train Loss: 0.7087, Avg Val Loss: 0.4771\nEpoch 12/50, Batch 0/422, Train Loss: 0.8007\nEpoch 12/50, Batch 100/422, Train Loss: 0.8032\nEpoch 12/50, Batch 200/422, Train Loss: 0.6692\nEpoch 12/50, Batch 300/422, Train Loss: 0.5614\nEpoch 12/50, Batch 400/422, Train Loss: 0.6490\nModel CNN at epoch 12/50: Avg Train Loss: 0.6716, Avg Val Loss: 0.4397\nEpoch 13/50, Batch 0/422, Train Loss: 0.5447\nEpoch 13/50, Batch 100/422, Train Loss: 0.6621\nEpoch 13/50, Batch 200/422, Train Loss: 0.6423\nEpoch 13/50, Batch 300/422, Train Loss: 0.6751\nEpoch 13/50, Batch 400/422, Train Loss: 0.5951\nModel CNN at epoch 13/50: Avg Train Loss: 0.6533, Avg Val Loss: 0.4261\nEpoch 14/50, Batch 0/422, Train Loss: 0.5528\nEpoch 14/50, Batch 100/422, Train Loss: 0.5315\nEpoch 14/50, Batch 200/422, Train Loss: 0.4941\nEpoch 14/50, Batch 300/422, Train Loss: 0.6322\nEpoch 14/50, Batch 400/422, Train Loss: 0.7926\nModel CNN at epoch 14/50: Avg Train Loss: 0.6215, Avg Val Loss: 0.4491\nEpoch 15/50, Batch 0/422, Train Loss: 0.6536\nEpoch 15/50, Batch 100/422, Train Loss: 0.4680\nEpoch 15/50, Batch 200/422, Train Loss: 0.6051\nEpoch 15/50, Batch 300/422, Train Loss: 0.5747\nEpoch 15/50, Batch 400/422, Train Loss: 0.7325\nModel CNN at epoch 15/50: Avg Train Loss: 0.6087, Avg Val Loss: 0.3909\nEpoch 16/50, Batch 0/422, Train Loss: 0.5925\nEpoch 16/50, Batch 100/422, Train Loss: 0.5034\nEpoch 16/50, Batch 200/422, Train Loss: 0.5824\nEpoch 16/50, Batch 300/422, Train Loss: 0.5982\nEpoch 16/50, Batch 400/422, Train Loss: 0.6432\nModel CNN at epoch 16/50: Avg Train Loss: 0.5877, Avg Val Loss: 0.3673\nEpoch 17/50, Batch 0/422, Train Loss: 0.5682\nEpoch 17/50, Batch 100/422, Train Loss: 0.6268\nEpoch 17/50, Batch 200/422, Train Loss: 0.5600\nEpoch 17/50, Batch 300/422, Train Loss: 0.4972\nEpoch 17/50, Batch 400/422, Train Loss: 0.5300\nModel CNN at epoch 17/50: Avg Train Loss: 0.5842, Avg Val Loss: 0.3614\nEpoch 18/50, Batch 0/422, Train Loss: 0.5143\nEpoch 18/50, Batch 100/422, Train Loss: 0.4710\nEpoch 18/50, Batch 200/422, Train Loss: 0.6429\nEpoch 18/50, Batch 300/422, Train Loss: 0.4870\nEpoch 18/50, Batch 400/422, Train Loss: 0.7846\nModel CNN at epoch 18/50: Avg Train Loss: 0.5663, Avg Val Loss: 0.3699\nEpoch 19/50, Batch 0/422, Train Loss: 0.5932\nEpoch 19/50, Batch 100/422, Train Loss: 0.5830\nEpoch 19/50, Batch 200/422, Train Loss: 0.5216\nEpoch 19/50, Batch 300/422, Train Loss: 0.8089\nEpoch 19/50, Batch 400/422, Train Loss: 0.5567\nModel CNN at epoch 19/50: Avg Train Loss: 0.5502, Avg Val Loss: 0.3602\nEpoch 20/50, Batch 0/422, Train Loss: 0.3822\nEpoch 20/50, Batch 100/422, Train Loss: 0.5109\nEpoch 20/50, Batch 200/422, Train Loss: 0.6781\nEpoch 20/50, Batch 300/422, Train Loss: 0.6351\nEpoch 20/50, Batch 400/422, Train Loss: 0.6009\nModel CNN at epoch 20/50: Avg Train Loss: 0.5481, Avg Val Loss: 0.3611\nEpoch 21/50, Batch 0/422, Train Loss: 0.6459\nEpoch 21/50, Batch 100/422, Train Loss: 0.5972\nEpoch 21/50, Batch 200/422, Train Loss: 0.4573\nEpoch 21/50, Batch 300/422, Train Loss: 0.4659\nEpoch 21/50, Batch 400/422, Train Loss: 0.5522\nModel CNN at epoch 21/50: Avg Train Loss: 0.5402, Avg Val Loss: 0.3671\nEpoch 22/50, Batch 0/422, Train Loss: 0.7845\nEpoch 22/50, Batch 100/422, Train Loss: 0.5109\nEpoch 22/50, Batch 200/422, Train Loss: 0.6508\nEpoch 22/50, Batch 300/422, Train Loss: 0.4640\nEpoch 22/50, Batch 400/422, Train Loss: 0.5751\nModel CNN at epoch 22/50: Avg Train Loss: 0.5273, Avg Val Loss: 0.3468\nEpoch 23/50, Batch 0/422, Train Loss: 0.4680\nEpoch 23/50, Batch 100/422, Train Loss: 0.5722\nEpoch 23/50, Batch 200/422, Train Loss: 0.5185\nEpoch 23/50, Batch 300/422, Train Loss: 0.4738\nEpoch 23/50, Batch 400/422, Train Loss: 0.5722\nModel CNN at epoch 23/50: Avg Train Loss: 0.5220, Avg Val Loss: 0.3288\nEpoch 24/50, Batch 0/422, Train Loss: 0.4701\nEpoch 24/50, Batch 100/422, Train Loss: 0.5306\nEpoch 24/50, Batch 200/422, Train Loss: 0.5249\nEpoch 24/50, Batch 300/422, Train Loss: 0.5947\nEpoch 24/50, Batch 400/422, Train Loss: 0.3968\nModel CNN at epoch 24/50: Avg Train Loss: 0.5087, Avg Val Loss: 0.3507\nEpoch 25/50, Batch 0/422, Train Loss: 0.3998\nEpoch 25/50, Batch 100/422, Train Loss: 0.4695\nEpoch 25/50, Batch 200/422, Train Loss: 0.3861\nEpoch 25/50, Batch 300/422, Train Loss: 0.5734\nEpoch 25/50, Batch 400/422, Train Loss: 0.4767\nModel CNN at epoch 25/50: Avg Train Loss: 0.5038, Avg Val Loss: 0.3184\nEpoch 26/50, Batch 0/422, Train Loss: 0.6219\nEpoch 26/50, Batch 100/422, Train Loss: 0.5381\nEpoch 26/50, Batch 200/422, Train Loss: 0.7277\nEpoch 26/50, Batch 300/422, Train Loss: 0.5455\nEpoch 26/50, Batch 400/422, Train Loss: 0.5405\nModel CNN at epoch 26/50: Avg Train Loss: 0.4925, Avg Val Loss: 0.2972\nEpoch 27/50, Batch 0/422, Train Loss: 0.6287\nEpoch 27/50, Batch 100/422, Train Loss: 0.4228\nEpoch 27/50, Batch 200/422, Train Loss: 0.5430\nEpoch 27/50, Batch 300/422, Train Loss: 0.4092\nEpoch 27/50, Batch 400/422, Train Loss: 0.4065\nModel CNN at epoch 27/50: Avg Train Loss: 0.4902, Avg Val Loss: 0.3216\nEpoch 28/50, Batch 0/422, Train Loss: 0.5185\nEpoch 28/50, Batch 100/422, Train Loss: 0.3685\nEpoch 28/50, Batch 200/422, Train Loss: 0.4667\nEpoch 28/50, Batch 300/422, Train Loss: 0.5284\nEpoch 28/50, Batch 400/422, Train Loss: 0.3925\nModel CNN at epoch 28/50: Avg Train Loss: 0.4847, Avg Val Loss: 0.3111\nEpoch 29/50, Batch 0/422, Train Loss: 0.3149\nEpoch 29/50, Batch 100/422, Train Loss: 0.5621\nEpoch 29/50, Batch 200/422, Train Loss: 0.4215\nEpoch 29/50, Batch 300/422, Train Loss: 0.5191\nEpoch 29/50, Batch 400/422, Train Loss: 0.4134\nModel CNN at epoch 29/50: Avg Train Loss: 0.4904, Avg Val Loss: 0.2909\nEpoch 30/50, Batch 0/422, Train Loss: 0.3063\nEpoch 30/50, Batch 100/422, Train Loss: 0.4910\nEpoch 30/50, Batch 200/422, Train Loss: 0.4054\nEpoch 30/50, Batch 300/422, Train Loss: 0.4294\nEpoch 30/50, Batch 400/422, Train Loss: 0.4691\nModel CNN at epoch 30/50: Avg Train Loss: 0.4716, Avg Val Loss: 0.3143\nEpoch 31/50, Batch 0/422, Train Loss: 0.5904\nEpoch 31/50, Batch 100/422, Train Loss: 0.4259\nEpoch 31/50, Batch 200/422, Train Loss: 0.3185\nEpoch 31/50, Batch 300/422, Train Loss: 0.4530\nEpoch 31/50, Batch 400/422, Train Loss: 0.6300\nModel CNN at epoch 31/50: Avg Train Loss: 0.4746, Avg Val Loss: 0.2950\nEpoch 32/50, Batch 0/422, Train Loss: 0.4738\nEpoch 32/50, Batch 100/422, Train Loss: 0.3552\nEpoch 32/50, Batch 200/422, Train Loss: 0.4557\nEpoch 32/50, Batch 300/422, Train Loss: 0.4273\nEpoch 32/50, Batch 400/422, Train Loss: 0.2883\nModel CNN at epoch 32/50: Avg Train Loss: 0.4600, Avg Val Loss: 0.2755\nEpoch 33/50, Batch 0/422, Train Loss: 0.3415\nEpoch 33/50, Batch 100/422, Train Loss: 0.5817\nEpoch 33/50, Batch 200/422, Train Loss: 0.3615\nEpoch 33/50, Batch 300/422, Train Loss: 0.4219\nEpoch 33/50, Batch 400/422, Train Loss: 0.4566\nModel CNN at epoch 33/50: Avg Train Loss: 0.4579, Avg Val Loss: 0.2813\nEpoch 34/50, Batch 0/422, Train Loss: 0.3429\nEpoch 34/50, Batch 100/422, Train Loss: 0.3748\nEpoch 34/50, Batch 200/422, Train Loss: 0.5429\nEpoch 34/50, Batch 300/422, Train Loss: 0.4138\nEpoch 34/50, Batch 400/422, Train Loss: 0.4549\nModel CNN at epoch 34/50: Avg Train Loss: 0.4581, Avg Val Loss: 0.2934\nEpoch 35/50, Batch 0/422, Train Loss: 0.4158\nEpoch 35/50, Batch 100/422, Train Loss: 0.3607\nEpoch 35/50, Batch 200/422, Train Loss: 0.3699\nEpoch 35/50, Batch 300/422, Train Loss: 0.4755\nEpoch 35/50, Batch 400/422, Train Loss: 0.4399\nModel CNN at epoch 35/50: Avg Train Loss: 0.4563, Avg Val Loss: 0.2759\nEpoch 36/50, Batch 0/422, Train Loss: 0.3898\nEpoch 36/50, Batch 100/422, Train Loss: 0.5723\nEpoch 36/50, Batch 200/422, Train Loss: 0.4609\nEpoch 36/50, Batch 300/422, Train Loss: 0.6139\nEpoch 36/50, Batch 400/422, Train Loss: 0.3916\nModel CNN at epoch 36/50: Avg Train Loss: 0.4534, Avg Val Loss: 0.2627\nEpoch 37/50, Batch 0/422, Train Loss: 0.6310\nEpoch 37/50, Batch 100/422, Train Loss: 0.5480\nEpoch 37/50, Batch 200/422, Train Loss: 0.5648\nEpoch 37/50, Batch 300/422, Train Loss: 0.3860\nEpoch 37/50, Batch 400/422, Train Loss: 0.5367\nModel CNN at epoch 37/50: Avg Train Loss: 0.4462, Avg Val Loss: 0.2725\nEpoch 38/50, Batch 0/422, Train Loss: 0.4912\nEpoch 38/50, Batch 100/422, Train Loss: 0.4802\nEpoch 38/50, Batch 200/422, Train Loss: 0.5533\nEpoch 38/50, Batch 300/422, Train Loss: 0.5560\nEpoch 38/50, Batch 400/422, Train Loss: 0.4355\nModel CNN at epoch 38/50: Avg Train Loss: 0.4411, Avg Val Loss: 0.2910\nEpoch 39/50, Batch 0/422, Train Loss: 0.4258\nEpoch 39/50, Batch 100/422, Train Loss: 0.4088\nEpoch 39/50, Batch 200/422, Train Loss: 0.3664\nEpoch 39/50, Batch 300/422, Train Loss: 0.4035\nEpoch 39/50, Batch 400/422, Train Loss: 0.3550\nModel CNN at epoch 39/50: Avg Train Loss: 0.4420, Avg Val Loss: 0.2851\nEpoch 40/50, Batch 0/422, Train Loss: 0.5209\nEpoch 40/50, Batch 100/422, Train Loss: 0.4991\nEpoch 40/50, Batch 200/422, Train Loss: 0.3847\nEpoch 40/50, Batch 300/422, Train Loss: 0.4264\nEpoch 40/50, Batch 400/422, Train Loss: 0.3394\nModel CNN at epoch 40/50: Avg Train Loss: 0.4319, Avg Val Loss: 0.2872\nEpoch 41/50, Batch 0/422, Train Loss: 0.3160\nEpoch 41/50, Batch 100/422, Train Loss: 0.5508\nEpoch 41/50, Batch 200/422, Train Loss: 0.3226\nEpoch 41/50, Batch 300/422, Train Loss: 0.4600\nEpoch 41/50, Batch 400/422, Train Loss: 0.4819\nModel CNN at epoch 41/50: Avg Train Loss: 0.4318, Avg Val Loss: 0.2645\nEpoch 42/50, Batch 0/422, Train Loss: 0.4893\nEpoch 42/50, Batch 100/422, Train Loss: 0.3823\nEpoch 42/50, Batch 200/422, Train Loss: 0.6137\nEpoch 42/50, Batch 300/422, Train Loss: 0.3479\nEpoch 42/50, Batch 400/422, Train Loss: 0.3154\nModel CNN at epoch 42/50: Avg Train Loss: 0.4296, Avg Val Loss: 0.2782\nEpoch 43/50, Batch 0/422, Train Loss: 0.3659\nEpoch 43/50, Batch 100/422, Train Loss: 0.3557\nEpoch 43/50, Batch 200/422, Train Loss: 0.5471\nEpoch 43/50, Batch 300/422, Train Loss: 0.4942\nEpoch 43/50, Batch 400/422, Train Loss: 0.3763\nModel CNN at epoch 43/50: Avg Train Loss: 0.4227, Avg Val Loss: 0.2674\nEpoch 44/50, Batch 0/422, Train Loss: 0.4183\nEpoch 44/50, Batch 100/422, Train Loss: 0.3351\nEpoch 44/50, Batch 200/422, Train Loss: 0.4929\nEpoch 44/50, Batch 300/422, Train Loss: 0.2880\nEpoch 44/50, Batch 400/422, Train Loss: 0.4499\nModel CNN at epoch 44/50: Avg Train Loss: 0.4232, Avg Val Loss: 0.2486\nEpoch 45/50, Batch 0/422, Train Loss: 0.3861\nEpoch 45/50, Batch 100/422, Train Loss: 0.4013\nEpoch 45/50, Batch 200/422, Train Loss: 0.3169\nEpoch 45/50, Batch 300/422, Train Loss: 0.5061\nEpoch 45/50, Batch 400/422, Train Loss: 0.3661\nModel CNN at epoch 45/50: Avg Train Loss: 0.4119, Avg Val Loss: 0.2615\nEpoch 46/50, Batch 0/422, Train Loss: 0.4265\nEpoch 46/50, Batch 100/422, Train Loss: 0.3461\nEpoch 46/50, Batch 200/422, Train Loss: 0.4652\nEpoch 46/50, Batch 300/422, Train Loss: 0.5545\nEpoch 46/50, Batch 400/422, Train Loss: 0.3831\nModel CNN at epoch 46/50: Avg Train Loss: 0.4217, Avg Val Loss: 0.2715\nEpoch 47/50, Batch 0/422, Train Loss: 0.2880\nEpoch 47/50, Batch 100/422, Train Loss: 0.4254\nEpoch 47/50, Batch 200/422, Train Loss: 0.4702\nEpoch 47/50, Batch 300/422, Train Loss: 0.3644\nEpoch 47/50, Batch 400/422, Train Loss: 0.4249\nModel CNN at epoch 47/50: Avg Train Loss: 0.4199, Avg Val Loss: 0.2608\nEpoch 48/50, Batch 0/422, Train Loss: 0.3634\nEpoch 48/50, Batch 100/422, Train Loss: 0.2980\nEpoch 48/50, Batch 200/422, Train Loss: 0.4423\nEpoch 48/50, Batch 300/422, Train Loss: 0.4605\nEpoch 48/50, Batch 400/422, Train Loss: 0.4975\nModel CNN at epoch 48/50: Avg Train Loss: 0.4168, Avg Val Loss: 0.2483\nEpoch 49/50, Batch 0/422, Train Loss: 0.5798\nEpoch 49/50, Batch 100/422, Train Loss: 0.4099\nEpoch 49/50, Batch 200/422, Train Loss: 0.3008\nEpoch 49/50, Batch 300/422, Train Loss: 0.2947\nEpoch 49/50, Batch 400/422, Train Loss: 0.7095\nModel CNN at epoch 49/50: Avg Train Loss: 0.4053, Avg Val Loss: 0.2519\nEpoch 50/50, Batch 0/422, Train Loss: 0.5667\nEpoch 50/50, Batch 100/422, Train Loss: 0.3483\nEpoch 50/50, Batch 200/422, Train Loss: 0.4728\nEpoch 50/50, Batch 300/422, Train Loss: 0.3982\nEpoch 50/50, Batch 400/422, Train Loss: 0.3632\nModel CNN at epoch 50/50: Avg Train Loss: 0.4084, Avg Val Loss: 0.2534\nModel CNN took 164.67 minutes to run on 50 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate CNN on cluterred MNIST\ncnn_clutter_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:39:12.981145Z","iopub.execute_input":"2024-06-26T18:39:12.981604Z","iopub.status.idle":"2024-06-26T18:39:48.026720Z","shell.execute_reply.started":"2024-06-26T18:39:12.981557Z","shell.execute_reply":"2024-06-26T18:39:48.025582Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Test Accuracy for CNN: 0.9382 - in 34.404470443725586 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"####################\n### VAN Training ###\n####################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize VAN on MNIST\nvan_mnist = VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_mnist_optimizer = optim.AdamW(van_mnist.parameters(), lr=1e-3)\nvan_mnist_trainer = Trainer(model=van_mnist, optimizer=van_mnist_optimizer,\n                            train_loader=mnist_train_loader, val_loader=mnist_val_loader, test_loader=mnist_test_loader,\n                            num_epochs=25, save_checkpoints=True, path=f'VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:42:01.306757Z","iopub.execute_input":"2024-06-26T18:42:01.307281Z","iopub.status.idle":"2024-06-26T18:42:01.326928Z","shell.execute_reply.started":"2024-06-26T18:42:01.307236Z","shell.execute_reply":"2024-06-26T18:42:01.325684Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Train VAN on MNIST\nvan_mnist_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:47:10.468961Z","iopub.execute_input":"2024-06-26T15:47:10.469617Z","iopub.status.idle":"2024-06-26T15:53:59.117163Z","shell.execute_reply.started":"2024-06-26T15:47:10.469582Z","shell.execute_reply":"2024-06-26T15:53:59.116187Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/25, Batch 0/422, Train Loss: 2.2933\nEpoch 1/25, Batch 100/422, Train Loss: 0.1864\nEpoch 1/25, Batch 200/422, Train Loss: 0.0708\nEpoch 1/25, Batch 300/422, Train Loss: 0.1068\nEpoch 1/25, Batch 400/422, Train Loss: 0.0845\nModel VAN_MNIST at epoch 1/25: Avg Train Loss: 0.3051, Avg Val Loss: 0.0773\nEpoch 2/25, Batch 0/422, Train Loss: 0.2000\nEpoch 2/25, Batch 100/422, Train Loss: 0.1385\nEpoch 2/25, Batch 200/422, Train Loss: 0.1000\nEpoch 2/25, Batch 300/422, Train Loss: 0.0806\nEpoch 2/25, Batch 400/422, Train Loss: 0.0781\nModel VAN_MNIST at epoch 2/25: Avg Train Loss: 0.0605, Avg Val Loss: 0.0485\nEpoch 3/25, Batch 0/422, Train Loss: 0.0267\nEpoch 3/25, Batch 100/422, Train Loss: 0.0763\nEpoch 3/25, Batch 200/422, Train Loss: 0.0830\nEpoch 3/25, Batch 300/422, Train Loss: 0.0090\nEpoch 3/25, Batch 400/422, Train Loss: 0.0061\nModel VAN_MNIST at epoch 3/25: Avg Train Loss: 0.0433, Avg Val Loss: 0.0467\nEpoch 4/25, Batch 0/422, Train Loss: 0.0291\nEpoch 4/25, Batch 100/422, Train Loss: 0.0796\nEpoch 4/25, Batch 200/422, Train Loss: 0.0519\nEpoch 4/25, Batch 300/422, Train Loss: 0.0100\nEpoch 4/25, Batch 400/422, Train Loss: 0.0033\nModel VAN_MNIST at epoch 4/25: Avg Train Loss: 0.0330, Avg Val Loss: 0.0382\nEpoch 5/25, Batch 0/422, Train Loss: 0.0542\nEpoch 5/25, Batch 100/422, Train Loss: 0.0406\nEpoch 5/25, Batch 200/422, Train Loss: 0.0007\nEpoch 5/25, Batch 300/422, Train Loss: 0.0534\nEpoch 5/25, Batch 400/422, Train Loss: 0.0530\nModel VAN_MNIST at epoch 5/25: Avg Train Loss: 0.0281, Avg Val Loss: 0.0563\nEpoch 6/25, Batch 0/422, Train Loss: 0.0254\nEpoch 6/25, Batch 100/422, Train Loss: 0.0340\nEpoch 6/25, Batch 200/422, Train Loss: 0.0144\nEpoch 6/25, Batch 300/422, Train Loss: 0.0246\nEpoch 6/25, Batch 400/422, Train Loss: 0.0175\nModel VAN_MNIST at epoch 6/25: Avg Train Loss: 0.0230, Avg Val Loss: 0.0518\nEpoch 7/25, Batch 0/422, Train Loss: 0.0573\nEpoch 7/25, Batch 100/422, Train Loss: 0.0036\nEpoch 7/25, Batch 200/422, Train Loss: 0.0018\nEpoch 7/25, Batch 300/422, Train Loss: 0.0212\nEpoch 7/25, Batch 400/422, Train Loss: 0.0245\nModel VAN_MNIST at epoch 7/25: Avg Train Loss: 0.0216, Avg Val Loss: 0.0416\nEpoch 8/25, Batch 0/422, Train Loss: 0.0084\nEpoch 8/25, Batch 100/422, Train Loss: 0.0495\nEpoch 8/25, Batch 200/422, Train Loss: 0.0286\nEpoch 8/25, Batch 300/422, Train Loss: 0.0718\nEpoch 8/25, Batch 400/422, Train Loss: 0.0015\nModel VAN_MNIST at epoch 8/25: Avg Train Loss: 0.0197, Avg Val Loss: 0.0360\nEpoch 9/25, Batch 0/422, Train Loss: 0.0283\nEpoch 9/25, Batch 100/422, Train Loss: 0.0163\nEpoch 9/25, Batch 200/422, Train Loss: 0.0009\nEpoch 9/25, Batch 300/422, Train Loss: 0.0089\nEpoch 9/25, Batch 400/422, Train Loss: 0.0519\nModel VAN_MNIST at epoch 9/25: Avg Train Loss: 0.0171, Avg Val Loss: 0.0310\nEpoch 10/25, Batch 0/422, Train Loss: 0.0026\nEpoch 10/25, Batch 100/422, Train Loss: 0.0211\nEpoch 10/25, Batch 200/422, Train Loss: 0.0015\nEpoch 10/25, Batch 300/422, Train Loss: 0.0016\nEpoch 10/25, Batch 400/422, Train Loss: 0.0071\nModel VAN_MNIST at epoch 10/25: Avg Train Loss: 0.0155, Avg Val Loss: 0.0448\nEpoch 11/25, Batch 0/422, Train Loss: 0.0027\nEpoch 11/25, Batch 100/422, Train Loss: 0.0280\nEpoch 11/25, Batch 200/422, Train Loss: 0.0006\nEpoch 11/25, Batch 300/422, Train Loss: 0.0105\nEpoch 11/25, Batch 400/422, Train Loss: 0.0057\nModel VAN_MNIST at epoch 11/25: Avg Train Loss: 0.0142, Avg Val Loss: 0.0384\nEpoch 12/25, Batch 0/422, Train Loss: 0.0006\nEpoch 12/25, Batch 100/422, Train Loss: 0.0513\nEpoch 12/25, Batch 200/422, Train Loss: 0.0058\nEpoch 12/25, Batch 300/422, Train Loss: 0.0033\nEpoch 12/25, Batch 400/422, Train Loss: 0.0131\nModel VAN_MNIST at epoch 12/25: Avg Train Loss: 0.0148, Avg Val Loss: 0.0420\nEpoch 13/25, Batch 0/422, Train Loss: 0.0030\nEpoch 13/25, Batch 100/422, Train Loss: 0.0008\nEpoch 13/25, Batch 200/422, Train Loss: 0.0031\nEpoch 13/25, Batch 300/422, Train Loss: 0.0001\nEpoch 13/25, Batch 400/422, Train Loss: 0.0098\nModel VAN_MNIST at epoch 13/25: Avg Train Loss: 0.0119, Avg Val Loss: 0.0356\nEpoch 14/25, Batch 0/422, Train Loss: 0.0009\nEpoch 14/25, Batch 100/422, Train Loss: 0.0386\nEpoch 14/25, Batch 200/422, Train Loss: 0.0001\nEpoch 14/25, Batch 300/422, Train Loss: 0.0375\nEpoch 14/25, Batch 400/422, Train Loss: 0.0115\nModel VAN_MNIST at epoch 14/25: Avg Train Loss: 0.0098, Avg Val Loss: 0.0407\nEpoch 15/25, Batch 0/422, Train Loss: 0.0019\nEpoch 15/25, Batch 100/422, Train Loss: 0.0076\nEpoch 15/25, Batch 200/422, Train Loss: 0.0427\nEpoch 15/25, Batch 300/422, Train Loss: 0.0078\nEpoch 15/25, Batch 400/422, Train Loss: 0.0096\nModel VAN_MNIST at epoch 15/25: Avg Train Loss: 0.0138, Avg Val Loss: 0.0370\nEpoch 16/25, Batch 0/422, Train Loss: 0.0177\nEpoch 16/25, Batch 100/422, Train Loss: 0.0032\nEpoch 16/25, Batch 200/422, Train Loss: 0.0140\nEpoch 16/25, Batch 300/422, Train Loss: 0.0006\nEpoch 16/25, Batch 400/422, Train Loss: 0.0029\nModel VAN_MNIST at epoch 16/25: Avg Train Loss: 0.0082, Avg Val Loss: 0.0354\nEpoch 17/25, Batch 0/422, Train Loss: 0.0006\nEpoch 17/25, Batch 100/422, Train Loss: 0.0168\nEpoch 17/25, Batch 200/422, Train Loss: 0.0764\nEpoch 17/25, Batch 300/422, Train Loss: 0.0266\nEpoch 17/25, Batch 400/422, Train Loss: 0.0368\nModel VAN_MNIST at epoch 17/25: Avg Train Loss: 0.0111, Avg Val Loss: 0.0390\nEpoch 18/25, Batch 0/422, Train Loss: 0.0008\nEpoch 18/25, Batch 100/422, Train Loss: 0.0411\nEpoch 18/25, Batch 200/422, Train Loss: 0.0212\nEpoch 18/25, Batch 300/422, Train Loss: 0.0038\nEpoch 18/25, Batch 400/422, Train Loss: 0.0010\nModel VAN_MNIST at epoch 18/25: Avg Train Loss: 0.0096, Avg Val Loss: 0.0356\nEpoch 19/25, Batch 0/422, Train Loss: 0.0003\nEpoch 19/25, Batch 100/422, Train Loss: 0.0033\nEpoch 19/25, Batch 200/422, Train Loss: 0.0004\nEpoch 19/25, Batch 300/422, Train Loss: 0.0012\nEpoch 19/25, Batch 400/422, Train Loss: 0.0003\nModel VAN_MNIST at epoch 19/25: Avg Train Loss: 0.0087, Avg Val Loss: 0.0509\nEpoch 20/25, Batch 0/422, Train Loss: 0.0001\nEpoch 20/25, Batch 100/422, Train Loss: 0.0493\nEpoch 20/25, Batch 200/422, Train Loss: 0.0208\nEpoch 20/25, Batch 300/422, Train Loss: 0.0001\nEpoch 20/25, Batch 400/422, Train Loss: 0.0214\nModel VAN_MNIST at epoch 20/25: Avg Train Loss: 0.0101, Avg Val Loss: 0.0375\nEpoch 21/25, Batch 0/422, Train Loss: 0.0011\nEpoch 21/25, Batch 100/422, Train Loss: 0.0259\nEpoch 21/25, Batch 200/422, Train Loss: 0.0035\nEpoch 21/25, Batch 300/422, Train Loss: 0.0026\nEpoch 21/25, Batch 400/422, Train Loss: 0.0011\nModel VAN_MNIST at epoch 21/25: Avg Train Loss: 0.0029, Avg Val Loss: 0.0281\nEpoch 22/25, Batch 0/422, Train Loss: 0.0021\nEpoch 22/25, Batch 100/422, Train Loss: 0.0018\nEpoch 22/25, Batch 200/422, Train Loss: 0.0136\nEpoch 22/25, Batch 300/422, Train Loss: 0.0013\nEpoch 22/25, Batch 400/422, Train Loss: 0.0007\nModel VAN_MNIST at epoch 22/25: Avg Train Loss: 0.0019, Avg Val Loss: 0.0278\nEpoch 23/25, Batch 0/422, Train Loss: 0.0018\nEpoch 23/25, Batch 100/422, Train Loss: 0.0002\nEpoch 23/25, Batch 200/422, Train Loss: 0.0027\nEpoch 23/25, Batch 300/422, Train Loss: 0.0010\nEpoch 23/25, Batch 400/422, Train Loss: 0.0002\nModel VAN_MNIST at epoch 23/25: Avg Train Loss: 0.0011, Avg Val Loss: 0.0264\nEpoch 24/25, Batch 0/422, Train Loss: 0.0001\nEpoch 24/25, Batch 100/422, Train Loss: 0.0001\nEpoch 24/25, Batch 200/422, Train Loss: 0.0003\nEpoch 24/25, Batch 300/422, Train Loss: 0.0006\nEpoch 24/25, Batch 400/422, Train Loss: 0.0002\nModel VAN_MNIST at epoch 24/25: Avg Train Loss: 0.0010, Avg Val Loss: 0.0268\nEpoch 25/25, Batch 0/422, Train Loss: 0.0001\nEpoch 25/25, Batch 100/422, Train Loss: 0.0015\nEpoch 25/25, Batch 200/422, Train Loss: 0.0006\nEpoch 25/25, Batch 300/422, Train Loss: 0.0003\nEpoch 25/25, Batch 400/422, Train Loss: 0.0002\nModel VAN_MNIST at epoch 25/25: Avg Train Loss: 0.0007, Avg Val Loss: 0.0272\nModel VAN_MNIST took 6.80 minutes to run on 25 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate VAN on MNIST\nvan_mnist_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T15:53:59.118752Z","iopub.execute_input":"2024-06-26T15:53:59.119238Z","iopub.status.idle":"2024-06-26T15:54:01.613386Z","shell.execute_reply.started":"2024-06-26T15:53:59.119199Z","shell.execute_reply":"2024-06-26T15:54:01.612140Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN_MNIST: 0.9950 - in 2.4644970893859863 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize VAN on cluttered MNIST\nvan_clutter = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_clutter_optimizer = optim.AdamW(van_clutter.parameters(), lr=1e-3)\nvan_clutter_trainer = Trainer(model=van_clutter, optimizer=van_clutter_optimizer,\n                              train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                              num_epochs=50, save_checkpoints=True, path=f'VAN_CLUTTER(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:42:09.379776Z","iopub.execute_input":"2024-06-26T18:42:09.380664Z","iopub.status.idle":"2024-06-26T18:42:09.395807Z","shell.execute_reply.started":"2024-06-26T18:42:09.380630Z","shell.execute_reply":"2024-06-26T18:42:09.394927Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Train VAN on cluttered MNIST\nvan_clutter_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T18:42:12.472418Z","iopub.execute_input":"2024-06-26T18:42:12.473087Z","iopub.status.idle":"2024-06-26T21:39:58.780366Z","shell.execute_reply.started":"2024-06-26T18:42:12.473053Z","shell.execute_reply":"2024-06-26T21:39:58.779177Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/50, Batch 0/422, Train Loss: 2.3009\nEpoch 1/50, Batch 100/422, Train Loss: 1.6607\nEpoch 1/50, Batch 200/422, Train Loss: 0.5063\nEpoch 1/50, Batch 300/422, Train Loss: 0.2999\nEpoch 1/50, Batch 400/422, Train Loss: 0.2943\nModel VAN at epoch 1/50: Avg Train Loss: 0.8136, Avg Val Loss: 0.2378\nEpoch 2/50, Batch 0/422, Train Loss: 0.2080\nEpoch 2/50, Batch 100/422, Train Loss: 0.1794\nEpoch 2/50, Batch 200/422, Train Loss: 0.2417\nEpoch 2/50, Batch 300/422, Train Loss: 0.1559\nEpoch 2/50, Batch 400/422, Train Loss: 0.1892\nModel VAN at epoch 2/50: Avg Train Loss: 0.1625, Avg Val Loss: 0.1105\nEpoch 3/50, Batch 0/422, Train Loss: 0.0553\nEpoch 3/50, Batch 100/422, Train Loss: 0.0837\nEpoch 3/50, Batch 200/422, Train Loss: 0.1060\nEpoch 3/50, Batch 300/422, Train Loss: 0.0965\nEpoch 3/50, Batch 400/422, Train Loss: 0.1883\nModel VAN at epoch 3/50: Avg Train Loss: 0.1134, Avg Val Loss: 0.1002\nEpoch 4/50, Batch 0/422, Train Loss: 0.0479\nEpoch 4/50, Batch 100/422, Train Loss: 0.0534\nEpoch 4/50, Batch 200/422, Train Loss: 0.0537\nEpoch 4/50, Batch 300/422, Train Loss: 0.0717\nEpoch 4/50, Batch 400/422, Train Loss: 0.1215\nModel VAN at epoch 4/50: Avg Train Loss: 0.0931, Avg Val Loss: 0.0891\nEpoch 5/50, Batch 0/422, Train Loss: 0.0220\nEpoch 5/50, Batch 100/422, Train Loss: 0.0784\nEpoch 5/50, Batch 200/422, Train Loss: 0.0752\nEpoch 5/50, Batch 300/422, Train Loss: 0.0831\nEpoch 5/50, Batch 400/422, Train Loss: 0.1221\nModel VAN at epoch 5/50: Avg Train Loss: 0.0816, Avg Val Loss: 0.0753\nEpoch 6/50, Batch 0/422, Train Loss: 0.0292\nEpoch 6/50, Batch 100/422, Train Loss: 0.0448\nEpoch 6/50, Batch 200/422, Train Loss: 0.0232\nEpoch 6/50, Batch 300/422, Train Loss: 0.0903\nEpoch 6/50, Batch 400/422, Train Loss: 0.1099\nModel VAN at epoch 6/50: Avg Train Loss: 0.0710, Avg Val Loss: 0.0792\nEpoch 7/50, Batch 0/422, Train Loss: 0.0894\nEpoch 7/50, Batch 100/422, Train Loss: 0.0536\nEpoch 7/50, Batch 200/422, Train Loss: 0.0430\nEpoch 7/50, Batch 300/422, Train Loss: 0.0381\nEpoch 7/50, Batch 400/422, Train Loss: 0.0359\nModel VAN at epoch 7/50: Avg Train Loss: 0.0709, Avg Val Loss: 0.0688\nEpoch 8/50, Batch 0/422, Train Loss: 0.0262\nEpoch 8/50, Batch 100/422, Train Loss: 0.0676\nEpoch 8/50, Batch 200/422, Train Loss: 0.0854\nEpoch 8/50, Batch 300/422, Train Loss: 0.0586\nEpoch 8/50, Batch 400/422, Train Loss: 0.1461\nModel VAN at epoch 8/50: Avg Train Loss: 0.0633, Avg Val Loss: 0.0557\nEpoch 9/50, Batch 0/422, Train Loss: 0.0399\nEpoch 9/50, Batch 100/422, Train Loss: 0.0867\nEpoch 9/50, Batch 200/422, Train Loss: 0.0699\nEpoch 9/50, Batch 300/422, Train Loss: 0.1696\nEpoch 9/50, Batch 400/422, Train Loss: 0.0308\nModel VAN at epoch 9/50: Avg Train Loss: 0.0574, Avg Val Loss: 0.0561\nEpoch 10/50, Batch 0/422, Train Loss: 0.1171\nEpoch 10/50, Batch 100/422, Train Loss: 0.0382\nEpoch 10/50, Batch 200/422, Train Loss: 0.0745\nEpoch 10/50, Batch 300/422, Train Loss: 0.0352\nEpoch 10/50, Batch 400/422, Train Loss: 0.0226\nModel VAN at epoch 10/50: Avg Train Loss: 0.0558, Avg Val Loss: 0.0531\nEpoch 11/50, Batch 0/422, Train Loss: 0.0632\nEpoch 11/50, Batch 100/422, Train Loss: 0.0442\nEpoch 11/50, Batch 200/422, Train Loss: 0.1183\nEpoch 11/50, Batch 300/422, Train Loss: 0.0298\nEpoch 11/50, Batch 400/422, Train Loss: 0.0715\nModel VAN at epoch 11/50: Avg Train Loss: 0.0524, Avg Val Loss: 0.0465\nEpoch 12/50, Batch 0/422, Train Loss: 0.1089\nEpoch 12/50, Batch 100/422, Train Loss: 0.0403\nEpoch 12/50, Batch 200/422, Train Loss: 0.0901\nEpoch 12/50, Batch 300/422, Train Loss: 0.0624\nEpoch 12/50, Batch 400/422, Train Loss: 0.0703\nModel VAN at epoch 12/50: Avg Train Loss: 0.0519, Avg Val Loss: 0.0509\nEpoch 13/50, Batch 0/422, Train Loss: 0.0664\nEpoch 13/50, Batch 100/422, Train Loss: 0.0213\nEpoch 13/50, Batch 200/422, Train Loss: 0.0458\nEpoch 13/50, Batch 300/422, Train Loss: 0.0149\nEpoch 13/50, Batch 400/422, Train Loss: 0.0403\nModel VAN at epoch 13/50: Avg Train Loss: 0.0488, Avg Val Loss: 0.0737\nEpoch 14/50, Batch 0/422, Train Loss: 0.0212\nEpoch 14/50, Batch 100/422, Train Loss: 0.0041\nEpoch 14/50, Batch 200/422, Train Loss: 0.0440\nEpoch 14/50, Batch 300/422, Train Loss: 0.0435\nEpoch 14/50, Batch 400/422, Train Loss: 0.0541\nModel VAN at epoch 14/50: Avg Train Loss: 0.0472, Avg Val Loss: 0.0552\nEpoch 15/50, Batch 0/422, Train Loss: 0.0441\nEpoch 15/50, Batch 100/422, Train Loss: 0.0195\nEpoch 15/50, Batch 200/422, Train Loss: 0.0142\nEpoch 15/50, Batch 300/422, Train Loss: 0.0785\nEpoch 15/50, Batch 400/422, Train Loss: 0.0467\nModel VAN at epoch 15/50: Avg Train Loss: 0.0448, Avg Val Loss: 0.0506\nEpoch 16/50, Batch 0/422, Train Loss: 0.0190\nEpoch 16/50, Batch 100/422, Train Loss: 0.0556\nEpoch 16/50, Batch 200/422, Train Loss: 0.0060\nEpoch 16/50, Batch 300/422, Train Loss: 0.0600\nEpoch 16/50, Batch 400/422, Train Loss: 0.0529\nModel VAN at epoch 16/50: Avg Train Loss: 0.0438, Avg Val Loss: 0.0366\nEpoch 17/50, Batch 0/422, Train Loss: 0.0367\nEpoch 17/50, Batch 100/422, Train Loss: 0.0679\nEpoch 17/50, Batch 200/422, Train Loss: 0.1054\nEpoch 17/50, Batch 300/422, Train Loss: 0.0258\nEpoch 17/50, Batch 400/422, Train Loss: 0.0376\nModel VAN at epoch 17/50: Avg Train Loss: 0.0427, Avg Val Loss: 0.0562\nEpoch 18/50, Batch 0/422, Train Loss: 0.0143\nEpoch 18/50, Batch 100/422, Train Loss: 0.0688\nEpoch 18/50, Batch 200/422, Train Loss: 0.0143\nEpoch 18/50, Batch 300/422, Train Loss: 0.0267\nEpoch 18/50, Batch 400/422, Train Loss: 0.0280\nModel VAN at epoch 18/50: Avg Train Loss: 0.0417, Avg Val Loss: 0.0511\nEpoch 19/50, Batch 0/422, Train Loss: 0.0410\nEpoch 19/50, Batch 100/422, Train Loss: 0.0658\nEpoch 19/50, Batch 200/422, Train Loss: 0.0504\nEpoch 19/50, Batch 300/422, Train Loss: 0.0095\nEpoch 19/50, Batch 400/422, Train Loss: 0.0071\nModel VAN at epoch 19/50: Avg Train Loss: 0.0423, Avg Val Loss: 0.0397\nEpoch 20/50, Batch 0/422, Train Loss: 0.0061\nEpoch 20/50, Batch 100/422, Train Loss: 0.0073\nEpoch 20/50, Batch 200/422, Train Loss: 0.0210\nEpoch 20/50, Batch 300/422, Train Loss: 0.0171\nEpoch 20/50, Batch 400/422, Train Loss: 0.0213\nModel VAN at epoch 20/50: Avg Train Loss: 0.0373, Avg Val Loss: 0.0436\nEpoch 21/50, Batch 0/422, Train Loss: 0.0599\nEpoch 21/50, Batch 100/422, Train Loss: 0.0726\nEpoch 21/50, Batch 200/422, Train Loss: 0.0835\nEpoch 21/50, Batch 300/422, Train Loss: 0.0375\nEpoch 21/50, Batch 400/422, Train Loss: 0.0535\nModel VAN at epoch 21/50: Avg Train Loss: 0.0373, Avg Val Loss: 0.0494\nEpoch 22/50, Batch 0/422, Train Loss: 0.0826\nEpoch 22/50, Batch 100/422, Train Loss: 0.0304\nEpoch 22/50, Batch 200/422, Train Loss: 0.0472\nEpoch 22/50, Batch 300/422, Train Loss: 0.0486\nEpoch 22/50, Batch 400/422, Train Loss: 0.0080\nModel VAN at epoch 22/50: Avg Train Loss: 0.0361, Avg Val Loss: 0.0300\nEpoch 23/50, Batch 0/422, Train Loss: 0.0094\nEpoch 23/50, Batch 100/422, Train Loss: 0.0106\nEpoch 23/50, Batch 200/422, Train Loss: 0.0716\nEpoch 23/50, Batch 300/422, Train Loss: 0.0206\nEpoch 23/50, Batch 400/422, Train Loss: 0.0316\nModel VAN at epoch 23/50: Avg Train Loss: 0.0349, Avg Val Loss: 0.0395\nEpoch 24/50, Batch 0/422, Train Loss: 0.0038\nEpoch 24/50, Batch 100/422, Train Loss: 0.0037\nEpoch 24/50, Batch 200/422, Train Loss: 0.0045\nEpoch 24/50, Batch 300/422, Train Loss: 0.0740\nEpoch 24/50, Batch 400/422, Train Loss: 0.0515\nModel VAN at epoch 24/50: Avg Train Loss: 0.0347, Avg Val Loss: 0.0473\nEpoch 25/50, Batch 0/422, Train Loss: 0.0261\nEpoch 25/50, Batch 100/422, Train Loss: 0.0189\nEpoch 25/50, Batch 200/422, Train Loss: 0.0275\nEpoch 25/50, Batch 300/422, Train Loss: 0.0358\nEpoch 25/50, Batch 400/422, Train Loss: 0.0123\nModel VAN at epoch 25/50: Avg Train Loss: 0.0342, Avg Val Loss: 0.0465\nEpoch 26/50, Batch 0/422, Train Loss: 0.0786\nEpoch 26/50, Batch 100/422, Train Loss: 0.0396\nEpoch 26/50, Batch 200/422, Train Loss: 0.0296\nEpoch 26/50, Batch 300/422, Train Loss: 0.0044\nEpoch 26/50, Batch 400/422, Train Loss: 0.0205\nModel VAN at epoch 26/50: Avg Train Loss: 0.0342, Avg Val Loss: 0.0379\nEpoch 27/50, Batch 0/422, Train Loss: 0.0274\nEpoch 27/50, Batch 100/422, Train Loss: 0.1213\nEpoch 27/50, Batch 200/422, Train Loss: 0.0873\nEpoch 27/50, Batch 300/422, Train Loss: 0.0358\nEpoch 27/50, Batch 400/422, Train Loss: 0.0070\nModel VAN at epoch 27/50: Avg Train Loss: 0.0330, Avg Val Loss: 0.0431\nEpoch 28/50, Batch 0/422, Train Loss: 0.0420\nEpoch 28/50, Batch 100/422, Train Loss: 0.0129\nEpoch 28/50, Batch 200/422, Train Loss: 0.0092\nEpoch 28/50, Batch 300/422, Train Loss: 0.0139\nEpoch 28/50, Batch 400/422, Train Loss: 0.0268\nModel VAN at epoch 28/50: Avg Train Loss: 0.0329, Avg Val Loss: 0.0373\nEpoch 29/50, Batch 0/422, Train Loss: 0.0269\nEpoch 29/50, Batch 100/422, Train Loss: 0.0312\nEpoch 29/50, Batch 200/422, Train Loss: 0.0288\nEpoch 29/50, Batch 300/422, Train Loss: 0.0316\nEpoch 29/50, Batch 400/422, Train Loss: 0.0805\nModel VAN at epoch 29/50: Avg Train Loss: 0.0308, Avg Val Loss: 0.0378\nEpoch 30/50, Batch 0/422, Train Loss: 0.0375\nEpoch 30/50, Batch 100/422, Train Loss: 0.0412\nEpoch 30/50, Batch 200/422, Train Loss: 0.0223\nEpoch 30/50, Batch 300/422, Train Loss: 0.0487\nEpoch 30/50, Batch 400/422, Train Loss: 0.0526\nModel VAN at epoch 30/50: Avg Train Loss: 0.0319, Avg Val Loss: 0.0400\nEpoch 31/50, Batch 0/422, Train Loss: 0.0212\nEpoch 31/50, Batch 100/422, Train Loss: 0.0057\nEpoch 31/50, Batch 200/422, Train Loss: 0.0090\nEpoch 31/50, Batch 300/422, Train Loss: 0.0044\nEpoch 31/50, Batch 400/422, Train Loss: 0.0122\nModel VAN at epoch 31/50: Avg Train Loss: 0.0304, Avg Val Loss: 0.0303\nEpoch 32/50, Batch 0/422, Train Loss: 0.0249\nEpoch 32/50, Batch 100/422, Train Loss: 0.0031\nEpoch 32/50, Batch 200/422, Train Loss: 0.0319\nEpoch 32/50, Batch 300/422, Train Loss: 0.0511\nEpoch 32/50, Batch 400/422, Train Loss: 0.0511\nModel VAN at epoch 32/50: Avg Train Loss: 0.0298, Avg Val Loss: 0.0263\nEpoch 33/50, Batch 0/422, Train Loss: 0.0143\nEpoch 33/50, Batch 100/422, Train Loss: 0.0017\nEpoch 33/50, Batch 200/422, Train Loss: 0.0533\nEpoch 33/50, Batch 300/422, Train Loss: 0.0515\nEpoch 33/50, Batch 400/422, Train Loss: 0.0007\nModel VAN at epoch 33/50: Avg Train Loss: 0.0306, Avg Val Loss: 0.0308\nEpoch 34/50, Batch 0/422, Train Loss: 0.0115\nEpoch 34/50, Batch 100/422, Train Loss: 0.0557\nEpoch 34/50, Batch 200/422, Train Loss: 0.0008\nEpoch 34/50, Batch 300/422, Train Loss: 0.0348\nEpoch 34/50, Batch 400/422, Train Loss: 0.0132\nModel VAN at epoch 34/50: Avg Train Loss: 0.0279, Avg Val Loss: 0.0382\nEpoch 35/50, Batch 0/422, Train Loss: 0.0050\nEpoch 35/50, Batch 100/422, Train Loss: 0.0182\nEpoch 35/50, Batch 200/422, Train Loss: 0.0463\nEpoch 35/50, Batch 300/422, Train Loss: 0.1092\nEpoch 35/50, Batch 400/422, Train Loss: 0.0104\nModel VAN at epoch 35/50: Avg Train Loss: 0.0299, Avg Val Loss: 0.0373\nEpoch 36/50, Batch 0/422, Train Loss: 0.0207\nEpoch 36/50, Batch 100/422, Train Loss: 0.0167\nEpoch 36/50, Batch 200/422, Train Loss: 0.0022\nEpoch 36/50, Batch 300/422, Train Loss: 0.0032\nEpoch 36/50, Batch 400/422, Train Loss: 0.0863\nModel VAN at epoch 36/50: Avg Train Loss: 0.0260, Avg Val Loss: 0.0417\nEpoch 37/50, Batch 0/422, Train Loss: 0.0278\nEpoch 37/50, Batch 100/422, Train Loss: 0.0666\nEpoch 37/50, Batch 200/422, Train Loss: 0.0809\nEpoch 37/50, Batch 300/422, Train Loss: 0.0576\nEpoch 37/50, Batch 400/422, Train Loss: 0.0138\nModel VAN at epoch 37/50: Avg Train Loss: 0.0284, Avg Val Loss: 0.0384\nEpoch 38/50, Batch 0/422, Train Loss: 0.0214\nEpoch 38/50, Batch 100/422, Train Loss: 0.0034\nEpoch 38/50, Batch 200/422, Train Loss: 0.0506\nEpoch 38/50, Batch 300/422, Train Loss: 0.0179\nEpoch 38/50, Batch 400/422, Train Loss: 0.0797\nModel VAN at epoch 38/50: Avg Train Loss: 0.0274, Avg Val Loss: 0.0320\nEpoch 39/50, Batch 0/422, Train Loss: 0.0080\nEpoch 39/50, Batch 100/422, Train Loss: 0.0088\nEpoch 39/50, Batch 200/422, Train Loss: 0.0073\nEpoch 39/50, Batch 300/422, Train Loss: 0.0080\nEpoch 39/50, Batch 400/422, Train Loss: 0.0288\nModel VAN at epoch 39/50: Avg Train Loss: 0.0283, Avg Val Loss: 0.0419\nEpoch 40/50, Batch 0/422, Train Loss: 0.0218\nEpoch 40/50, Batch 100/422, Train Loss: 0.0611\nEpoch 40/50, Batch 200/422, Train Loss: 0.0211\nEpoch 40/50, Batch 300/422, Train Loss: 0.0161\nEpoch 40/50, Batch 400/422, Train Loss: 0.0286\nModel VAN at epoch 40/50: Avg Train Loss: 0.0273, Avg Val Loss: 0.0327\nEpoch 41/50, Batch 0/422, Train Loss: 0.0173\nEpoch 41/50, Batch 100/422, Train Loss: 0.0076\nEpoch 41/50, Batch 200/422, Train Loss: 0.0068\nEpoch 41/50, Batch 300/422, Train Loss: 0.0167\nEpoch 41/50, Batch 400/422, Train Loss: 0.0218\nModel VAN at epoch 41/50: Avg Train Loss: 0.0251, Avg Val Loss: 0.0318\nEpoch 42/50, Batch 0/422, Train Loss: 0.0109\nEpoch 42/50, Batch 100/422, Train Loss: 0.0131\nEpoch 42/50, Batch 200/422, Train Loss: 0.0406\nEpoch 42/50, Batch 300/422, Train Loss: 0.0003\nEpoch 42/50, Batch 400/422, Train Loss: 0.0017\nModel VAN at epoch 42/50: Avg Train Loss: 0.0235, Avg Val Loss: 0.0488\nEpoch 43/50, Batch 0/422, Train Loss: 0.0118\nEpoch 43/50, Batch 100/422, Train Loss: 0.0031\nEpoch 43/50, Batch 200/422, Train Loss: 0.0019\nEpoch 43/50, Batch 300/422, Train Loss: 0.0062\nEpoch 43/50, Batch 400/422, Train Loss: 0.0080\nModel VAN at epoch 43/50: Avg Train Loss: 0.0253, Avg Val Loss: 0.0285\nEpoch 44/50, Batch 0/422, Train Loss: 0.0080\nEpoch 44/50, Batch 100/422, Train Loss: 0.0126\nEpoch 44/50, Batch 200/422, Train Loss: 0.0410\nEpoch 44/50, Batch 300/422, Train Loss: 0.0254\nEpoch 44/50, Batch 400/422, Train Loss: 0.0048\nModel VAN at epoch 44/50: Avg Train Loss: 0.0173, Avg Val Loss: 0.0266\nEpoch 45/50, Batch 0/422, Train Loss: 0.0146\nEpoch 45/50, Batch 100/422, Train Loss: 0.0417\nEpoch 45/50, Batch 200/422, Train Loss: 0.0216\nEpoch 45/50, Batch 300/422, Train Loss: 0.0026\nEpoch 45/50, Batch 400/422, Train Loss: 0.0020\nModel VAN at epoch 45/50: Avg Train Loss: 0.0147, Avg Val Loss: 0.0238\nEpoch 46/50, Batch 0/422, Train Loss: 0.0034\nEpoch 46/50, Batch 100/422, Train Loss: 0.0930\nEpoch 46/50, Batch 200/422, Train Loss: 0.0046\nEpoch 46/50, Batch 300/422, Train Loss: 0.0178\nEpoch 46/50, Batch 400/422, Train Loss: 0.0094\nModel VAN at epoch 46/50: Avg Train Loss: 0.0144, Avg Val Loss: 0.0285\nEpoch 47/50, Batch 0/422, Train Loss: 0.0043\nEpoch 47/50, Batch 100/422, Train Loss: 0.0294\nEpoch 47/50, Batch 200/422, Train Loss: 0.0053\nEpoch 47/50, Batch 300/422, Train Loss: 0.0012\nEpoch 47/50, Batch 400/422, Train Loss: 0.0015\nModel VAN at epoch 47/50: Avg Train Loss: 0.0144, Avg Val Loss: 0.0244\nEpoch 48/50, Batch 0/422, Train Loss: 0.0006\nEpoch 48/50, Batch 100/422, Train Loss: 0.0379\nEpoch 48/50, Batch 200/422, Train Loss: 0.0011\nEpoch 48/50, Batch 300/422, Train Loss: 0.0590\nEpoch 48/50, Batch 400/422, Train Loss: 0.0178\nModel VAN at epoch 48/50: Avg Train Loss: 0.0140, Avg Val Loss: 0.0223\nEpoch 49/50, Batch 0/422, Train Loss: 0.0023\nEpoch 49/50, Batch 100/422, Train Loss: 0.0280\nEpoch 49/50, Batch 200/422, Train Loss: 0.0305\nEpoch 49/50, Batch 300/422, Train Loss: 0.0112\nEpoch 49/50, Batch 400/422, Train Loss: 0.0898\nModel VAN at epoch 49/50: Avg Train Loss: 0.0130, Avg Val Loss: 0.0251\nEpoch 50/50, Batch 0/422, Train Loss: 0.0251\nEpoch 50/50, Batch 100/422, Train Loss: 0.0064\nEpoch 50/50, Batch 200/422, Train Loss: 0.0245\nEpoch 50/50, Batch 300/422, Train Loss: 0.0002\nEpoch 50/50, Batch 400/422, Train Loss: 0.0020\nModel VAN at epoch 50/50: Avg Train Loss: 0.0133, Avg Val Loss: 0.0249\nModel VAN took 177.75 minutes to run on 50 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate VAN on cluttered MNIST\nvan_clutter_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:39:58.782584Z","iopub.execute_input":"2024-06-26T21:39:58.783064Z","iopub.status.idle":"2024-06-26T21:40:34.172364Z","shell.execute_reply.started":"2024-06-26T21:39:58.783019Z","shell.execute_reply":"2024-06-26T21:40:34.171306Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN: 0.9920 - in 35.359241247177124 seconds.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# #DO NOT TOUCH ANY CODE FROM ABOVE, EXCEPT COMMENTS!","metadata":{}},{"cell_type":"code","source":"# Get information about current runtime and package versions.\n\n# Check if CUDA is available\ncuda_available = torch.cuda.is_available()\n\n# Get CUDA device count\ncuda_device_count = torch.cuda.device_count() if cuda_available else 0\n\n# Get current CUDA device index\ncuda_device_index = torch.cuda.current_device() if cuda_available else None\n\n# Get name of current CUDA device\ncuda_device_name = torch.cuda.get_device_name(cuda_device_index) if cuda_available else None\n\n# Get CUDA capability of the device\ncuda_capability = torch.cuda.get_device_capability(cuda_device_index) if cuda_available else None\n\n# Get CUDA version\ncuda_version = torch.version.cuda if cuda_available else None\n\n# Get cuDNN version\ncudnn_version = torch.backends.cudnn.version() if cuda_available else None\n\n# Get PyTorch version\npytorch_version = torch.__version__\n\n# Get OS information\nos_info = platform.platform()\n\npython_version = platform.python_version()\n\n# Print the information\nenvironment_dict = {\"OS:\", os_info,\n                    \"GPU:\", cuda_device_name,\n                    \"PyTorch:\", pytorch_version,\n                    \"CUDA:\", cuda_version,\n                    \"cudnn:\", cudnn_version,\n                    \"Python Version:\", python_version\n                   }\nprint(\"OS:\", os_info)\nprint(\"GPU:\", cuda_device_name)\nprint(\"PyTorch:\", pytorch_version)\nprint(\"CUDA:\", cuda_version)\nprint(\"cudnn:\", cudnn_version)\nprint(\"Python Version:\", python_version)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:30:31.802624Z","iopub.execute_input":"2024-06-26T07:30:31.803571Z","iopub.status.idle":"2024-06-26T07:30:31.878658Z","shell.execute_reply.started":"2024-06-26T07:30:31.803531Z","shell.execute_reply":"2024-06-26T07:30:31.877683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze ","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:30:44.306299Z","iopub.execute_input":"2024-06-26T07:30:44.306693Z","iopub.status.idle":"2024-06-26T07:30:47.614988Z","shell.execute_reply.started":"2024-06-26T07:30:44.306659Z","shell.execute_reply":"2024-06-26T07:30:47.613861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###Import function for checkpoints!###","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper funtion to import models from a checkpoint\ndef import_model_from_ckpt(model:str, dataset:str ,path:str):\n    '''\n    Function to import models from a checkpoint.\n    The model and the dataset the model was trained on as well as the path to the checkpoint\n    need to be specified. Returns the model in the checkpoint state.\n    '''\n    ckpt = torch.load(path)\n    if (model == 'VAN' and dataset == 'MNIST'):\n        ckpt_model = VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\n    if (model == 'VAN' and dataset == 'cluttered_MNIST'):\n        ckpt_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4]) \n    if (model == 'CNN' and dataset == 'MNIST'):\n        ckpt_model = CNN_MNIST()\n    if (model == 'CNN' and dataset == 'cluttered_MNIST'):\n        ckpt_model = CNN()\n    ckpt_model.load_state_dict(ckpt['model_state_dict'])\n    \n    return ckpt_model","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:43:49.267962Z","iopub.execute_input":"2024-06-26T21:43:49.268365Z","iopub.status.idle":"2024-06-26T21:43:49.277303Z","shell.execute_reply.started":"2024-06-26T21:43:49.268324Z","shell.execute_reply":"2024-06-26T21:43:49.276178Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Import models for the upcoming comparisons to ensure reproducability as good as possible.\nvan_MNIST = import_model_from_ckpt('VAN', 'MNIST', '/kaggle/input/van/pytorch/mnist/1/VAN_MNIST(channels64 128 stages2 l1 1 expansion_ratio2 4).pth')\ncnn_MNIST = import_model_from_ckpt('CNN', 'MNIST', '/kaggle/working/CNN_MNIST().pth')\nvan = import_model_from_ckpt('VAN', 'cluttered_MNIST', '/kaggle/input/van/pytorch/cluttered_mnist/1/VAN_CLUTTER(channels64 128 stages2 l1 1 expansion_ratio2 4).pth')\ncnn = import_model_from_ckpt('CNN', 'cluttered_MNIST', '/kaggle/working/CNN_CLUTTER().pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:43:59.833219Z","iopub.execute_input":"2024-06-26T21:43:59.833589Z","iopub.status.idle":"2024-06-26T21:44:00.370497Z","shell.execute_reply.started":"2024-06-26T21:43:59.833558Z","shell.execute_reply":"2024-06-26T21:44:00.369341Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"ck = torch.load('/kaggle/working/CNN_MNIST().pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T22:17:16.749807Z","iopub.execute_input":"2024-06-26T22:17:16.750750Z","iopub.status.idle":"2024-06-26T22:17:16.771021Z","shell.execute_reply.started":"2024-06-26T22:17:16.750713Z","shell.execute_reply":"2024-06-26T22:17:16.770225Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"ck['test_accuracy']","metadata":{"execution":{"iopub.status.busy":"2024-06-26T22:17:40.982544Z","iopub.execute_input":"2024-06-26T22:17:40.982954Z","iopub.status.idle":"2024-06-26T22:17:40.989388Z","shell.execute_reply.started":"2024-06-26T22:17:40.982921Z","shell.execute_reply":"2024-06-26T22:17:40.988361Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"0.9905"},"metadata":{}}]},{"cell_type":"markdown","source":"**Create CMAPs to visualize the attention maps.**","metadata":{}},{"cell_type":"code","source":"# CMAP\n# reference: https://jacobgil.github.io/pytorch-gradcam-book/Class%20Activation%20Maps%20for%20Semantic%20Segmentation.html\n!pip install grad-cam # grad-cam-1.5.2","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:44:05.993494Z","iopub.execute_input":"2024-06-26T21:44:05.994237Z","iopub.status.idle":"2024-06-26T21:44:36.860245Z","shell.execute_reply.started":"2024-06-26T21:44:05.994204Z","shell.execute_reply":"2024-06-26T21:44:36.859164Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Collecting grad-cam\n  Downloading grad-cam-1.5.2.tar.gz (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from grad-cam) (9.5.0)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (2.1.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (0.16.2)\nCollecting ttach (from grad-cam)\n  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.66.1)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.9.0.80)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from grad-cam) (3.7.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->grad-cam) (2.31.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (2.8.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\nDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nBuilding wheels for collected packages: grad-cam\n  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.5.2-py3-none-any.whl size=38335 sha256=5106d9b819a09a350a451d6bd6e166d713bd84d38ee7f308d54f9dd7d0b99d05\n  Stored in directory: /root/.cache/pip/wheels/b4/68/bb/d10381e86dc0de1c9354bce3d86bffcd247305058c40ce2e55\nSuccessfully built grad-cam\nInstalling collected packages: ttach, grad-cam\nSuccessfully installed grad-cam-1.5.2 ttach-0.0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# Functions to create the acivation maps.\nimport cv2 #opencv-python==4.9.0.80\n\n\ndef get_gradcam(model, image, target_layer):\n    activations = []\n    gradients = []\n\n    def forward_hook(module, input, output):\n        activations.append(output)\n\n    def backward_hook(module, grad_in, grad_out):\n        gradients.append(grad_out[0])\n\n    # Register hooks\n    hook_handles = []\n    hook_handles.append(target_layer.register_forward_hook(forward_hook))\n    hook_handles.append(target_layer.register_backward_hook(backward_hook))\n\n    # Add batch dimension and prepare the input\n    image = img_tensor.unsqueeze(0).unsqueeze(0)  # shape: [1, 1, 28, 28]\n\n    # Forward pass\n    model.eval()\n    output = model(image)\n    pred_class = output.argmax(dim=1).item()\n\n    # Backward pass\n    model.zero_grad()\n    output[0, pred_class].backward()\n\n    # Remove hooks\n    for handle in hook_handles:\n        handle.remove()\n\n    # Get gradients and activations\n    gradients = gradients[0].cpu().data.numpy()[0]\n    activations = activations[0].cpu().data.numpy()[0]\n\n    # Compute weights\n    weights = np.mean(gradients, axis=(1, 2))\n    cam = np.zeros(activations.shape[1:], dtype=np.float32)\n    for i, w in enumerate(weights):\n        cam += w * activations[i]\n\n    cam = np.maximum(cam, 0)\n    cam = cv2.resize(cam, (image.shape[2], image.shape[3]))  # Resize to input image dimensions\n    cam = cam - np.min(cam)\n    cam = cam / np.max(cam)\n\n    return cam\n\n# Overlay the Grad-CAM on the original image\ndef overlay_cam_on_image(image, cam, alpha=0.4):\n    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_MAGMA)\n    heatmap = np.float32(heatmap) / 255\n    image = image.numpy().transpose(1, 2, 0)\n    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n    overlay = heatmap + np.float32(image)\n    overlay = overlay / np.max(overlay)\n    return np.uint8(255 * overlay)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:44:50.454505Z","iopub.execute_input":"2024-06-26T21:44:50.454894Z","iopub.status.idle":"2024-06-26T21:44:50.676836Z","shell.execute_reply.started":"2024-06-26T21:44:50.454843Z","shell.execute_reply":"2024-06-26T21:44:50.675912Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# GradCAM comparison of VAN and CNN on cluttered_MNIST\n# Set models into eval mode\nvan.eval()\ncnn.eval()\n# Define target layer (last convolutional layer) for each network and move models to cpu.\ntarget_layer_van = van.cpu().block_2[-1].FFN.conv3  \ntarget_layer_cnn = cnn.cpu().conv2","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:45:58.139656Z","iopub.execute_input":"2024-06-26T21:45:58.140044Z","iopub.status.idle":"2024-06-26T21:45:58.148377Z","shell.execute_reply.started":"2024-06-26T21:45:58.140012Z","shell.execute_reply":"2024-06-26T21:45:58.147469Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Create GradCAMs.\n# 539\nimg_id = 695 # Select image_id for GradCAM\naugmented_img, ground_truth = augmented_dataset_train[img_id]\naugmented_img = augmented_img.squeeze(0)\nimg_tensor = augmented_img\nimage = img_tensor.unsqueeze(0).to('cpu')\n\n'''\noutput = self.model(data)\n_, predicted = torch.max(output.data, 1)\n'''\n'''\noutput_van = van(image.unsqueeze(0))\n_, prediction_van = torch.max(output_van.data, 1)\noutput_cnn = cnn(image.unsqueeze(0))\n'''\ncam_van = get_gradcam(van, image, target_layer_van)\noverlay_van = overlay_cam_on_image(image, cam_van)\n\ncam_cnn = get_gradcam(cnn, image, target_layer_cnn)\noverlay_cnn = overlay_cam_on_image(image, cam_cnn)\n\n\n\n# Plot the results\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\naxes[0].imshow(overlay_van)\naxes[0].set_title('VAN')\naxes[0].annotate(f'VAN Prediction: {prediction_van}', xy=(1, -0.1))\naxes[0].axis('off')\naxes[1].imshow(overlay_cnn)\naxes[1].set_title('CNN')\naxes[1].axis('off')\n\nfig.suptitle('Side-by-Side Plots', fontsize=16)\nfig.text(0.5, 0.90, f'Ground Truth: {ground_truth}', ha='center', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:55:14.806023Z","iopub.execute_input":"2024-06-26T21:55:14.806712Z","iopub.status.idle":"2024-06-26T21:55:15.473802Z","shell.execute_reply.started":"2024-06-26T21:55:14.806678Z","shell.execute_reply":"2024-06-26T21:55:15.472685Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"F.softmax(output_van)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:46:36.083801Z","iopub.execute_input":"2024-06-26T21:46:36.084200Z","iopub.status.idle":"2024-06-26T21:46:36.105617Z","shell.execute_reply.started":"2024-06-26T21:46:36.084168Z","shell.execute_reply":"2024-06-26T21:46:36.104604Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/268539198.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  F.softmax(output_van)\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"tensor([[3.9278e-05, 3.3655e-05, 4.8638e-03, 3.3473e-05, 1.4629e-05, 2.2425e-04,\n         6.4202e-03, 3.8020e-06, 9.8836e-01, 5.6815e-06]],\n       grad_fn=<SoftmaxBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"F.softmax(output_van, dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:29:45.178444Z","iopub.execute_input":"2024-06-26T08:29:45.178837Z","iopub.status.idle":"2024-06-26T08:29:45.186111Z","shell.execute_reply.started":"2024-06-26T08:29:45.178808Z","shell.execute_reply":"2024-06-26T08:29:45.185244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:20:52.028095Z","iopub.execute_input":"2024-06-26T08:20:52.028881Z","iopub.status.idle":"2024-06-26T08:20:52.041441Z","shell.execute_reply.started":"2024-06-26T08:20:52.028847Z","shell.execute_reply":"2024-06-26T08:20:52.040499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m(image.unsqueeze(0)).sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:24:36.479229Z","iopub.execute_input":"2024-06-26T08:24:36.479666Z","iopub.status.idle":"2024-06-26T08:24:36.517719Z","shell.execute_reply.started":"2024-06-26T08:24:36.479634Z","shell.execute_reply":"2024-06-26T08:24:36.516557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m2 = CNN_MNIST()\nm2(image.unsqueeze(0))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:22:13.980128Z","iopub.execute_input":"2024-06-26T08:22:13.980828Z","iopub.status.idle":"2024-06-26T08:22:14.176817Z","shell.execute_reply.started":"2024-06-26T08:22:13.980793Z","shell.execute_reply":"2024-06-26T08:22:14.175276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_cnn","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:22:08.449494Z","iopub.execute_input":"2024-06-26T08:22:08.450411Z","iopub.status.idle":"2024-06-26T08:22:08.457093Z","shell.execute_reply.started":"2024-06-26T08:22:08.450378Z","shell.execute_reply":"2024-06-26T08:22:08.456144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compare the accuracy of the models**","metadata":{}},{"cell_type":"code","source":"# Function to load checkpoints\ndef load_ckpt(path: str):\n    '''\n    Loads checkpoint from given path.\n    '''    \n    return torch.load(path)\n\n# Load checkpoints\nvan_ckpt = load_ckpt('/kaggle/working/VAN_CLUTTER(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4]).pth')\ncnn_ckpt = load_ckpt('/kaggle/working/CNN_CLUTTER().pth')\nvan_MNIST_ckpt = load_ckpt('/kaggle/working/VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4]).pth')\ncnn_MNIST_ckpt = load_ckpt('/kaggle/working/CNN_MNIST().pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T22:19:16.876774Z","iopub.execute_input":"2024-06-26T22:19:16.877205Z","iopub.status.idle":"2024-06-26T22:19:17.143266Z","shell.execute_reply.started":"2024-06-26T22:19:16.877169Z","shell.execute_reply":"2024-06-26T22:19:17.142266Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_MNIST_ckpt['running_loss_train']\nvan_MNIST_ckpt['running_loss_test']\nvan_MNIST_ckpt['test_accuracy']\nvan_MNIST_ckpt['train_time']\nvan_MNIST_ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:08:27.897839Z","iopub.execute_input":"2024-06-26T10:08:27.898556Z","iopub.status.idle":"2024-06-26T10:08:27.904409Z","shell.execute_reply.started":"2024-06-26T10:08:27.898498Z","shell.execute_reply":"2024-06-26T10:08:27.903559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Train and Validation Loss for models\n# Funciton to plot losses\ndef plot_loss(train_loss, val_loss):\n    '''\n    Function to plot the train and validation losses during training.\n    '''\n    epochs = range(1, len(train_loss) + 1)\n    plt.plot(epochs, train_loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n# VAN on MNIST\nplot_loss(van_MNIST_ckpt['running_loss_train'], van_MNIST_ckpt['running_loss_val'])\n# VAN on cluttered MNIST\nplot_loss(van_ckpt['running_loss_train'], van_ckpt['running_loss_val'])\n# CNN on MNIST\nplot_loss(cnn_MNIST_ckpt['running_loss_train'], cnn_MNIST_ckpt['running_loss_val'])\n# CNN on cluterred MNIST\nplot_loss(cnn_ckpt['running_loss_train'], cnn_ckpt['running_loss_val'])","metadata":{"execution":{"iopub.status.busy":"2024-06-26T10:12:42.942403Z","iopub.execute_input":"2024-06-26T10:12:42.943290Z","iopub.status.idle":"2024-06-26T10:12:43.262211Z","shell.execute_reply.started":"2024-06-26T10:12:42.943255Z","shell.execute_reply":"2024-06-26T10:12:43.260846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare the Test Accuracy\nimport pandas as pd #pandas==2.1.4\n\nmodels = ['VAN_MNIST', 'CNN_MNIST', 'VAN', 'CNN']\nvalues = [van_MNIST_ckpt['test_accuracy'], cnn_MNIST_ckpt['test_accuracy'],\n          van_ckpt['test_accuracy'], cnn_ckpt['test_accuracy']]\naccuracy_df = pd.DataFrame({'Model': models,\n                            'Accuracy': values})\nprint(accuracy_df.to_string(index=False))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T22:19:45.865795Z","iopub.execute_input":"2024-06-26T22:19:45.866753Z","iopub.status.idle":"2024-06-26T22:19:45.876315Z","shell.execute_reply.started":"2024-06-26T22:19:45.866715Z","shell.execute_reply":"2024-06-26T22:19:45.875123Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"    Model  Accuracy\nVAN_MNIST    0.9950\nCNN_MNIST    0.9905\n      VAN    0.9920\n      CNN    0.9382\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Computational Cost Comparison**","metadata":{}},{"cell_type":"code","source":"# Compare number of parameters\ndef count_params(model):\n    '''\n    Funciton that returns the number of trainable parameters and the total number of parameters.\n    '''\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    \n    return trainable_params, total_paramas\n# VAN\nvan_trainable_params, van_total_params = count_params()\nprint('Trainable Parameters VAN: '\"{:,}\".format(van_trainable_params), 'Total Parameters VAN: '\"{:,}\".format(van_total_params))\n# CNN\ncnn_trainable_params, cnn_total_params = count_params()\nprint('Trainable Parameters CNN: '\"{:,}\".format(cnn_trainable_params), 'Total Parameters CNN: '\"{:,}\".format(cnn_total_params))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T22:19:55.230428Z","iopub.execute_input":"2024-06-26T22:19:55.231123Z","iopub.status.idle":"2024-06-26T22:19:55.274092Z","shell.execute_reply.started":"2024-06-26T22:19:55.231086Z","shell.execute_reply":"2024-06-26T22:19:55.272908Z"},"trusted":true},"execution_count":69,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[69], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainable_params, total_paramas\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# VAN\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m van_trainable_params, van_total_params \u001b[38;5;241m=\u001b[39m \u001b[43mcount_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainable Parameters VAN: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:,}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(van_trainable_params), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Parameters VAN: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:,}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(van_total_params))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# CNN\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: count_params() missing 1 required positional argument: 'model'"],"ename":"TypeError","evalue":"count_params() missing 1 required positional argument: 'model'","output_type":"error"}]},{"cell_type":"code","source":"# Compare number of modueles\ndef count_modules(model):\n    '''\n    Function that returns the number of modules in a network.\n    '''\n    num_modules = sum(1 for _ in model.modules())\n    return num_modules\n\nvan_num_modules = count_modules()\ncnn_num_modules = count_modules()\n\nprint(\"Number of modules in VAN:\", van_num_modules)\nprint(\"Number of modules in CNN:\", cnn_num_modules)","metadata":{"id":"6a5e_FegAoGs","executionInfo":{"status":"ok","timestamp":1711019998475,"user_tz":-60,"elapsed":336,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"85dbf9d1-b18e-46b1-b7d1-4ff66b5b309c","execution":{"iopub.status.busy":"2024-03-21T11:39:11.847181Z","iopub.execute_input":"2024-03-21T11:39:11.847897Z","iopub.status.idle":"2024-03-21T11:39:11.924267Z","shell.execute_reply.started":"2024-03-21T11:39:11.847864Z","shell.execute_reply":"2024-03-21T11:39:11.923437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use deepspeed profiler to estimate FLOPS, MACS and Latency\n!pip install deepspeed\nfrom deepspeed.profiling.flops_profiler import FlopsProfiler","metadata":{"id":"5npplbR9v-vu","outputId":"3c1e8282-709e-4771-ae20-ee0d3d59ae2c","execution":{"iopub.status.busy":"2024-03-26T18:06:35.292615Z","iopub.execute_input":"2024-03-26T18:06:35.293076Z","iopub.status.idle":"2024-03-26T18:07:19.351944Z","shell.execute_reply.started":"2024-03-26T18:06:35.293044Z","shell.execute_reply":"2024-03-26T18:07:19.350905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = VAN(num_classes=14, stages=2, channels=[64, 128], image_channels=3, l=[1,1], expansion_ratio=[2,4])\nprofile_model(input_model=m1, data_loader=pc_train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:52:16.531727Z","iopub.execute_input":"2024-03-25T17:52:16.532454Z","iopub.status.idle":"2024-03-25T17:52:19.048782Z","shell.execute_reply.started":"2024-03-25T17:52:16.532421Z","shell.execute_reply":"2024-03-25T17:52:19.047886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def profile_model(model, data_loader=train_loader):\n    '''\n    Function that uses the deepspeed profiler.\n    Uses a short warum-up stage and profiles at batch_idx = 50.\n    '''\n    # Profile a model to get the FLOPS and Latency\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n    prof = FlopsProfiler(model)\n    # Profile at step 50 to warmup\n    profile_step = 50\n    for batch_idx, (data, target) in enumerate(data_loader):\n      if batch_idx == profile_step:\n        prof.start_profile()\n\n      data, target = data.to(device), target.to(device)\n      optimizer.zero_grad()\n      output = model(data)\n      loss = criterion(output, target)\n\n      if batch_idx == profile_step:\n        prof.stop_profile()\n        flops = prof.get_total_flops()\n        macs = prof.get_total_macs()\n        params = prof.get_total_params()\n        prof.print_model_profile(profile_step=profile_step)\n        prof.end_profile()\n\n      loss.backward()\n      optimizer.step()\n\n      if batch_idx == profile_step:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:47:37.606860Z","iopub.execute_input":"2024-03-25T17:47:37.607618Z","iopub.status.idle":"2024-03-25T17:47:37.616235Z","shell.execute_reply.started":"2024-03-25T17:47:37.607586Z","shell.execute_reply":"2024-03-25T17:47:37.615214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FLOPs for VAN\nfor data, target in augmented_loader:\n  input_data, input_target = data.to(device), target.to(device)\n  break\n\nflops_van, params = profile(van, inputs=(input_data,))\nprint(f'Estimated Params for VAN:, {(\"{:,}\".format(params))}')\nprint(f'Estimated FLOPs for VAN:, {(\"{:,}\".format(flops_van))}')","metadata":{"id":"zqHb0WdSA3Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for Baseline CNN\n\n# Define your model and input data\nbaseline = BaselineCNN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = baseline(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"6vf3Yhg3BFbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for VAN\n\n# Define your model and input data\nvan = VAN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = van(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"jvtS_uZKBFSo"},"execution_count":null,"outputs":[]}]}