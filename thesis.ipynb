{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Xi9z2tGsLgV_OMGB36wWYdspsBzsG8Sb","authorship_tag":"ABX9TyPua6D/VG55KQLJKEi/Yp89"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook contains the empirical study regarding the attention mechanism.","metadata":{}},{"cell_type":"markdown","source":"______________\n# FINAL STEPS:\n* Train networks on MNIST for X epochs\n* Train networks for augmented MNIST for X epochs\n* Ablation Study (VAN without LKA)\n* Compare Computational Costs (Deepspeed Profiler?)\n - Training time\n - Number of Modules\n - Number of parameters\n - FLOPs\n ","metadata":{}},{"cell_type":"code","source":"# Installation and import of relevant packages\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nimport platform\nimport random\nimport time\nimport torch\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import v2\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.profiler import profile, record_function, ProfilerActivity","metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1711009733593,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"hj481hNsaSLk","execution":{"iopub.status.busy":"2024-06-21T17:21:34.000597Z","iopub.execute_input":"2024-06-21T17:21:34.000885Z","iopub.status.idle":"2024-06-21T17:21:40.242506Z","shell.execute_reply.started":"2024-06-21T17:21:34.000859Z","shell.execute_reply":"2024-06-21T17:21:40.241706Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Get information about current runtime and package versions.\n\n# Check if CUDA is available\ncuda_available = torch.cuda.is_available()\n\n# Get CUDA device count\ncuda_device_count = torch.cuda.device_count() if cuda_available else 0\n\n# Get current CUDA device index\ncuda_device_index = torch.cuda.current_device() if cuda_available else None\n\n# Get name of current CUDA device\ncuda_device_name = torch.cuda.get_device_name(cuda_device_index) if cuda_available else None\n\n# Get CUDA capability of the device\ncuda_capability = torch.cuda.get_device_capability(cuda_device_index) if cuda_available else None\n\n# Get CUDA version\ncuda_version = torch.version.cuda if cuda_available else None\n\n# Get cuDNN version\ncudnn_version = torch.backends.cudnn.version() if cuda_available else None\n\n# Get PyTorch version\npytorch_version = torch.__version__\n\n# Get OS information\nos_info = platform.platform()\n\npython_version = platform.python_version()\n\n# Print the information\nenvironment_dict = {\"OS:\", os_info,\n                    \"GPU:\", cuda_device_name,\n                    \"PyTorch:\", pytorch_version,\n                    \"CUDA:\", cuda_version,\n                    \"cudnn:\", cudnn_version,\n                    \"Python Version:\", python_version\n                   }\nprint(\"OS:\", os_info)\nprint(\"GPU:\", cuda_device_name)\nprint(\"PyTorch:\", pytorch_version)\nprint(\"CUDA:\", cuda_version)\nprint(\"cudnn:\", cudnn_version)\nprint(\"Python Version:\", python_version)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:22:53.217453Z","iopub.execute_input":"2024-06-21T17:22:53.218399Z","iopub.status.idle":"2024-06-21T17:22:53.284980Z","shell.execute_reply.started":"2024-06-21T17:22:53.218362Z","shell.execute_reply":"2024-06-21T17:22:53.284074Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"OS: Linux-5.15.133+-x86_64-with-glibc2.31\nGPU: Tesla P100-PCIE-16GB\nPyTorch: 2.1.2\nCUDA: 12.1\ncudnn: 8900\nPython Version: 3.10.13\n","output_type":"stream"}]},{"cell_type":"code","source":"# List package versions\n!pip freeze","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:03:32.639253Z","iopub.execute_input":"2024-06-21T17:03:32.640323Z","iopub.status.idle":"2024-06-21T17:03:36.390366Z","shell.execute_reply.started":"2024-06-21T17:03:32.640279Z","shell.execute_reply":"2024-06-21T17:03:36.388914Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"absl-py==1.4.0\naccelerate==0.27.2\naccess==1.1.9\naffine==2.4.0\naiobotocore==2.11.2\naiofiles==22.1.0\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1701099469104/work\naiohttp-cors==0.7.0\naioitertools==0.11.0\naiorwlock==1.3.0\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1667935791922/work\naiosqlite==0.19.0\nalbumentations==1.4.0\nalembic==1.13.1\naltair==5.2.0\nannotated-types==0.6.0\nannoy==1.17.3\nanyio @ file:///home/conda/feedstock_root/build_artifacts/anyio_1702909220329/work\napache-beam==2.46.0\naplus==0.11.0\nappdirs==1.4.4\narchspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386546427/work\narray-record==0.5.0\narrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\narviz==0.17.0\nastroid==3.0.3\nastropy==6.0.0\nastropy-iers-data==0.2024.2.19.0.28.47\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\nastunparse==1.6.3\nasync-lru==2.0.4\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1691763562544/work\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1704011227531/work\naudioread==3.0.1\nautopep8==2.0.4\nBabel==2.14.0\nbackoff==2.2.1\nbayesian-optimization==1.4.3\nbayespy==0.5.28\nbeatrix_jupyterlab @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-cpu_1704939196367/work/packages/beatrix_jupyterlab-2023.128.151533.tar.gz#sha256=8c6941d08ce18f5b9ea7719574d611c18163074ff8254e0734342014eb064a48\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1680888073205/work\nbidict==0.23.1\nbiopython==1.83\nblake3==0.2.1\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\nblessed==1.20.0\nblinker==1.7.0\nblis==0.7.11\nblosc2==2.5.1\nbokeh==3.3.4\nboltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\nBoruta==0.3\nboto3==1.26.100\nbotocore==1.34.34\nbq_helper==0.4.1\nbqplot==0.12.43\nbranca==0.7.1\nbrewer2mpl==1.4.1\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\nbrotlipy==0.7.0\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\ncachetools==4.2.4\nCartopy @ file:///home/conda/feedstock_root/build_artifacts/cartopy_1698172724393/work\ncatalogue==2.0.10\ncatalyst @ git+https://github.com/Philmod/catalyst.git@9420384a98c4b9d3b17b959e66f845b98457b545\ncatboost==1.2.2\ncategory-encoders==2.6.3\ncertifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1707022139797/work/certifi\ncesium==0.12.1\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\nchex==0.1.85\ncleverhans==4.0.0\nclick==8.1.7\nclick-plugins==1.1.1\ncligj==0.7.2\ncloud-tpu-client==0.10\ncloud-tpu-profiler==2.4.0\ncloudpathlib==0.16.0\ncloudpickle==2.2.1\ncmdstanpy==1.2.1\ncmudict==1.0.18\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\ncolorcet==3.0.1\ncolorful==0.5.6\ncolorlog==6.8.2\ncolorlover==0.3.0\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1704278392174/work\nconda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\nconda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1702406360642/work/src\nconda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\nconda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\nconfection==0.1.4\ncontextily==1.5.0\ncontourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1699041363598/work\nconvertdate==2.4.0\ncrcmod==1.7\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1701563205069/work\ncufflinks==0.17.3\nCVXcanon==0.1.2\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\ncymem==2.0.8\ncysignals==1.11.4\nCython==3.0.8\ncytoolz==0.12.3\ndaal==2024.1.0\ndaal4py==2024.1.0\ndacite==1.8.1\ndask==2024.2.0\ndataclasses-json==0.6.4\ndataproc_jupyter_plugin==0.1.66\ndatasets==2.1.0\ndatashader==0.16.0\ndatatile==1.0.3\ndb-dtypes==1.2.0\ndeap==1.4.1\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1695534290310/work\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\ndeepdiff==6.7.1\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\nDelorean==1.0.0\nDeprecated==1.2.14\ndeprecation==2.1.0\ndescartes==1.1.0\ndill==0.3.8\ndipy==1.8.0\ndistlib==0.3.8\ndistro @ file:///home/conda/feedstock_root/build_artifacts/distro_1704321475663/work\ndm-tree==0.1.8\ndocker==7.0.0\ndocker-pycreds==0.4.0\ndocopt==0.6.2\ndocstring-parser==0.15\ndocstring-to-markdown==0.15\ndocutils==0.20.1\nearthengine-api==0.1.391\neasydict==1.12\neasyocr==1.7.1\necos==2.0.13\neli5==0.13.0\nemoji==2.10.1\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl#sha256=ab70aeb6172cde82508f7739f35ebc9918a3d07debeed637403c8f794ba3d3dc\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\nephem==4.1.5\nesda==2.5.1\nessentia==2.1b6.dev1110\net-xmlfile==1.1.0\netils==1.6.0\nexceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\nexplainable-ai-sdk==1.3.3\nFarama-Notifications==0.0.4\nfastai==2.7.14\nfastapi==0.108.0\nfastavro==1.9.3\nfastcore==1.5.29\nfastdownload==0.0.7\nfasteners==0.19\nfastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1703780968325/work/dist\nfastprogress==1.0.3\nfasttext==0.9.2\nfbpca==1.0\nfeather-format==0.4.1\nfeaturetools==1.29.0\nfilelock==3.13.1\nfiona==1.9.5\nfitter==1.7.0\nflake8==7.0.0\nflashtext==2.7\nFlask==3.0.2\nflatbuffers==23.5.26\nflax==0.8.1\nfolium==0.15.1\nfonttools==4.47.0\nfqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\nfrozendict==2.4.0\nfrozenlist @ file:///home/conda/feedstock_root/build_artifacts/frozenlist_1702645481127/work\nfsspec==2024.2.0\nfuncy==2.0\nfury==0.9.0\nfuture==1.0.0\nfuzzywuzzy==0.18.0\ngast==0.5.4\ngatspy==0.3\ngcsfs==2023.12.2.post1\ngensim==4.3.2\ngeographiclib==2.0\nGeohash==1.0\ngeojson==3.1.0\ngeopandas==0.14.3\ngeoplot==0.5.1\ngeopy==2.4.1\ngeoviews==1.11.1\nggplot @ https://github.com/hbasria/ggpy/archive/0.11.5.zip#sha256=7df947ba3fd86d3757686afec264785ad8df38dc50ffb2d2d31064fb355f69b1\ngiddy==2.3.5\ngitdb==4.0.11\nGitPython==3.1.41\ngoogle-ai-generativelanguage==0.4.0\ngoogle-api-core==2.11.1\ngoogle-api-python-client==2.118.0\ngoogle-apitools==0.5.31\ngoogle-auth==2.26.1\ngoogle-auth-httplib2==0.1.1\ngoogle-auth-oauthlib==1.2.0\ngoogle-cloud-aiplatform==0.6.0a1\ngoogle-cloud-artifact-registry==1.10.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==2.34.4\ngoogle-cloud-bigtable==1.7.3\ngoogle-cloud-core==2.4.1\ngoogle-cloud-datastore==1.15.5\ngoogle-cloud-dlp==3.14.0\ngoogle-cloud-jupyter-config==0.0.5\ngoogle-cloud-language==2.13.1\ngoogle-cloud-monitoring==2.18.0\ngoogle-cloud-pubsub==2.19.0\ngoogle-cloud-pubsublite==1.9.0\ngoogle-cloud-recommendations-ai==0.7.1\ngoogle-cloud-resource-manager==1.11.0\ngoogle-cloud-spanner==3.40.1\ngoogle-cloud-storage==1.44.0\ngoogle-cloud-translate==3.12.1\ngoogle-cloud-videointelligence==2.13.1\ngoogle-cloud-vision==2.8.0\ngoogle-crc32c==1.5.0\ngoogle-generativeai==0.3.2\ngoogle-pasta==0.2.0\ngoogle-resumable-media==2.7.0\ngoogleapis-common-protos==1.62.0\ngplearn==0.4.2\ngpustat==1.0.0\ngpxpy==1.6.2\ngraphviz==0.20.1\ngreenlet==3.0.3\ngrpc-google-iam-v1==0.12.7\ngrpcio==1.60.0\ngrpcio-status @ file:///home/conda/feedstock_root/build_artifacts/grpcio-status_1662108958711/work\ngviz-api==1.10.0\ngym==0.26.2\ngym-notices==0.0.8\ngymnasium==0.29.0\nh11==0.14.0\nh2o==3.44.0.3\nh5netcdf==1.3.0\nh5py==3.10.0\nhaversine==2.8.1\nhdfs==2.7.3\nhep-ml==0.7.2\nhijri-converter==2.3.1\nhmmlearn==0.3.0\nholidays==0.24\nholoviews==1.18.3\nhpsklearn==0.1.0\nhtml5lib==1.1\nhtmlmin==0.1.12\nhttpcore==1.0.4\nhttplib2==0.21.0\nhttptools==0.6.1\nhttpx==0.27.0\nhuggingface-hub==0.20.3\nhumanize==4.9.0\nhunspell==0.5.5\nhusl==4.0.3\nhydra-slayer==0.5.0\nhyperopt==0.2.7\nhypertools==0.8.0\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1701026962277/work\nigraph==0.11.4\nimagecodecs==2024.1.1\nImageHash==4.3.1\nimageio==2.33.1\nimbalanced-learn==0.12.0\nimgaug==0.4.0\nimportlib-metadata==6.11.0\nimportlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1699364556997/work\ninequality==1.0.1\niniconfig==2.0.0\nipydatawidgets==4.3.5\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1703631723894/work\nipyleaflet==0.18.2\nipympl==0.7.0\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1704718870316/work\nipython-genutils==0.2.0\nipython-sql==0.5.0\nipyvolume==0.6.3\nipyvue==1.10.1\nipyvuetify==1.8.10\nipywebrtc==0.6.0\nipywidgets==7.7.1\nisoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\nisort==5.13.2\nisoweek==1.3.3\nitsdangerous==2.1.2\nJanome==0.5.0\njaraco.classes==3.3.0\njax==0.4.24\njax-jumpy==1.0.0\njaxlib==0.4.24\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\njeepney==0.8.0\njieba==0.42.1\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1654302431367/work\njmespath==1.0.1\njoblib==1.3.2\njson5==0.9.14\njsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\njsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1700159890288/work\njsonschema-specifications @ file:///tmp/tmpkv1z7p57/src\njupyter-console==6.6.3\njupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1699285872613/work\njupyter-http-over-ws==0.0.8\njupyter-lsp==1.5.1\njupyter-server-mathjax==0.2.6\njupyter-ydoc==0.2.5\njupyter_client==7.4.9\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1704727030956/work\njupyter_server==2.12.5\njupyter_server_fileid==0.9.1\njupyter_server_proxy==4.1.0\njupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1703611053195/work\njupyter_server_ydoc==0.8.0\njupyterlab==4.1.2\njupyterlab-lsp==5.0.3\njupyterlab-widgets==3.0.9\njupyterlab_git==0.44.0\njupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1700744013163/work\njupyterlab_server==2.25.2\njupytext==1.16.0\nkaggle==1.6.6\nkaggle-environments==1.14.3\nkagglehub==0.1.9\nkeras==3.0.5\nkeras-cv==0.8.2\nkeras-nlp==0.8.1\nkeras-tuner==1.4.6\nkernels-mixer==0.0.7\nkeyring==24.3.0\nkeyrings.google-artifactregistry-auth==1.1.2\nkfp==2.5.0\nkfp-pipeline-spec==0.2.2\nkfp-server-api==2.0.5\nkiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379902431/work\nkmapper==2.0.1\nkmodes==0.12.2\nkorean-lunar-calendar==0.3.1\nkornia==0.7.1\nkt-legacy==1.0.5\nkubernetes==26.1.0\nlangcodes==3.3.0\nlangid==1.1.6\nlazy_loader==0.3\nlearntools @ git+https://github.com/Kaggle/learntools@183cdad0530e7c898cd4658a63b579c54e91f056\nleven==1.0.4\nLevenshtein==0.25.0\nlibclang==16.0.6\nlibmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1703178593403/work/libmambapy\nlibpysal==4.9.2\nlibrosa==0.10.1\nlightgbm==4.2.0\nlightning-utilities==0.10.1\nlime==0.2.0.1\nline-profiler==4.1.2\nlinkify-it-py==2.0.3\nllvmlite==0.41.1\nlml==0.1.0\nlocket==1.0.0\nloguru==0.7.2\nLunarCalendar==0.0.9\nlxml==5.1.0\nlz4==4.3.3\nMako==1.3.2\nmamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1703178593403/work/mamba\nmapclassify==2.6.1\nmarisa-trie==1.1.0\nMarkdown==3.5.2\nmarkdown-it-py==3.0.0\nmarkovify==0.9.4\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1695367434228/work\nmarshmallow==3.20.2\nmatplotlib==3.7.5\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work\nmatplotlib-venn==0.11.10\nmccabe==0.7.0\nmdit-py-plugins==0.4.0\nmdurl==0.1.2\nmemory-profiler==0.61.0\nmenuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\nmercantile==1.2.1\nmgwr==2.2.1\nmissingno==0.5.2\nmistune==0.8.4\nmizani==0.11.0\nml-dtypes==0.2.0\nmlcrate==0.2.0\nmlens==0.2.3\nmlxtend==0.23.1\nmmh3==4.1.0\nmne==1.6.1\nmnist==0.2.2\nmock==5.1.0\nmomepy==0.7.0\nmore-itertools==10.2.0\nmpld3==0.5.10\nmpmath==1.3.0\nmsgpack==1.0.7\nmsgpack-numpy==0.4.8\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1696716075096/work\nmultimethod==1.10\nmultipledispatch==1.0.0\nmultiprocess==0.70.16\nmunkres==1.1.4\nmurmurhash==1.0.10\nmypy-extensions==1.0.0\nnamex==0.0.7\nnb-conda-kernels @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_kernels_1699980974206/work\nnb_conda @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_1704789357480/work\nnbclassic @ file:///home/conda/feedstock_root/build_artifacts/nbclassic_1683202081046/work\nnbclient==0.5.13\nnbconvert==6.4.5\nnbdime==3.2.0\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1690814868471/work\nndindex==1.8\nnest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1697083700168/work\nnetworkx==3.2.1\nnibabel==5.2.0\nnilearn==0.10.3\nninja==1.11.1.1\nnltk==3.2.4\nnose==1.3.7\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1680870634737/work\nnotebook_executor @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-cpu_1704939196367/work/packages/notebook_executor\nnotebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1682360583588/work\nnumba==0.58.1\nnumexpr==2.9.0\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\nnvidia-ml-py==11.495.46\noauth2client==4.1.3\noauthlib==3.2.2\nobjsize==0.6.1\nodfpy==1.4.1\nolefile==0.47\nonnx==1.15.0\nopencensus==0.11.4\nopencensus-context==0.1.3\nopencv-contrib-python==4.9.0.80\nopencv-python==4.9.0.80\nopencv-python-headless==4.9.0.80\nopenpyxl==3.1.2\nopenslide-python==1.3.1\nopentelemetry-api==1.22.0\nopentelemetry-exporter-otlp==1.22.0\nopentelemetry-exporter-otlp-proto-common==1.22.0\nopentelemetry-exporter-otlp-proto-grpc==1.22.0\nopentelemetry-exporter-otlp-proto-http==1.22.0\nopentelemetry-proto==1.22.0\nopentelemetry-sdk==1.22.0\nopentelemetry-semantic-conventions==0.43b0\nopt-einsum==3.3.0\noptax==0.1.9\noptuna==3.5.0\norbax-checkpoint==0.5.3\nordered-set==4.1.0\norderedmultidict==1.0.1\norjson==3.9.10\nortools==9.4.1874\nosmnx==1.9.1\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1691338815398/work\npackaging==21.3\npandas==2.2.0\npandas-datareader==0.10.0\npandas-profiling==3.6.6\npandas-summary==0.2.0\npandasql==0.7.3\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\npanel==1.3.8\npapermill==2.5.0\nparam==2.0.2\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\npartd==1.4.1\npath==16.10.0\npath.py==12.5.0\npathos==0.3.2\npatsy==0.5.6\npdf2image==1.17.0\npettingzoo==1.24.0\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1667297516076/work\nphik==0.12.4\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\nPillow==9.5.0\npkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\nplatformdirs==4.2.0\nplotly==5.18.0\nplotly-express==0.4.1\nplotnine==0.13.0\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\npointpats==2.4.0\npolars==0.20.10\npolyglot==16.7.4\npooch==1.8.1\npox==0.3.4\nppca==0.0.4\nppft==1.7.6.8\npreprocessing==0.1.13\npreshed==3.0.9\nprettytable==3.9.0\nprogressbar2==4.3.2\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1700579315247/work\npromise==2.3\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1702399386289/work\npronouncing==0.2.0\nprophet==1.1.1\nproto-plus==1.23.0\nprotobuf==3.20.3\npsutil==5.9.3\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\npudb==2024.1\nPuLP==2.8.0\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\npy-cpuinfo==9.0.0\npy-spy==0.3.14\npy4j==0.10.9.7\npyaml==23.12.0\nPyArabic==0.6.15\npyarrow==15.0.0\npyasn1 @ file:///home/conda/feedstock_root/build_artifacts/pyasn1_1701287008248/work\npyasn1-modules @ file:///home/conda/feedstock_root/build_artifacts/pyasn1-modules_1695107857548/work\nPyAstronomy==0.20.0\npybind11==2.11.1\npyclipper==1.3.0.post5\npycodestyle==2.11.1\npycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\npycryptodome==3.20.0\npyct==0.5.0\npydantic==2.5.3\npydantic_core==2.14.6\npydegensac==0.1.2\npydicom==2.4.4\npydocstyle==6.3.0\npydot==1.4.2\npydub==0.25.1\npyemd==1.0.0\npyerfa==2.0.1.1\npyexcel-io==0.6.6\npyexcel-ods==0.6.0\npyfasttext==0.4.6\npyflakes==3.2.0\npygltflib==1.16.1\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1700607939962/work\nPyJWT==2.8.0\npykalman==0.9.5\npyLDAvis==3.4.1\npylint==3.0.3\npymc3==3.11.4\nPyMeeus==0.5.12\npymongo==3.13.0\nPympler==1.0.1\npynndescent==0.5.11\npyocr==0.8.5\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1698795453264/work\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1690737849915/work\npypdf==4.0.2\npyproj @ file:///home/conda/feedstock_root/build_artifacts/pyproj_1702028071709/work\npysal==24.1\npyshp @ file:///home/conda/feedstock_root/build_artifacts/pyshp_1659002966020/work\nPySocks @ file:///home/builder/ci_310/pysocks_1640793678128/work\npytesseract==0.3.10\npytest==8.0.1\npython-bidi==0.4.2\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\npython-dotenv==1.0.0\npython-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\npython-Levenshtein==0.25.0\npython-louvain==0.16\npython-lsp-jsonrpc==1.1.2\npython-lsp-server==1.10.0\npython-slugify==8.0.4\npython-utils==3.8.2\npythreejs==2.4.2\npytoolconfig==1.3.1\npytorch-ignite==0.4.13\npytorch-lightning==2.2.0.post0\npytz==2023.3.post1\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\nPyUpSet==0.1.1.post7\npyviz_comms==3.0.1\nPyWavelets==1.5.0\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1695373428874/work\npyzmq==24.0.1\nqgrid==1.3.1\nqtconsole==5.5.1\nQtPy==2.4.1\nquantecon==0.7.1\nquantities==0.15.0\nqudida==0.0.4\nrapidfuzz==3.6.1\nrasterio==1.3.9\nrasterstats==0.19.0\nray==2.9.0\nray-cpp==2.9.0\nreferencing @ file:///home/conda/feedstock_root/build_artifacts/referencing_1704489226496/work\nregex==2023.12.25\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\nrequests-oauthlib==1.3.1\nrequests-toolbelt==0.10.1\nresponses==0.18.0\nretrying==1.3.3\nrfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\nrfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\nrgf-python==3.12.0\nrich==13.7.0\nrich-click==1.7.3\nrope==1.12.0\nrpds-py @ file:///home/conda/feedstock_root/build_artifacts/rpds-py_1703822618592/work\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1658328885051/work\nRtree==1.2.0\nruamel-yaml-conda @ file:///home/builder/ci_310/ruamel_yaml_1640794439226/work\nruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1699007337104/work\nruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\ns2sphere==0.2.5\ns3fs==2024.2.0\ns3transfer==0.6.2\nsafetensors==0.4.2\nscattertext==0.1.19\nscikit-image==0.22.0\nscikit-learn==1.2.2\nscikit-learn-intelex==2024.1.0\nscikit-multilearn==0.2.0\nscikit-optimize==0.9.0\nscikit-plot==0.3.7\nscikit-surprise==1.1.3\nscipy==1.11.4\nseaborn==0.12.2\nSecretStorage==3.3.3\nsegment_anything @ git+https://github.com/facebookresearch/segment-anything.git@6fdee8f2727f4506cfbbe553e23b895e27956588\nsegregation==2.5\nsemver==3.0.2\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1682601222253/work\nsentencepiece==0.2.0\nsentry-sdk==1.40.5\nsetproctitle==1.3.3\nsetuptools-git==1.2\nsetuptools-scm==8.0.4\nshap==0.44.1\nShapely==1.8.5.post1\nShimmy==1.3.0\nsimpervisor==1.0.0\nSimpleITK==2.3.1\nsimplejson==3.19.2\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\nsklearn-pandas==2.2.0\nslicer==0.0.7\nsmart-open==6.4.0\nsmhasher==0.150.1\nsmmap==5.0.1\nsniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1662051266223/work\nsnowballstemmer==2.2.0\nsnuggs==1.4.7\nsoundfile==0.12.1\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\nsoxr==0.3.7\nspacy==3.7.4\nspacy-legacy==3.0.12\nspacy-loggers==1.0.5\nspaghetti==1.7.5.post1\nspectral==0.23.1\nspglm==1.1.0\nsphinx-rtd-theme==0.2.4\nspint==1.0.7\nsplot==1.1.5.post1\nspopt==0.6.0\nspreg==1.4.2\nspvcm==0.3.0\nSQLAlchemy==2.0.25\nsqlparse==0.4.4\nsquarify==0.4.3\nsrsly==2.4.8\nstable-baselines3==2.1.0\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\nstanio==0.3.0\nstarlette==0.32.0.post1\nstatsmodels==0.14.1\nstemming==1.0.1\nstop-words==2018.7.23\nstopit==1.1.2\nstumpy==1.12.0\nsympy==1.12\ntables==3.9.2\ntabulate==0.9.0\ntangled-up-in-unicode==0.2.0\ntbb==2021.11.0\ntenacity==8.2.3\ntensorboard==2.15.1\ntensorboard-data-server==0.7.2\ntensorboard-plugin-profile==2.15.0\ntensorboardX==2.6.2.2\ntensorflow==2.15.0\ntensorflow-cloud==0.1.16\ntensorflow-datasets==4.9.4\ntensorflow-decision-forests==1.8.1\ntensorflow-estimator==2.15.0\ntensorflow-hub==0.16.1\ntensorflow-io==0.35.0\ntensorflow-io-gcs-filesystem==0.35.0\ntensorflow-metadata==0.14.0\ntensorflow-probability==0.23.0\ntensorflow-serving-api==2.14.1\ntensorflow-text==2.15.0\ntensorflow-transform==0.14.0\ntensorpack==0.11\ntensorstore==0.1.53\ntermcolor==2.4.0\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1699810101464/work\ntestpath==0.6.0\ntext-unidecode==1.3\ntextblob==0.18.0.post0\ntexttable==1.7.0\ntf-keras==2.15.0\ntfp-nightly @ git+https://github.com/tensorflow/probability.git@fbc5ebe9b1d343113fb917010096cfd88b32eecf\nTheano==1.0.5\nTheano-PyMC==1.1.2\nthinc==8.2.3\nthreadpoolctl==3.2.0\ntifffile==2023.12.9\ntimm==0.9.16\ntinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1666100256010/work\ntobler==0.11.2\ntokenizers==0.15.2\ntoml==0.10.2\ntomli==2.0.1\ntomlkit==0.12.3\ntoolz==0.12.1\ntorch==2.1.2+cpu\ntorchaudio==2.1.2+cpu\ntorchdata==0.7.1\ntorchinfo==1.8.0\ntorchmetrics==1.3.1\ntorchtext==0.16.2+cpu\ntorchvision==0.16.2+cpu\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1695373560918/work\nTPOT==0.12.1\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1691671248568/work\ntraceml==1.0.8\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1675110562325/work\ntraittypes==0.2.1\ntransformers==4.38.1\ntrueskill==0.4.5\ntruststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\ntrx-python==0.2.9\ntsfresh==0.20.2\ntypeguard==4.1.5\ntyper==0.9.0\ntypes-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1704512562698/work\ntyping-inspect==0.9.0\ntyping-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1702176139754/work\ntzdata==2023.4\ntzlocal==5.2\nuc-micro-py==1.0.3\nujson==5.9.0\numap-learn==0.5.5\nunicodedata2 @ file:///home/conda/feedstock_root/build_artifacts/unicodedata2_1695847980273/work\nUnidecode==1.3.8\nupdate-checker==0.18.0\nuri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\nuritemplate==3.0.1\nurllib3==1.26.18\nurwid==2.6.4\nurwid_readline==0.13\nuvicorn==0.25.0\nuvloop==0.19.0\nvaex==4.17.0\nvaex-astro==0.9.3\nvaex-core==4.17.1\nvaex-hdf5==0.14.1\nvaex-jupyter==0.8.2\nvaex-ml==0.18.3\nvaex-server==0.9.0\nvaex-viz==0.5.4\nvec_noise==1.1.4\nvecstack==0.4.0\nvirtualenv==20.21.0\nvisions==0.7.5\nvowpalwabbit==9.9.0\nvtk==9.3.0\nWand==0.6.13\nwandb==0.16.3\nwasabi==1.1.2\nwatchfiles==0.21.0\nwavio==0.0.8\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\nweasel==0.3.4\nwebcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1679900785843/work\nwebencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\nwebsocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1701630677416/work\nwebsockets==12.0\nWerkzeug==3.0.1\nwfdb==4.1.2\nwhatthepatch==1.0.5\nwidgetsnbextension==3.6.6\nwitwidget==1.8.1\nwoodwork==0.28.0\nwordcloud==1.9.3\nwordsegment==1.3.1\nwrapt==1.14.1\nxarray==2024.2.0\nxarray-einstats==0.7.0\nxgboost==2.0.3\nxvfbwrapper==0.2.9\nxxhash==3.4.1\nxyzservices==2023.10.1\ny-py==0.6.2\nyapf==0.40.2\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1701168553642/work\nydata-profiling==4.6.4\nyellowbrick==1.5\nypy-websocket==0.8.4\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1695255097490/work\nzstandard==0.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"######################################\n### CREATE CLUTTERED MNIST DATASET ###\n######################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Transformation classes\n\nclass RandomPlacement(object):\n  def __call__(self, img):\n    canvas = torch.zeros(1,100,100)\n    x = torch.randint(0, 73, (1,))\n    y = torch.randint(0, 73, (1,))\n    canvas[:, x:x+28, y:y+28] = img\n\n    return canvas\n\nclass RandomCropAndCombine(object):\n  def __init__(self, dataset):\n    self.dataset = dataset\n\n  def __call__(self, canvas):\n    for _ in range(8):\n      img, _ = random.choice(self.dataset)\n      img = transforms.ToTensor()(img)\n      x = torch.randint(0, 91, (1,))\n      y = torch.randint(0, 91, (1,))\n      patch = transforms.RandomCrop((9,9))(img)\n      canvas[:, x:x+9, y:y+9] += patch\n      canvas = canvas.clamp(0, 1)\n\n    return canvas","metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1711009738485,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"YM6ay7S8Vu6-","execution":{"iopub.status.busy":"2024-06-21T17:23:11.777918Z","iopub.execute_input":"2024-06-21T17:23:11.778622Z","iopub.status.idle":"2024-06-21T17:23:11.794066Z","shell.execute_reply.started":"2024-06-21T17:23:11.778590Z","shell.execute_reply":"2024-06-21T17:23:11.793181Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Create cluttered MNIST dataset, split datasets and create DataLoaders.\n\n# Set seed for reproducability\ntorch.manual_seed(1)\nnp.random.seed(1)\ngenerator = torch.Generator().manual_seed(1)\n\n# Set batch size parameter\nBATCH_SIZE = 128\n\n# Define data transformations\noriginal_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\nmnist_original = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=None)\naugmented_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,)),\n    #transforms.RandomRotation(30),\n    RandomPlacement(),\n    RandomCropAndCombine(mnist_original),\n])\n\n# Train datasets\nmnist_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=original_transform)\naugmented_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=augmented_transform)\n\n# Test datasets\naugmented_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=augmented_transform)\nmnist_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=original_transform)\n\n# Split train dataset into 90% train and 10% validation data\nmnist_train, mnist_val = torch.utils.data.random_split(dataset=mnist_dataset_train, lengths=[0.9, 0.1], generator=generator)\naugmented_train, augmented_val = torch.utils.data.random_split(dataset=augmented_dataset_train, lengths=[0.9, 0.1], generator=generator)\n\n# Create data loaders for original and augmented datasets\n\n# Load train data\nmnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=BATCH_SIZE, shuffle=True)\ntrain_loader = torch.utils.data.DataLoader(dataset=augmented_train, batch_size=BATCH_SIZE, shuffle=True)\n# Load validation data\nmnist_val_loader = torch.utils.data.DataLoader(dataset=mnist_val, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset=augmented_val, batch_size=BATCH_SIZE, shuffle=True)\n# Load test data\ntest_loader = torch.utils.data.DataLoader(dataset=augmented_dataset_test, batch_size=BATCH_SIZE, shuffle=False)\nmnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_dataset_test, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:44:35.719318Z","iopub.execute_input":"2024-06-21T17:44:35.719980Z","iopub.status.idle":"2024-06-21T17:44:35.953180Z","shell.execute_reply.started":"2024-06-21T17:44:35.719946Z","shell.execute_reply":"2024-06-21T17:44:35.952170Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Plot the original and the augmented dataset\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\nfor i in range(4):\n  original_img, _ = mnist_original[i]\n  original_img = transforms.ToTensor()(original_img).squeeze(0)\n  axes[0, i].imshow(original_img, cmap='gray')\n  axes[0, i].axis('off')\n  axes[0, i].set_title('Original')\n\n  augmented_img, _ = augmented_dataset_train[i]\n  augmented_img = augmented_img.squeeze(0)\n  axes[1, i].imshow(augmented_img, cmap='gray')\n  axes[1, i].axis('off')\n  axes[1, i].set_title('Transformed')\n    \nplt.tight_layout()\nplt.show()","metadata":{"executionInfo":{"elapsed":822,"status":"ok","timestamp":1711014574594,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"kGbbSYiscR-9","outputId":"94d74291-72ba-4227-c66c-289378c48520","execution":{"iopub.status.busy":"2024-06-21T17:37:52.610244Z","iopub.execute_input":"2024-06-21T17:37:52.611002Z","iopub.status.idle":"2024-06-21T17:37:53.569416Z","shell.execute_reply.started":"2024-06-21T17:37:52.610968Z","shell.execute_reply":"2024-06-21T17:37:53.568483Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 8 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"###############################################################\n### Helper Trainer Class to faciliate training the networks ###\n###############################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer():\n    def __init__(self, model, optimizer, train_loader, val_loader, test_loader,\n                 num_epochs, estimate_step=100, save_checkpoints=True, path='model'):\n        \n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n        self.criterion = nn.CrossEntropyLoss()\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.num_epochs = num_epochs\n        self.estimate_step = estimate_step\n        self.model_name = type(self.model).__name__\n        self.path = path\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.save_checkpoints = save_checkpoints\n        self.running_loss_train = []\n        self.running_loss_val = []\n        self.train_time_per_epoch = []\n        self.total_epochs_trained = 0\n        self.test_accuracy = None\n        self.inference_time = None\n\n    \n    def train(self):\n        '''\n        Function to train the model. Trains the model on a training dataset and evaluates the current performance\n        on a validation dataset at the end of each epoch. Reduces the learning rate, if there is no\n        improvement in the validation loss for 10 epochs. \n        '''\n        self.model.to(self.device)\n        self.model.train()\n        for epoch in range(self.num_epochs):\n            # Start timer\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            start_epoch = time.time()\n            \n            # Training process for one epoch\n            self.model.train(True)\n            running_loss_train = 0.00\n            for batch_idx, (data, target) in enumerate(self.train_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                self.optimizer.zero_grad(set_to_none=True)\n                output = self.model(data)\n                loss = self.criterion(output, target)\n                running_loss_train += loss.item()\n                loss.backward()\n                self.optimizer.step()\n                if batch_idx % self.estimate_step == 0:\n                    print(f'Epoch {epoch+1}/{self.num_epochs}, Batch {batch_idx}/{len(self.train_loader)}, Train Loss: {loss.item():.4f}')     \n            avg_loss_train = running_loss_train / len(self.train_loader)\n            self.running_loss_train.append(avg_loss_train)\n            \n            # Validate model at the end of each epoch\n            self.model.eval()\n            running_loss_val = 0.00\n            with torch.no_grad():\n                for i, (data_val, target_val) in enumerate(self.val_loader):\n                    data_val, target_val = data_val.to(self.device), target_val.to(self.device)\n                    output_val = self.model(data_val)\n                    loss_val = self.criterion(output_val, target_val)\n                    running_loss_val += loss_val.item()\n                avg_loss_val = running_loss_val / len(self.val_loader)\n                self.running_loss_val.append(avg_loss_val)\n            \n            # Recuce LR if model does not improve for 10 epochs\n            self.scheduler.step(avg_loss_val)\n            \n            # Track training time for each epoch\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            end_epoch = time.time()\n            self.train_time_per_epoch.append(end_epoch-start_epoch)\n            print(f'Model {self.model_name} at epoch {epoch+1}/{self.num_epochs}: Avg Train Loss: {avg_loss_train:.4f}, Avg Val Loss: {avg_loss_val:.4f}')\n            \n            # Increase epoch counter\n            self.total_epochs_trained += 1\n            \n            # Save checkpoint at the end of each epoch\n            if self.save_checkpoints:\n                self.save_checkpoint(self.path)\n            \n        # Print total training time at the end\n        train_time = \"{:.2f} minutes\".format(sum(self.train_time_per_epoch) / 60)\n        print(f'Model {self.model_name} took {train_time} to run on {self.total_epochs_trained} epochs.')\n        \n                \n    def eval(self):\n        '''\n        Function to evaluate the performance of the model.\n        Therefore, the models accuracy on a test dataset is measured.\n        '''\n        self.model.to(self.device)\n        self.model.eval()\n        correct = 0\n        total = 0\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        start_eval = time.time()\n        with torch.no_grad():\n            for data, target in self.test_loader:\n                data, target = data.to(self.device), target.to(self.device)\n                output = self.model(data)\n                _, predicted = torch.max(output.data, 1)\n                total += target.size(0)\n                correct += (predicted == target).sum().item()\n        self.test_accuracy = correct / total\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        end_eval = time.time()\n        self.inference_time = end_eval - start_eval\n        print(f'Test Accuracy for {self.model_name}: {self.test_accuracy:.4f} - in {self.inference_time} seconds.')\n        \n    def save_checkpoint(self, path):\n        '''\n        Function to save the current state of the model, optimizer and scheduler.\n        Also saves the model metrics training loss, validation loss, accuracy,\n        training and inference time.\n        '''\n        torch.save({'epoch': self.total_epochs_trained,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'scheduler_state_dict': self.scheduler.state_dict(),\n                    'loss': self.running_loss_train[-1],\n                    'running_loss_train': self.running_loss_train,\n                    'running_loss_val': self.running_loss_val,\n                    'test_accuracy': self.test_accuracy,\n                    'train_time': self.train_time_per_epoch,\n                    'inference_time': self.inference_time}, \n                    f'{path}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:45:20.101287Z","iopub.execute_input":"2024-06-21T18:45:20.101640Z","iopub.status.idle":"2024-06-21T18:45:20.125413Z","shell.execute_reply.started":"2024-06-21T18:45:20.101612Z","shell.execute_reply":"2024-06-21T18:45:20.124264Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"###############################################\n### CNN model for MNIST and cluttered MNIST ###\n###############################################\n# NOTE: Only difference if the models is the linear layer fc1. Input features needs adjustment as the size of the input images is different.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n####### CNN Model MNIST #######\n###############################\nclass CNN_MNIST(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(CNN_MNIST, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(9216, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:47:18.576302Z","iopub.execute_input":"2024-06-21T17:47:18.577252Z","iopub.status.idle":"2024-06-21T17:47:18.587418Z","shell.execute_reply.started":"2024-06-21T17:47:18.577208Z","shell.execute_reply":"2024-06-21T17:47:18.586350Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#################################\n####### CNN Model Clutter #######\n#################################\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(147456, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x","metadata":{"id":"Wdk5Gp7tlc4s","executionInfo":{"status":"ok","timestamp":1711019808528,"user_tz":-60,"elapsed":1920959,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"357f0e45-2497-42e1-bb5c-1f23c3ae1434","execution":{"iopub.status.busy":"2024-06-21T17:47:20.972618Z","iopub.execute_input":"2024-06-21T17:47:20.973585Z","iopub.status.idle":"2024-06-21T17:47:20.982533Z","shell.execute_reply.started":"2024-06-21T17:47:20.973553Z","shell.execute_reply":"2024-06-21T17:47:20.981404Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"###############################################\n### VAN model for MNIST and cluttered MNIST ###\n###############################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n####### VAN Model MNIST #######\n###############################\nclass Downsampling_MNIST(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block_MNIST(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA_MNIST(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN_MNIST(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN_MNIST(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA_MNIST(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=kernel_size, groups=in_channels)#DWConv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=kernel_size,\n                           dilation=dilation, groups=in_channels, padding=8)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN_MNIST(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling_MNIST(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block_MNIST(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:36:59.865129Z","iopub.execute_input":"2024-06-21T18:36:59.865486Z","iopub.status.idle":"2024-06-21T18:36:59.888991Z","shell.execute_reply.started":"2024-06-21T18:36:59.865458Z","shell.execute_reply":"2024-06-21T18:36:59.888026Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#################################\n####### VAN Model Clutter #######\n#################################\nclass Downsampling(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=kernel_size, groups=in_channels)#DWConv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=kernel_size,\n                           dilation=dilation, groups=in_channels, padding=8)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################\n### TRAINING OF THE NETWORKS ###\n################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################\n### CNN Training ###\n####################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize CNN on MNIST\ncnn_mnist = CNN_MNIST()\ncnn_mnist_optimizer = optim.AdamW(cnn_mnist.parameters(), lr=1e-3)\ncnn_mnist_trainer = Trainer(model=cnn_mnist, optimizer=cnn_mnist_optimizer,\n                            train_loader=mnist_train_loader, val_loader=mnist_val_loader, test_loader=mnist_test_loader,\n                            num_epochs=25, save_checkpoints=True, path=f'CNN_MNIST()')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:45:25.629419Z","iopub.execute_input":"2024-06-21T18:45:25.629791Z","iopub.status.idle":"2024-06-21T18:45:25.649282Z","shell.execute_reply.started":"2024-06-21T18:45:25.629763Z","shell.execute_reply":"2024-06-21T18:45:25.648549Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# Train CNN on MNIST\ncnn_mnist_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:45:29.574739Z","iopub.execute_input":"2024-06-21T18:45:29.575445Z","iopub.status.idle":"2024-06-21T18:50:46.680737Z","shell.execute_reply.started":"2024-06-21T18:45:29.575415Z","shell.execute_reply":"2024-06-21T18:50:46.679709Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Epoch 1/25, Batch 0/422, Train Loss: 2.3040\nEpoch 1/25, Batch 100/422, Train Loss: 1.6201\nEpoch 1/25, Batch 200/422, Train Loss: 1.5465\nEpoch 1/25, Batch 300/422, Train Loss: 1.5241\nEpoch 1/25, Batch 400/422, Train Loss: 1.5124\nModel CNN_MNIST at epoch 1/25: Avg Train Loss: 1.5933, Avg Val Loss: 1.4915\nEpoch 2/25, Batch 0/422, Train Loss: 1.5077\nEpoch 2/25, Batch 100/422, Train Loss: 1.4997\nEpoch 2/25, Batch 200/422, Train Loss: 1.4866\nEpoch 2/25, Batch 300/422, Train Loss: 1.4873\nEpoch 2/25, Batch 400/422, Train Loss: 1.5013\nModel CNN_MNIST at epoch 2/25: Avg Train Loss: 1.4984, Avg Val Loss: 1.4818\nEpoch 3/25, Batch 0/422, Train Loss: 1.5122\nEpoch 3/25, Batch 100/422, Train Loss: 1.4706\nEpoch 3/25, Batch 200/422, Train Loss: 1.4702\nEpoch 3/25, Batch 300/422, Train Loss: 1.4898\nEpoch 3/25, Batch 400/422, Train Loss: 1.4950\nModel CNN_MNIST at epoch 3/25: Avg Train Loss: 1.4900, Avg Val Loss: 1.4781\nEpoch 4/25, Batch 0/422, Train Loss: 1.4829\nEpoch 4/25, Batch 100/422, Train Loss: 1.4884\nEpoch 4/25, Batch 200/422, Train Loss: 1.4774\nEpoch 4/25, Batch 300/422, Train Loss: 1.4738\nEpoch 4/25, Batch 400/422, Train Loss: 1.4687\nModel CNN_MNIST at epoch 4/25: Avg Train Loss: 1.4880, Avg Val Loss: 1.4806\nEpoch 5/25, Batch 0/422, Train Loss: 1.5060\nEpoch 5/25, Batch 100/422, Train Loss: 1.4899\nEpoch 5/25, Batch 200/422, Train Loss: 1.4855\nEpoch 5/25, Batch 300/422, Train Loss: 1.4777\nEpoch 5/25, Batch 400/422, Train Loss: 1.4776\nModel CNN_MNIST at epoch 5/25: Avg Train Loss: 1.4841, Avg Val Loss: 1.4761\nEpoch 6/25, Batch 0/422, Train Loss: 1.4620\nEpoch 6/25, Batch 100/422, Train Loss: 1.4692\nEpoch 6/25, Batch 200/422, Train Loss: 1.4692\nEpoch 6/25, Batch 300/422, Train Loss: 1.4664\nEpoch 6/25, Batch 400/422, Train Loss: 1.4950\nModel CNN_MNIST at epoch 6/25: Avg Train Loss: 1.4825, Avg Val Loss: 1.4789\nEpoch 7/25, Batch 0/422, Train Loss: 1.4774\nEpoch 7/25, Batch 100/422, Train Loss: 1.4640\nEpoch 7/25, Batch 200/422, Train Loss: 1.4989\nEpoch 7/25, Batch 300/422, Train Loss: 1.4695\nEpoch 7/25, Batch 400/422, Train Loss: 1.4630\nModel CNN_MNIST at epoch 7/25: Avg Train Loss: 1.4814, Avg Val Loss: 1.4746\nEpoch 8/25, Batch 0/422, Train Loss: 1.4959\nEpoch 8/25, Batch 100/422, Train Loss: 1.4741\nEpoch 8/25, Batch 200/422, Train Loss: 1.4874\nEpoch 8/25, Batch 300/422, Train Loss: 1.4768\nEpoch 8/25, Batch 400/422, Train Loss: 1.4847\nModel CNN_MNIST at epoch 8/25: Avg Train Loss: 1.4806, Avg Val Loss: 1.4751\nEpoch 9/25, Batch 0/422, Train Loss: 1.4738\nEpoch 9/25, Batch 100/422, Train Loss: 1.4768\nEpoch 9/25, Batch 200/422, Train Loss: 1.4691\nEpoch 9/25, Batch 300/422, Train Loss: 1.4937\nEpoch 9/25, Batch 400/422, Train Loss: 1.4768\nModel CNN_MNIST at epoch 9/25: Avg Train Loss: 1.4793, Avg Val Loss: 1.4760\nEpoch 10/25, Batch 0/422, Train Loss: 1.4761\nEpoch 10/25, Batch 100/422, Train Loss: 1.4844\nEpoch 10/25, Batch 200/422, Train Loss: 1.4829\nEpoch 10/25, Batch 300/422, Train Loss: 1.4771\nEpoch 10/25, Batch 400/422, Train Loss: 1.4690\nModel CNN_MNIST at epoch 10/25: Avg Train Loss: 1.4790, Avg Val Loss: 1.4725\nEpoch 11/25, Batch 0/422, Train Loss: 1.4683\nEpoch 11/25, Batch 100/422, Train Loss: 1.4775\nEpoch 11/25, Batch 200/422, Train Loss: 1.4846\nEpoch 11/25, Batch 300/422, Train Loss: 1.4774\nEpoch 11/25, Batch 400/422, Train Loss: 1.4843\nModel CNN_MNIST at epoch 11/25: Avg Train Loss: 1.4781, Avg Val Loss: 1.4745\nEpoch 12/25, Batch 0/422, Train Loss: 1.4704\nEpoch 12/25, Batch 100/422, Train Loss: 1.4613\nEpoch 12/25, Batch 200/422, Train Loss: 1.4762\nEpoch 12/25, Batch 300/422, Train Loss: 1.4839\nEpoch 12/25, Batch 400/422, Train Loss: 1.4616\nModel CNN_MNIST at epoch 12/25: Avg Train Loss: 1.4777, Avg Val Loss: 1.4736\nEpoch 13/25, Batch 0/422, Train Loss: 1.4714\nEpoch 13/25, Batch 100/422, Train Loss: 1.5047\nEpoch 13/25, Batch 200/422, Train Loss: 1.4915\nEpoch 13/25, Batch 300/422, Train Loss: 1.4941\nEpoch 13/25, Batch 400/422, Train Loss: 1.4768\nModel CNN_MNIST at epoch 13/25: Avg Train Loss: 1.4772, Avg Val Loss: 1.4742\nEpoch 14/25, Batch 0/422, Train Loss: 1.4761\nEpoch 14/25, Batch 100/422, Train Loss: 1.4867\nEpoch 14/25, Batch 200/422, Train Loss: 1.4915\nEpoch 14/25, Batch 300/422, Train Loss: 1.4679\nEpoch 14/25, Batch 400/422, Train Loss: 1.4983\nModel CNN_MNIST at epoch 14/25: Avg Train Loss: 1.4764, Avg Val Loss: 1.4738\nEpoch 15/25, Batch 0/422, Train Loss: 1.4689\nEpoch 15/25, Batch 100/422, Train Loss: 1.4899\nEpoch 15/25, Batch 200/422, Train Loss: 1.4864\nEpoch 15/25, Batch 300/422, Train Loss: 1.4630\nEpoch 15/25, Batch 400/422, Train Loss: 1.4887\nModel CNN_MNIST at epoch 15/25: Avg Train Loss: 1.4766, Avg Val Loss: 1.4744\nEpoch 16/25, Batch 0/422, Train Loss: 1.4996\nEpoch 16/25, Batch 100/422, Train Loss: 1.4699\nEpoch 16/25, Batch 200/422, Train Loss: 1.4724\nEpoch 16/25, Batch 300/422, Train Loss: 1.4845\nEpoch 16/25, Batch 400/422, Train Loss: 1.4805\nModel CNN_MNIST at epoch 16/25: Avg Train Loss: 1.4758, Avg Val Loss: 1.4729\nEpoch 17/25, Batch 0/422, Train Loss: 1.4738\nEpoch 17/25, Batch 100/422, Train Loss: 1.4771\nEpoch 17/25, Batch 200/422, Train Loss: 1.4820\nEpoch 17/25, Batch 300/422, Train Loss: 1.4713\nEpoch 17/25, Batch 400/422, Train Loss: 1.4689\nModel CNN_MNIST at epoch 17/25: Avg Train Loss: 1.4749, Avg Val Loss: 1.4711\nEpoch 18/25, Batch 0/422, Train Loss: 1.4705\nEpoch 18/25, Batch 100/422, Train Loss: 1.4666\nEpoch 18/25, Batch 200/422, Train Loss: 1.4916\nEpoch 18/25, Batch 300/422, Train Loss: 1.4729\nEpoch 18/25, Batch 400/422, Train Loss: 1.4925\nModel CNN_MNIST at epoch 18/25: Avg Train Loss: 1.4750, Avg Val Loss: 1.4730\nEpoch 19/25, Batch 0/422, Train Loss: 1.4612\nEpoch 19/25, Batch 100/422, Train Loss: 1.4924\nEpoch 19/25, Batch 200/422, Train Loss: 1.4770\nEpoch 19/25, Batch 300/422, Train Loss: 1.4746\nEpoch 19/25, Batch 400/422, Train Loss: 1.4806\nModel CNN_MNIST at epoch 19/25: Avg Train Loss: 1.4754, Avg Val Loss: 1.4731\nEpoch 20/25, Batch 0/422, Train Loss: 1.4688\nEpoch 20/25, Batch 100/422, Train Loss: 1.4767\nEpoch 20/25, Batch 200/422, Train Loss: 1.4714\nEpoch 20/25, Batch 300/422, Train Loss: 1.4684\nEpoch 20/25, Batch 400/422, Train Loss: 1.4612\nModel CNN_MNIST at epoch 20/25: Avg Train Loss: 1.4738, Avg Val Loss: 1.4727\nEpoch 21/25, Batch 0/422, Train Loss: 1.4932\nEpoch 21/25, Batch 100/422, Train Loss: 1.4727\nEpoch 21/25, Batch 200/422, Train Loss: 1.4734\nEpoch 21/25, Batch 300/422, Train Loss: 1.4614\nEpoch 21/25, Batch 400/422, Train Loss: 1.4807\nModel CNN_MNIST at epoch 21/25: Avg Train Loss: 1.4746, Avg Val Loss: 1.4732\nEpoch 22/25, Batch 0/422, Train Loss: 1.4746\nEpoch 22/25, Batch 100/422, Train Loss: 1.4768\nEpoch 22/25, Batch 200/422, Train Loss: 1.4768\nEpoch 22/25, Batch 300/422, Train Loss: 1.4690\nEpoch 22/25, Batch 400/422, Train Loss: 1.4808\nModel CNN_MNIST at epoch 22/25: Avg Train Loss: 1.4736, Avg Val Loss: 1.4724\nEpoch 23/25, Batch 0/422, Train Loss: 1.4612\nEpoch 23/25, Batch 100/422, Train Loss: 1.4773\nEpoch 23/25, Batch 200/422, Train Loss: 1.4847\nEpoch 23/25, Batch 300/422, Train Loss: 1.4613\nEpoch 23/25, Batch 400/422, Train Loss: 1.4694\nModel CNN_MNIST at epoch 23/25: Avg Train Loss: 1.4730, Avg Val Loss: 1.4723\nEpoch 24/25, Batch 0/422, Train Loss: 1.4762\nEpoch 24/25, Batch 100/422, Train Loss: 1.4867\nEpoch 24/25, Batch 200/422, Train Loss: 1.4779\nEpoch 24/25, Batch 300/422, Train Loss: 1.4769\nEpoch 24/25, Batch 400/422, Train Loss: 1.4690\nModel CNN_MNIST at epoch 24/25: Avg Train Loss: 1.4737, Avg Val Loss: 1.4744\nEpoch 25/25, Batch 0/422, Train Loss: 1.4612\nEpoch 25/25, Batch 100/422, Train Loss: 1.4612\nEpoch 25/25, Batch 200/422, Train Loss: 1.4769\nEpoch 25/25, Batch 300/422, Train Loss: 1.4785\nEpoch 25/25, Batch 400/422, Train Loss: 1.4769\nModel CNN_MNIST at epoch 25/25: Avg Train Loss: 1.4725, Avg Val Loss: 1.4723\nModel CNN_MNIST took 5.27 minutes to run on 25 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate CNN on MNIST\ncnn_mnist_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:50:46.682415Z","iopub.execute_input":"2024-06-21T18:50:46.682734Z","iopub.status.idle":"2024-06-21T18:50:48.573576Z","shell.execute_reply.started":"2024-06-21T18:50:46.682703Z","shell.execute_reply":"2024-06-21T18:50:48.572666Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Test Accuracy for CNN_MNIST: 0.9896 - in 1.8851714134216309 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize CNN on cluterred MNIST\ncnn_clutter = CNN()\ncnn_clutter_optimizer = optim.AdamW(cnn_clutter.parameters(), lr=1e-3)\ncnn_clutter_trainer = Trainer(model=cnn_clutter, optimizer=cnn_clutter_optimizer,\n                            train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                            num_epochs=50, save_checkpoints=True, path=f'CNN_CLUTTER()')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:00:33.264197Z","iopub.execute_input":"2024-06-21T18:00:33.265015Z","iopub.status.idle":"2024-06-21T18:00:33.453917Z","shell.execute_reply.started":"2024-06-21T18:00:33.264981Z","shell.execute_reply":"2024-06-21T18:00:33.453077Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Train CNN on cluttered MNIST\ncnn_clutter_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:00:40.724465Z","iopub.execute_input":"2024-06-21T18:00:40.725184Z","iopub.status.idle":"2024-06-21T18:36:36.229263Z","shell.execute_reply.started":"2024-06-21T18:00:40.725152Z","shell.execute_reply":"2024-06-21T18:36:36.227779Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/50, Batch 0/422, Train Loss: 2.3027\nEpoch 1/50, Batch 100/422, Train Loss: 2.2940\nEpoch 1/50, Batch 200/422, Train Loss: 2.1898\nEpoch 1/50, Batch 300/422, Train Loss: 2.2339\nEpoch 1/50, Batch 400/422, Train Loss: 2.2011\nModel CNN at epoch 1/50: Avg Train Loss: 2.2483, Avg Val Loss: 1.2968\nEpoch 2/50, Batch 0/422, Train Loss: 2.2275\nEpoch 2/50, Batch 100/422, Train Loss: 2.1695\nEpoch 2/50, Batch 200/422, Train Loss: 2.1545\nEpoch 2/50, Batch 300/422, Train Loss: 2.1481\nEpoch 2/50, Batch 400/422, Train Loss: 2.1070\nModel CNN at epoch 2/50: Avg Train Loss: 2.1748, Avg Val Loss: 1.2710\nEpoch 3/50, Batch 0/422, Train Loss: 2.1990\nEpoch 3/50, Batch 100/422, Train Loss: 2.0563\nEpoch 3/50, Batch 200/422, Train Loss: 2.1155\nEpoch 3/50, Batch 300/422, Train Loss: 2.1208\nEpoch 3/50, Batch 400/422, Train Loss: 2.0781\nModel CNN at epoch 3/50: Avg Train Loss: 2.1097, Avg Val Loss: 1.2112\nEpoch 4/50, Batch 0/422, Train Loss: 2.0463\nEpoch 4/50, Batch 100/422, Train Loss: 2.0454\nEpoch 4/50, Batch 200/422, Train Loss: 2.1029\nEpoch 4/50, Batch 300/422, Train Loss: 2.0569\nEpoch 4/50, Batch 400/422, Train Loss: 2.0224\nModel CNN at epoch 4/50: Avg Train Loss: 2.0477, Avg Val Loss: 1.1660\nEpoch 5/50, Batch 0/422, Train Loss: 2.0051\nEpoch 5/50, Batch 100/422, Train Loss: 2.0133\nEpoch 5/50, Batch 200/422, Train Loss: 1.9658\nEpoch 5/50, Batch 300/422, Train Loss: 1.9375\nEpoch 5/50, Batch 400/422, Train Loss: 1.9125\nModel CNN at epoch 5/50: Avg Train Loss: 1.9986, Avg Val Loss: 1.1290\nEpoch 6/50, Batch 0/422, Train Loss: 1.9358\nEpoch 6/50, Batch 100/422, Train Loss: 2.0022\nEpoch 6/50, Batch 200/422, Train Loss: 1.9476\nEpoch 6/50, Batch 300/422, Train Loss: 1.9309\nEpoch 6/50, Batch 400/422, Train Loss: 1.9605\nModel CNN at epoch 6/50: Avg Train Loss: 1.9490, Avg Val Loss: 1.1040\nEpoch 7/50, Batch 0/422, Train Loss: 1.9422\nEpoch 7/50, Batch 100/422, Train Loss: 1.9887\nEpoch 7/50, Batch 200/422, Train Loss: 1.9061\nEpoch 7/50, Batch 300/422, Train Loss: 1.8653\nEpoch 7/50, Batch 400/422, Train Loss: 1.8599\nModel CNN at epoch 7/50: Avg Train Loss: 1.9092, Avg Val Loss: 1.0750\nEpoch 8/50, Batch 0/422, Train Loss: 1.9206\nEpoch 8/50, Batch 100/422, Train Loss: 1.9287\nEpoch 8/50, Batch 200/422, Train Loss: 1.8777\nEpoch 8/50, Batch 300/422, Train Loss: 1.8834\nEpoch 8/50, Batch 400/422, Train Loss: 1.8571\nModel CNN at epoch 8/50: Avg Train Loss: 1.8733, Avg Val Loss: 1.0512\nEpoch 9/50, Batch 0/422, Train Loss: 1.8377\nEpoch 9/50, Batch 100/422, Train Loss: 1.8555\nEpoch 9/50, Batch 200/422, Train Loss: 1.8998\nEpoch 9/50, Batch 300/422, Train Loss: 1.8225\nEpoch 9/50, Batch 400/422, Train Loss: 1.8437\nModel CNN at epoch 9/50: Avg Train Loss: 1.8449, Avg Val Loss: 1.0325\nEpoch 10/50, Batch 0/422, Train Loss: 1.8826\nEpoch 10/50, Batch 100/422, Train Loss: 1.8555\nEpoch 10/50, Batch 200/422, Train Loss: 1.8369\nEpoch 10/50, Batch 300/422, Train Loss: 1.9032\nEpoch 10/50, Batch 400/422, Train Loss: 1.7461\nModel CNN at epoch 10/50: Avg Train Loss: 1.8196, Avg Val Loss: 1.0385\nEpoch 11/50, Batch 0/422, Train Loss: 1.7734\nEpoch 11/50, Batch 100/422, Train Loss: 1.8005\nEpoch 11/50, Batch 200/422, Train Loss: 1.8105\nEpoch 11/50, Batch 300/422, Train Loss: 1.8324\nEpoch 11/50, Batch 400/422, Train Loss: 1.7677\nModel CNN at epoch 11/50: Avg Train Loss: 1.8057, Avg Val Loss: 1.0088\nEpoch 12/50, Batch 0/422, Train Loss: 1.8682\nEpoch 12/50, Batch 100/422, Train Loss: 1.7316\nEpoch 12/50, Batch 200/422, Train Loss: 1.7892\nEpoch 12/50, Batch 300/422, Train Loss: 1.7477\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train CNN on cluttered MNIST\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcnn_clutter_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[24], line 42\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m running_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m     43\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mRandomPlacement.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m----> 4\u001b[0m   canvas \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m73\u001b[39m, (\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m      6\u001b[0m   y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m73\u001b[39m, (\u001b[38;5;241m1\u001b[39m,))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate CNN on cluterred MNIST\ncnn_clutter_trainer.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################\n### VAN Training ###\n####################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize VAN on MNIST\nvan_mnist = VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_mnist_optimizer = optim.AdamW(van_mnist.parameters(), lr=1e-3)\nvan_mnist_trainer = Trainer(model=van_mnist, optimizer=van_mnist_optimizer,\n                            train_loader=mnist_train_loader, val_loader=mnist_val_loader, test_loader=mnist_test_loader,\n                            num_epochs=25, save_checkpoints=True, path=f'VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:38:36.225763Z","iopub.execute_input":"2024-06-21T18:38:36.226150Z","iopub.status.idle":"2024-06-21T18:38:36.240566Z","shell.execute_reply.started":"2024-06-21T18:38:36.226120Z","shell.execute_reply":"2024-06-21T18:38:36.239586Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Train VAN on MNIST\nvan_mnist_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:38:37.822268Z","iopub.execute_input":"2024-06-21T18:38:37.822901Z","iopub.status.idle":"2024-06-21T18:44:23.257039Z","shell.execute_reply.started":"2024-06-21T18:38:37.822868Z","shell.execute_reply":"2024-06-21T18:44:23.255702Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Epoch 1/50, Batch 0/422, Train Loss: 2.3054\nEpoch 1/50, Batch 100/422, Train Loss: 0.2388\nEpoch 1/50, Batch 200/422, Train Loss: 0.1700\nEpoch 1/50, Batch 300/422, Train Loss: 0.1105\nEpoch 1/50, Batch 400/422, Train Loss: 0.0494\nModel VAN_MNIST at epoch 1/50: Avg Train Loss: 0.3095, Avg Val Loss: 0.0468\nEpoch 2/50, Batch 0/422, Train Loss: 0.1146\nEpoch 2/50, Batch 100/422, Train Loss: 0.0747\nEpoch 2/50, Batch 200/422, Train Loss: 0.0372\nEpoch 2/50, Batch 300/422, Train Loss: 0.0820\nEpoch 2/50, Batch 400/422, Train Loss: 0.0164\nModel VAN_MNIST at epoch 2/50: Avg Train Loss: 0.0595, Avg Val Loss: 0.0264\nEpoch 3/50, Batch 0/422, Train Loss: 0.0203\nEpoch 3/50, Batch 100/422, Train Loss: 0.0269\nEpoch 3/50, Batch 200/422, Train Loss: 0.0065\nEpoch 3/50, Batch 300/422, Train Loss: 0.0431\nEpoch 3/50, Batch 400/422, Train Loss: 0.0888\nModel VAN_MNIST at epoch 3/50: Avg Train Loss: 0.0415, Avg Val Loss: 0.0310\nEpoch 4/50, Batch 0/422, Train Loss: 0.0015\nEpoch 4/50, Batch 100/422, Train Loss: 0.0408\nEpoch 4/50, Batch 200/422, Train Loss: 0.0838\nEpoch 4/50, Batch 300/422, Train Loss: 0.0916\nEpoch 4/50, Batch 400/422, Train Loss: 0.0180\nModel VAN_MNIST at epoch 4/50: Avg Train Loss: 0.0329, Avg Val Loss: 0.0319\nEpoch 5/50, Batch 0/422, Train Loss: 0.0175\nEpoch 5/50, Batch 100/422, Train Loss: 0.0318\nEpoch 5/50, Batch 200/422, Train Loss: 0.0056\nEpoch 5/50, Batch 300/422, Train Loss: 0.0039\nEpoch 5/50, Batch 400/422, Train Loss: 0.0332\nModel VAN_MNIST at epoch 5/50: Avg Train Loss: 0.0255, Avg Val Loss: 0.0225\nEpoch 6/50, Batch 0/422, Train Loss: 0.0098\nEpoch 6/50, Batch 100/422, Train Loss: 0.0162\nEpoch 6/50, Batch 200/422, Train Loss: 0.0408\nEpoch 6/50, Batch 300/422, Train Loss: 0.0019\nEpoch 6/50, Batch 400/422, Train Loss: 0.0016\nModel VAN_MNIST at epoch 6/50: Avg Train Loss: 0.0256, Avg Val Loss: 0.0201\nEpoch 7/50, Batch 0/422, Train Loss: 0.0078\nEpoch 7/50, Batch 100/422, Train Loss: 0.0148\nEpoch 7/50, Batch 200/422, Train Loss: 0.0064\nEpoch 7/50, Batch 300/422, Train Loss: 0.0131\nEpoch 7/50, Batch 400/422, Train Loss: 0.0514\nModel VAN_MNIST at epoch 7/50: Avg Train Loss: 0.0196, Avg Val Loss: 0.0263\nEpoch 8/50, Batch 0/422, Train Loss: 0.0240\nEpoch 8/50, Batch 100/422, Train Loss: 0.0212\nEpoch 8/50, Batch 200/422, Train Loss: 0.0069\nEpoch 8/50, Batch 300/422, Train Loss: 0.0110\nEpoch 8/50, Batch 400/422, Train Loss: 0.0040\nModel VAN_MNIST at epoch 8/50: Avg Train Loss: 0.0188, Avg Val Loss: 0.0235\nEpoch 9/50, Batch 0/422, Train Loss: 0.1136\nEpoch 9/50, Batch 100/422, Train Loss: 0.0050\nEpoch 9/50, Batch 200/422, Train Loss: 0.0254\nEpoch 9/50, Batch 300/422, Train Loss: 0.0201\nEpoch 9/50, Batch 400/422, Train Loss: 0.0127\nModel VAN_MNIST at epoch 9/50: Avg Train Loss: 0.0168, Avg Val Loss: 0.0271\nEpoch 10/50, Batch 0/422, Train Loss: 0.0045\nEpoch 10/50, Batch 100/422, Train Loss: 0.0186\nEpoch 10/50, Batch 200/422, Train Loss: 0.0318\nEpoch 10/50, Batch 300/422, Train Loss: 0.0096\nEpoch 10/50, Batch 400/422, Train Loss: 0.0078\nModel VAN_MNIST at epoch 10/50: Avg Train Loss: 0.0153, Avg Val Loss: 0.0272\nEpoch 11/50, Batch 0/422, Train Loss: 0.0103\nEpoch 11/50, Batch 100/422, Train Loss: 0.0011\nEpoch 11/50, Batch 200/422, Train Loss: 0.0009\nEpoch 11/50, Batch 300/422, Train Loss: 0.0014\nEpoch 11/50, Batch 400/422, Train Loss: 0.0015\nModel VAN_MNIST at epoch 11/50: Avg Train Loss: 0.0150, Avg Val Loss: 0.0171\nEpoch 12/50, Batch 0/422, Train Loss: 0.0580\nEpoch 12/50, Batch 100/422, Train Loss: 0.0002\nEpoch 12/50, Batch 200/422, Train Loss: 0.0211\nEpoch 12/50, Batch 300/422, Train Loss: 0.0064\nEpoch 12/50, Batch 400/422, Train Loss: 0.0117\nModel VAN_MNIST at epoch 12/50: Avg Train Loss: 0.0119, Avg Val Loss: 0.0191\nEpoch 13/50, Batch 0/422, Train Loss: 0.0021\nEpoch 13/50, Batch 100/422, Train Loss: 0.0661\nEpoch 13/50, Batch 200/422, Train Loss: 0.0176\nEpoch 13/50, Batch 300/422, Train Loss: 0.1580\nEpoch 13/50, Batch 400/422, Train Loss: 0.0010\nModel VAN_MNIST at epoch 13/50: Avg Train Loss: 0.0143, Avg Val Loss: 0.0339\nEpoch 14/50, Batch 0/422, Train Loss: 0.0054\nEpoch 14/50, Batch 100/422, Train Loss: 0.0048\nEpoch 14/50, Batch 200/422, Train Loss: 0.0047\nEpoch 14/50, Batch 300/422, Train Loss: 0.0303\nEpoch 14/50, Batch 400/422, Train Loss: 0.0283\nModel VAN_MNIST at epoch 14/50: Avg Train Loss: 0.0112, Avg Val Loss: 0.0203\nEpoch 15/50, Batch 0/422, Train Loss: 0.0083\nEpoch 15/50, Batch 100/422, Train Loss: 0.0104\nEpoch 15/50, Batch 200/422, Train Loss: 0.0007\nEpoch 15/50, Batch 300/422, Train Loss: 0.0040\nEpoch 15/50, Batch 400/422, Train Loss: 0.0115\nModel VAN_MNIST at epoch 15/50: Avg Train Loss: 0.0096, Avg Val Loss: 0.0263\nEpoch 16/50, Batch 0/422, Train Loss: 0.0006\nEpoch 16/50, Batch 100/422, Train Loss: 0.0130\nEpoch 16/50, Batch 200/422, Train Loss: 0.0153\nEpoch 16/50, Batch 300/422, Train Loss: 0.0015\nEpoch 16/50, Batch 400/422, Train Loss: 0.0285\nModel VAN_MNIST at epoch 16/50: Avg Train Loss: 0.0109, Avg Val Loss: 0.0219\nEpoch 17/50, Batch 0/422, Train Loss: 0.0004\nEpoch 17/50, Batch 100/422, Train Loss: 0.0017\nEpoch 17/50, Batch 200/422, Train Loss: 0.0017\nEpoch 17/50, Batch 300/422, Train Loss: 0.0024\nEpoch 17/50, Batch 400/422, Train Loss: 0.0115\nModel VAN_MNIST at epoch 17/50: Avg Train Loss: 0.0099, Avg Val Loss: 0.0232\nEpoch 18/50, Batch 0/422, Train Loss: 0.0001\nEpoch 18/50, Batch 100/422, Train Loss: 0.0074\nEpoch 18/50, Batch 200/422, Train Loss: 0.0001\nEpoch 18/50, Batch 300/422, Train Loss: 0.0005\nEpoch 18/50, Batch 400/422, Train Loss: 0.0159\nModel VAN_MNIST at epoch 18/50: Avg Train Loss: 0.0092, Avg Val Loss: 0.0198\nEpoch 19/50, Batch 0/422, Train Loss: 0.0057\nEpoch 19/50, Batch 100/422, Train Loss: 0.0014\nEpoch 19/50, Batch 200/422, Train Loss: 0.0079\nEpoch 19/50, Batch 300/422, Train Loss: 0.0075\nEpoch 19/50, Batch 400/422, Train Loss: 0.0211\nModel VAN_MNIST at epoch 19/50: Avg Train Loss: 0.0082, Avg Val Loss: 0.0285\nEpoch 20/50, Batch 0/422, Train Loss: 0.0630\nEpoch 20/50, Batch 100/422, Train Loss: 0.0123\nEpoch 20/50, Batch 200/422, Train Loss: 0.0092\nEpoch 20/50, Batch 300/422, Train Loss: 0.0015\nEpoch 20/50, Batch 400/422, Train Loss: 0.0046\nModel VAN_MNIST at epoch 20/50: Avg Train Loss: 0.0098, Avg Val Loss: 0.0205\nEpoch 21/50, Batch 0/422, Train Loss: 0.0010\nEpoch 21/50, Batch 100/422, Train Loss: 0.0007\nEpoch 21/50, Batch 200/422, Train Loss: 0.0185\nEpoch 21/50, Batch 300/422, Train Loss: 0.0103\nEpoch 21/50, Batch 400/422, Train Loss: 0.0246\nModel VAN_MNIST at epoch 21/50: Avg Train Loss: 0.0070, Avg Val Loss: 0.0300\nEpoch 22/50, Batch 0/422, Train Loss: 0.0009\nEpoch 22/50, Batch 100/422, Train Loss: 0.0106\nEpoch 22/50, Batch 200/422, Train Loss: 0.0372\nEpoch 22/50, Batch 300/422, Train Loss: 0.0007\nEpoch 22/50, Batch 400/422, Train Loss: 0.0004\nModel VAN_MNIST at epoch 22/50: Avg Train Loss: 0.0086, Avg Val Loss: 0.0271\nEpoch 23/50, Batch 0/422, Train Loss: 0.0549\nEpoch 23/50, Batch 100/422, Train Loss: 0.0004\nEpoch 23/50, Batch 200/422, Train Loss: 0.0004\nEpoch 23/50, Batch 300/422, Train Loss: 0.0050\nEpoch 23/50, Batch 400/422, Train Loss: 0.0004\nModel VAN_MNIST at epoch 23/50: Avg Train Loss: 0.0040, Avg Val Loss: 0.0174\nEpoch 24/50, Batch 0/422, Train Loss: 0.0033\nEpoch 24/50, Batch 100/422, Train Loss: 0.0003\nEpoch 24/50, Batch 200/422, Train Loss: 0.0002\nEpoch 24/50, Batch 300/422, Train Loss: 0.0001\nEpoch 24/50, Batch 400/422, Train Loss: 0.0001\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train VAN on MNIST\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvan_mnist_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[24], line 59\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m running_loss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (data_val, target_val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader):\n\u001b[1;32m     60\u001b[0m         data_val, target_val \u001b[38;5;241m=\u001b[39m data_val\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target_val\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     61\u001b[0m         output_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data_val)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate VAN on MNIST\nvan_mnist_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:44:28.504291Z","iopub.execute_input":"2024-06-21T18:44:28.504889Z","iopub.status.idle":"2024-06-21T18:44:30.669061Z","shell.execute_reply.started":"2024-06-21T18:44:28.504855Z","shell.execute_reply":"2024-06-21T18:44:30.668094Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN_MNIST: 0.9946 - in 2.1570987701416016 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize VAN on cluttered MNIST\nvan_clutter = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_clutter_optimizer = optim.AdamW(van_clutter.parameters(), lr=1e-3)\nvan_clutter_trainer = Trainer(model=van_clutter, optimizer=van_clutter_optimizer,\n                              train_loader=train_loader, loader=val_loader, loader=test_loader,\n                              num_epochs=50, save_checkpoints=True, path=f'VAN_CLUTTER(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train VAN on cluttered MNIST\nvan_clutter_trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate VAN on cluttered MNIST\nvan_clutter_trainer.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###Import function for checkpoints!###","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Computational Cost Comparison**","metadata":{}},{"cell_type":"code","source":"def plot_loss(train_loss, val_loss):\n    epochs = range(1, len(train_loss) + 1)\n    plt.plot(epochs, train_loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n\nplot_loss(trainer.running_loss_train, trainer.running_loss_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:55:13.614931Z","iopub.execute_input":"2024-04-19T11:55:13.615645Z","iopub.status.idle":"2024-04-19T11:55:13.915562Z","shell.execute_reply.started":"2024-04-19T11:55:13.615611Z","shell.execute_reply":"2024-04-19T11:55:13.914671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:45:28.052599Z","iopub.execute_input":"2024-04-19T10:45:28.052910Z","iopub.status.idle":"2024-04-19T10:45:31.272907Z","shell.execute_reply.started":"2024-04-19T10:45:28.052885Z","shell.execute_reply":"2024-04-19T10:45:31.271735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_weights_equal(model1, model2):\n    # Check if models have the same number of parameters\n    if sum(p.numel() for p in model1.parameters()) != sum(p.numel() for p in model2.parameters()):\n        return False\n    \n    # Check if parameters are the same\n    for p1, p2 in zip(model1.parameters(), model2.parameters()):\n        if not torch.all(torch.eq(p1.data, p2.data)):\n            return False\n    \n    return True","metadata":{"execution":{"iopub.status.busy":"2024-04-13T13:24:25.892067Z","iopub.execute_input":"2024-04-13T13:24:25.892740Z","iopub.status.idle":"2024-04-13T13:24:25.898837Z","shell.execute_reply.started":"2024-04-13T13:24:25.892707Z","shell.execute_reply":"2024-04-13T13:24:25.897756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Visual Attention Network ###","metadata":{"id":"O57xJG03K7-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#############################################################\n##### Own Implementation of the Visual Attention Network ####\n#############################################################\n'''\nNotes on the architecture from the paper:\n- Simple hierarchical structure\n  -> Sequence of four stages e.g\n  -> Decreasig output spatial resolution:\n    H/4 x W/4 -> H/8 x W/8 -> H/16 x W/16 -> H/32 x W/32 - Maybe start a 2**1??\n  -> With decreasing resolution, number of channels increases.\n  -> Each stage: First downsample the input with the stride number (-> Convolution)\n     --- In this step, we decrease the resolution and increase the dimensions\n         -> (First iteration: 100x100x1 as input and ?x?xdim[0] as output)\n         -> (Second iteration: 25x25xdim[0] as input and ?x?xdim[1] as output)\n  -> During each stage, the resolution (H & W) and the channels (C) remain the same and do not change\n     until the next stage starts\n  -> At each stage L-Groups (Blocks) of:\n    - Batch Norm\n    - 1x1 Conv\n    - GELU Activation\n    - LKA ()\n    - FFN (1x1 Conv. depthwise, 3x3 Conv, GELU, 1x1 Conv.)\n'''\n\nclass Downsampling(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=kernel_size, groups=in_channels)#DWConv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=kernel_size,\n                           dilation=dilation, groups=in_channels, padding=8)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711009784026,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"mYJOZ10DUg-P","execution":{"iopub.status.busy":"2024-06-21T17:23:46.528338Z","iopub.execute_input":"2024-06-21T17:23:46.528731Z","iopub.status.idle":"2024-06-21T17:23:46.553840Z","shell.execute_reply.started":"2024-06-21T17:23:46.528699Z","shell.execute_reply":"2024-06-21T17:23:46.552913Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nvan_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_optimizer = optim.AdamW(van_model.parameters(), lr=1e-3)\nvan_trainer = Trainer(model=van_model, optimizer=van_optimizer,\n                      train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                      num_epochs=30, save_checkpoints=True, path=f'VAN()')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:03:15.576090Z","iopub.execute_input":"2024-04-19T12:03:15.576479Z","iopub.status.idle":"2024-04-19T12:03:15.594482Z","shell.execute_reply.started":"2024-04-19T12:03:15.576450Z","shell.execute_reply":"2024-04-19T12:03:15.593648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:50:36.640470Z","iopub.execute_input":"2024-04-19T13:50:36.641161Z","iopub.status.idle":"2024-04-19T14:52:10.202946Z","shell.execute_reply.started":"2024-04-19T13:50:36.641128Z","shell.execute_reply":"2024-04-19T14:52:10.201954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:52:10.204576Z","iopub.execute_input":"2024-04-19T14:52:10.204896Z","iopub.status.idle":"2024-04-19T14:52:40.364649Z","shell.execute_reply.started":"2024-04-19T14:52:10.204869Z","shell.execute_reply":"2024-04-19T14:52:40.363712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt = torch.load('/kaggle/input/van-final/pytorch/van-clutter-mnist-final/1/VAN(channels64 128 stages2 l1 1 expansion_ratio2 4)_50_epochs_Acc_9922.pth', map_location='cpu')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:23:52.327880Z","iopub.execute_input":"2024-06-21T17:23:52.328324Z","iopub.status.idle":"2024-06-21T17:23:52.416516Z","shell.execute_reply.started":"2024-06-21T17:23:52.328289Z","shell.execute_reply":"2024-06-21T17:23:52.415486Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:16:49.211501Z","iopub.execute_input":"2024-06-21T17:16:49.211921Z","iopub.status.idle":"2024-06-21T17:16:49.219849Z","shell.execute_reply.started":"2024-06-21T17:16:49.211870Z","shell.execute_reply":"2024-06-21T17:16:49.218561Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'running_loss_train', 'running_loss_val', 'test_accuracy', 'inference_time'])"},"metadata":{}}]},{"cell_type":"code","source":"ckpt['test_accuracy']","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:23:54.661174Z","iopub.execute_input":"2024-06-21T17:23:54.661895Z","iopub.status.idle":"2024-06-21T17:23:54.668115Z","shell.execute_reply.started":"2024-06-21T17:23:54.661860Z","shell.execute_reply":"2024-06-21T17:23:54.667094Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.9881"},"metadata":{}}]},{"cell_type":"code","source":"ckpt['loss']","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:59.057906Z","iopub.execute_input":"2024-06-21T17:06:59.058369Z","iopub.status.idle":"2024-06-21T17:06:59.065549Z","shell.execute_reply.started":"2024-06-21T17:06:59.058333Z","shell.execute_reply":"2024-06-21T17:06:59.064328Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.014491620752601818"},"metadata":{}}]},{"cell_type":"code","source":"### Check reproducability","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:58:16.204296Z","iopub.execute_input":"2024-04-19T14:58:16.204665Z","iopub.status.idle":"2024-04-19T14:58:46.234582Z","shell.execute_reply.started":"2024-04-19T14:58:16.204637Z","shell.execute_reply":"2024-04-19T14:58:46.233655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_optimizer = optim.AdamW(van_model.parameters(), lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:02:25.092595Z","iopub.execute_input":"2024-04-19T15:02:25.093506Z","iopub.status.idle":"2024-04-19T15:02:25.099207Z","shell.execute_reply.started":"2024-04-19T15:02:25.093472Z","shell.execute_reply":"2024-04-19T15:02:25.098223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt['scheduler_state_dict']","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:10:44.840597Z","iopub.execute_input":"2024-04-19T15:10:44.841527Z","iopub.status.idle":"2024-04-19T15:10:44.847559Z","shell.execute_reply.started":"2024-04-19T15:10:44.841492Z","shell.execute_reply":"2024-04-19T15:10:44.846717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Wrap checkpoint loading into a function.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nckpt_model.load_state_dict(ckpt['model_state_dict'])\nckpt_optimizer = optim.AdamW(ckpt_model.parameters(), lr=1e-3)\nckpt_optimizer.load_state_dict(ckpt['optimizer_state_dict'])\nckpt_trainer = Trainer(model=ckpt_model, optimizer=ckpt_optimizer,\n                       train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                       num_epochs=30, save_checkpoints=False, path=f'Ckpt_VAN()')\nckpt_trainer.scheduler.load_state_dict(ckpt['scheduler_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:24:28.293120Z","iopub.execute_input":"2024-06-21T17:24:28.293560Z","iopub.status.idle":"2024-06-21T17:24:28.320823Z","shell.execute_reply.started":"2024-06-21T17:24:28.293530Z","shell.execute_reply":"2024-06-21T17:24:28.319911Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"ckpt_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:27:39.732022Z","iopub.execute_input":"2024-06-21T17:27:39.732761Z","iopub.status.idle":"2024-06-21T17:28:10.100599Z","shell.execute_reply.started":"2024-06-21T17:27:39.732730Z","shell.execute_reply":"2024-06-21T17:28:10.099689Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN: 0.9927 - in 30.361655712127686 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:26:45.387132Z","iopub.execute_input":"2024-06-21T17:26:45.387519Z","iopub.status.idle":"2024-06-21T17:26:45.393486Z","shell.execute_reply.started":"2024-06-21T17:26:45.387493Z","shell.execute_reply":"2024-06-21T17:26:45.392559Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'running_loss_train', 'running_loss_val', 'test_accuracy', 'inference_time'])"},"metadata":{}}]},{"cell_type":"code","source":"ckpt['epoch']","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:28:45.718595Z","iopub.execute_input":"2024-06-21T17:28:45.718966Z","iopub.status.idle":"2024-06-21T17:28:45.724959Z","shell.execute_reply.started":"2024-06-21T17:28:45.718940Z","shell.execute_reply":"2024-06-21T17:28:45.724021Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}]},{"cell_type":"code","source":"######################\n### ABLATION STUDY ###\n######################","metadata":{"id":"euX4LKFiCmla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementation of the VAN without an Attention Mechanism\nclass Downsampling_ablation(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block_ablation(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    #self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.abl_FFN = FFN_ablation(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    #x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.abl_FFN(x)\n\n    return x\n\n\nclass FFN_ablation(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\nclass VAN_ablation(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler_ablation = Downsampling_ablation(in_channels=1 if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block_ablation = nn.ModuleList([Block_ablation(channels=self.channels[j],\n                                      expansion_ratio=self.expansion_ratio[j],\n                                      dropout=dropout)\n                                      for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler_ablation)\n      setattr(self, f'block_{j+1}', block_ablation)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"id":"PfX0_Pu6Cmei","executionInfo":{"status":"ok","timestamp":1711012063764,"user_tz":-60,"elapsed":208,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"execution":{"iopub.status.busy":"2024-03-26T19:42:01.421882Z","iopub.execute_input":"2024-03-26T19:42:01.422639Z","iopub.status.idle":"2024-03-26T19:42:01.440940Z","shell.execute_reply.started":"2024-03-26T19:42:01.422607Z","shell.execute_reply":"2024-03-26T19:42:01.440077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nabl_model = VAN_ablation(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nabl_optimizer = optim.AdamW(abl_model.parameters(), lr=1e-3)\nabl_trainer = Trainer(model=vabl_model, optimizer=abl_optimizer,\n                      train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                      num_epochs=50, save_checkpoints=True, path=f'VAN_Ablation()')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abl_trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abl_trainer.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########################\n### ACCURACY COMPARISON ###\n###########################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#####################################\n### COMPUTATIONAL COST COMPARISON ###\n#####################################","metadata":{"id":"q80dXxsWAsh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nTODO: Check torchinfo Profiler\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare number of modueles\n\ndef count_modules(model):\n    # Use model.modules() for all modules including nested ones,\n    # or model.children() for immediate children only.\n    num_modules = sum(1 for _ in model.modules())\n    return num_modules\n\nbaseline = BaselineCNN()\nvan = VAN()\n\nnum_modules_cnn = count_modules(baseline)\nnum_modules_van = count_modules(van)\n\nprint(\"Number of modules in CNN:\", num_modules_cnn)\nprint(\"Number of modules in VAN:\", num_modules_van)","metadata":{"id":"6a5e_FegAoGs","executionInfo":{"status":"ok","timestamp":1711019998475,"user_tz":-60,"elapsed":336,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"85dbf9d1-b18e-46b1-b7d1-4ff66b5b309c","execution":{"iopub.status.busy":"2024-03-21T11:39:11.847181Z","iopub.execute_input":"2024-03-21T11:39:11.847897Z","iopub.status.idle":"2024-03-21T11:39:11.924267Z","shell.execute_reply.started":"2024-03-21T11:39:11.847864Z","shell.execute_reply":"2024-03-21T11:39:11.923437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of parameters for the baseline CNN model\ntrainable_params = sum(p.numel() for p in baseline.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in baseline.parameters())\n\"{:,}\".format(trainable_params), \"{:,}\".format(total_params)","metadata":{"id":"95prYojcBLah","executionInfo":{"status":"ok","timestamp":1711020097212,"user_tz":-60,"elapsed":230,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"857675c9-8beb-4fea-a514-810f8645a599","execution":{"iopub.status.busy":"2024-03-21T11:39:16.161026Z","iopub.execute_input":"2024-03-21T11:39:16.161748Z","iopub.status.idle":"2024-03-21T11:39:16.168610Z","shell.execute_reply.started":"2024-03-21T11:39:16.161715Z","shell.execute_reply":"2024-03-21T11:39:16.167723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of parameters for VAN\ntotal_params_van = sum(p.numel() for p in van.parameters())\nprint(f' Total parameters of the VAN model are: {\"{:,}\".format(total_params_van)}')","metadata":{"id":"NJIg4rfgBNHh","executionInfo":{"status":"ok","timestamp":1711020070331,"user_tz":-60,"elapsed":407,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"50aedc59-dcc0-4ee5-ec32-f1a56f34eae6","execution":{"iopub.status.busy":"2024-03-21T11:39:18.306852Z","iopub.execute_input":"2024-03-21T11:39:18.307471Z","iopub.status.idle":"2024-03-21T11:39:18.313188Z","shell.execute_reply.started":"2024-03-21T11:39:18.307441Z","shell.execute_reply":"2024-03-21T11:39:18.312277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install deepspeed\nfrom deepspeed.profiling.flops_profiler import FlopsProfiler","metadata":{"id":"5npplbR9v-vu","outputId":"3c1e8282-709e-4771-ae20-ee0d3d59ae2c","execution":{"iopub.status.busy":"2024-03-26T18:06:35.292615Z","iopub.execute_input":"2024-03-26T18:06:35.293076Z","iopub.status.idle":"2024-03-26T18:07:19.351944Z","shell.execute_reply.started":"2024-03-26T18:06:35.293044Z","shell.execute_reply":"2024-03-26T18:07:19.350905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = VAN(num_classes=14, stages=2, channels=[64, 128], image_channels=3, l=[1,1], expansion_ratio=[2,4])\nprofile_model(input_model=m1, data_loader=pc_train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:52:16.531727Z","iopub.execute_input":"2024-03-25T17:52:16.532454Z","iopub.status.idle":"2024-03-25T17:52:19.048782Z","shell.execute_reply.started":"2024-03-25T17:52:16.532421Z","shell.execute_reply":"2024-03-25T17:52:19.047886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def profile_model(input_model, data_loader=train_loader):\n    # Profile a model to get the FLOPS and Latency\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model = input_model\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n    prof = FlopsProfiler(model)\n    # Profile at step 5 to warmup\n    profile_step = 5\n    for batch_idx, (data, target) in enumerate(data_loader):\n      if batch_idx == profile_step:\n        prof.start_profile()\n\n      data, target = data.to(device), target.to(device)\n      optimizer.zero_grad()\n      output = model(data)\n      loss = criterion(output, target)\n\n      if batch_idx == profile_step:\n        prof.stop_profile()\n        flops = prof.get_total_flops()\n        macs = prof.get_total_macs()\n        params = prof.get_total_params()\n        prof.print_model_profile(profile_step=profile_step)\n        prof.end_profile()\n\n      loss.backward()\n      optimizer.step()\n\n      if batch_idx == profile_step:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:47:37.606860Z","iopub.execute_input":"2024-03-25T17:47:37.607618Z","iopub.status.idle":"2024-03-25T17:47:37.616235Z","shell.execute_reply.started":"2024-03-25T17:47:37.607586Z","shell.execute_reply":"2024-03-25T17:47:37.615214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FLOPs for VAN\nfor data, target in augmented_loader:\n  input_data, input_target = data.to(device), target.to(device)\n  break\n\nflops_van, params = profile(van, inputs=(input_data,))\nprint(f'Estimated Params for VAN:, {(\"{:,}\".format(params))}')\nprint(f'Estimated FLOPs for VAN:, {(\"{:,}\".format(flops_van))}')","metadata":{"id":"zqHb0WdSA3Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for Baseline CNN\n\n# Define your model and input data\nbaseline = BaselineCNN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = baseline(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"6vf3Yhg3BFbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for VAN\n\n# Define your model and input data\nvan = VAN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = van(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"jvtS_uZKBFSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare convolution speed ###\nfrom torch.autograd import profiler\ninput = torch.randn((128, 32, 50, 50), device=\"cuda\")\nm1 = LKA(32, 32).to(\"cuda\")\nm2 = LSKA(32, 32).to(\"cuda\")\nm3 = KA(32, 32).to(\"cuda\")\n\nwith profiler.profile(record_shapes=True, use_cuda=True) as prof:\n    with profiler.record_function(\"model_inference\"):\n        # Your PyTorch operations here\n        output = m3(input)\nprint(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))","metadata":{"id":"_rsVqxX4BFIW","execution":{"iopub.status.busy":"2024-03-22T09:19:14.996033Z","iopub.execute_input":"2024-03-22T09:19:14.996978Z","iopub.status.idle":"2024-03-22T09:19:15.029116Z","shell.execute_reply.started":"2024-03-22T09:19:14.996939Z","shell.execute_reply":"2024-03-22T09:19:15.028133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#######################################################\n### Compare difference in speed using fp32 and fp16 ###\n#######################################################","metadata":{"execution":{"iopub.status.busy":"2024-03-26T18:14:10.948549Z","iopub.execute_input":"2024-03-26T18:14:10.948985Z","iopub.status.idle":"2024-03-26T18:14:10.954385Z","shell.execute_reply.started":"2024-03-26T18:14:10.948955Z","shell.execute_reply":"2024-03-26T18:14:10.953437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda_loader = torch.utils.data.DataLoader(dataset=augmented_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T20:02:06.293855Z","iopub.execute_input":"2024-03-26T20:02:06.294762Z","iopub.status.idle":"2024-03-26T20:02:06.300379Z","shell.execute_reply.started":"2024-03-26T20:02:06.294726Z","shell.execute_reply":"2024-03-26T20:02:06.299351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4]).cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T19:22:35.929570Z","iopub.execute_input":"2024-03-26T19:22:35.930169Z","iopub.status.idle":"2024-03-26T19:22:35.951426Z","shell.execute_reply.started":"2024-03-26T19:22:35.930136Z","shell.execute_reply":"2024-03-26T19:22:35.950730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### FP32\n\n# Creates model and optimizer in default precision\nmodel = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4])\nmodel.to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\nwith torch.autograd.profiler.profile(use_cuda=True) as prof:\n    for epoch in range(1):\n        print(f'Epoch {epoch+1} started')\n\n        for i, (input, target) in enumerate(cuda_loader):\n            #input, target = input.to('cuda'), target.to('cuda')\n            optimizer.zero_grad()\n\n            output = model(input)\n            loss = criterion(output, target)\n\n            loss.backward()\n\n            optimizer.step()\n            if i == 10:\n                break\n        print(f'Epoch {epoch+1} finished')\nprint(prof.key_averages())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T20:02:09.897192Z","iopub.execute_input":"2024-03-26T20:02:09.898064Z","iopub.status.idle":"2024-03-26T20:02:14.591720Z","shell.execute_reply.started":"2024-03-26T20:02:09.898009Z","shell.execute_reply":"2024-03-26T20:02:14.590115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import autocast\nfrom torch.cuda.amp import GradScaler\n\n### FP16\n\n# Creates model and optimizer in default precision\nmodel = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4])\nmodel.to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\n# Creates a GradScaler once at the beginning of training.\nscaler = GradScaler()\nwith torch.autograd.profiler.profile(use_cuda=True) as prof:\n    for epoch in range(1):\n        print(f'Epoch {epoch+1} started')\n\n        for i, (input, target) in enumerate(train_loader):\n            input, target = input.to('cuda'), target.to('cuda')\n            optimizer.zero_grad()\n\n            # Runs the forward pass with autocasting.\n            with autocast(device_type='cuda', dtype=torch.float16):\n                output = model(input)\n                loss = criterion(output, target)\n\n            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n            # Backward passes under autocast are not recommended.\n            # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n            scaler.scale(loss).backward()\n\n            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n            # otherwise, optimizer.step() is skipped.\n            scaler.step(optimizer)\n\n            # Updates the scale for next iteration.\n            scaler.update()\n            if i == 10 :\n                break\n                \n        print(f'Epoch {epoch+1} finished')\nprint(prof.key_averages())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T19:49:18.065962Z","iopub.execute_input":"2024-03-26T19:49:18.066371Z","iopub.status.idle":"2024-03-26T19:50:37.974789Z","shell.execute_reply.started":"2024-03-26T19:49:18.066341Z","shell.execute_reply":"2024-03-26T19:50:37.973862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################## ARCHIVE CODE ##########################\n'''\ndef evaluate_significance(model_1, model_2, test_loader):\n    accuracy_m1 = {}\n    accuracy_m2 = {}\n    # For model_1\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model_1.to(device)\n    model_2.to(device)\n    with torch.no_grad():\n        for i, (data, target) in enumerate(test_loader):\n            data, target = data.to(device), target.to(device)\n            output_1 = model_1(data)\n            output_2 = model_2(data)\n            _, predicted_1 = torch.max(output_1.data, 1)\n            _, predicted_2 = torch.max(output_2.data, 1)\n            total = target.size(0)\n            correct_1 = (predicted_1 == target).sum().item()\n            correct_2 = (predicted_2 == target).sum().item()\n            test_accuracy_1 = correct_1 / total\n            test_accuracy_2 = correct_2 / total\n            accuracy_m1[i] = test_accuracy_1\n            accuracy_m2[i] = test_accuracy_2\n    return accuracy_m1, accuracy_m2\n\nimport numpy as np\nmean_m1 = np.mean(list(acc_m1.values())).round(4)\nmean_m2 = np.mean(list(acc_m2.values())).round(4)\nmean_m1, mean_m2\n\nstd_m1 = np.std(list(acc_m1.values())).round(4)\nstd_m2 = np.std(list(acc_m2.values())).round(4)\nstd_m1, std_m2\n\nimport scipy\nscipy.stats.ttest_rel(list(acc_m1.values()), list(acc_m2.values()))\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#############################\n### Create Baseline Model ###\n#############################\n\nclass BaselineCNN(nn.Module):\n  def __init__(self,):\n    super().__init__()\n    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n    self.relu1 = nn.ReLU()\n    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n    self.relu2 = nn.ReLU()\n    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    self.flatten = nn.Flatten()\n    self.fc1 = nn.Linear(64 * 25 * 25, 128) # TODO: Make input size dynamic\n\n    self.relu3 = nn.ReLU()\n    self.fc2 = nn.Linear(128, 10)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.relu1(x)\n    x = self.pool1(x)\n\n    x = self.conv2(x)\n    x = self.relu2(x)\n    x = self.pool2(x)\n\n    x = self.flatten(x)\n    x = self.fc1(x)\n    x = self.relu3(x)\n    x = self.fc2(x)\n    return x\n    '''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nFURTHER ATTENTION BLOCKS\n------------------------------------\nclass LSKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    \n    # When groups == in_channels and out_channels == K * in_channels,\n    # where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    self.conv1_1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=(1, kernel_size), groups=in_channels)#DWConv\n    self.conv1_2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=(kernel_size, 1), groups=in_channels)#DWConv\n    self.conv2_1 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=(1, kernel_size),\n                             dilation=dilation, groups=in_channels, padding=4)#DWDilationConv\n    self.conv2_2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=(kernel_size, 1),\n                             dilation=dilation, groups=in_channels, padding=4)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1_1(x)\n    attn = self.conv1_2(attn)\n    attn = self.conv2_1(attn)\n    attn = self.conv2_2(attn)\n    attn = self.conv3(attn)\n    print(attn.shape)\n    return input * attn\n-----------------------------------\nclass KA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    # When groups == in_channels and out_channels == K * in_channels,\n    # where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=13, padding='same')\n\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n\n    return input * attn\n    \n'''","metadata":{},"execution_count":null,"outputs":[]}]}