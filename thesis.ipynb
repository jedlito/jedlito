{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Xi9z2tGsLgV_OMGB36wWYdspsBzsG8Sb","authorship_tag":"ABX9TyPua6D/VG55KQLJKEi/Yp89"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":67880,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":56596}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook contains the empirical study regarding the attention mechanism.","metadata":{}},{"cell_type":"markdown","source":"______________\n# FINAL STEPS:\n* Train networks on MNIST for X epochs\n* Train networks for augmented MNIST for X epochs\n* Ablation Study (VAN without LKA)\n* Compare Computational Costs (Deepspeed Profiler?)\n - Training time\n - Number of Modules\n - Number of parameters\n - FLOPs\n ","metadata":{}},{"cell_type":"code","source":"# Installation and import of relevant packages\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nimport platform\nimport random\nimport time\nimport torch\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import v2\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.profiler import profile, record_function, ProfilerActivity","metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1711009733593,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"hj481hNsaSLk","execution":{"iopub.status.busy":"2024-06-23T10:00:08.189137Z","iopub.execute_input":"2024-06-23T10:00:08.189700Z","iopub.status.idle":"2024-06-23T10:00:14.179912Z","shell.execute_reply.started":"2024-06-23T10:00:08.189659Z","shell.execute_reply":"2024-06-23T10:00:14.179125Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Get information about current runtime and package versions.\n\n# Check if CUDA is available\ncuda_available = torch.cuda.is_available()\n\n# Get CUDA device count\ncuda_device_count = torch.cuda.device_count() if cuda_available else 0\n\n# Get current CUDA device index\ncuda_device_index = torch.cuda.current_device() if cuda_available else None\n\n# Get name of current CUDA device\ncuda_device_name = torch.cuda.get_device_name(cuda_device_index) if cuda_available else None\n\n# Get CUDA capability of the device\ncuda_capability = torch.cuda.get_device_capability(cuda_device_index) if cuda_available else None\n\n# Get CUDA version\ncuda_version = torch.version.cuda if cuda_available else None\n\n# Get cuDNN version\ncudnn_version = torch.backends.cudnn.version() if cuda_available else None\n\n# Get PyTorch version\npytorch_version = torch.__version__\n\n# Get OS information\nos_info = platform.platform()\n\npython_version = platform.python_version()\n\n# Print the information\nenvironment_dict = {\"OS:\", os_info,\n                    \"GPU:\", cuda_device_name,\n                    \"PyTorch:\", pytorch_version,\n                    \"CUDA:\", cuda_version,\n                    \"cudnn:\", cudnn_version,\n                    \"Python Version:\", python_version\n                   }\nprint(\"OS:\", os_info)\nprint(\"GPU:\", cuda_device_name)\nprint(\"PyTorch:\", pytorch_version)\nprint(\"CUDA:\", cuda_version)\nprint(\"cudnn:\", cudnn_version)\nprint(\"Python Version:\", python_version)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:00:19.335251Z","iopub.execute_input":"2024-06-23T10:00:19.335973Z","iopub.status.idle":"2024-06-23T10:00:19.345048Z","shell.execute_reply.started":"2024-06-23T10:00:19.335942Z","shell.execute_reply":"2024-06-23T10:00:19.344055Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"OS: Linux-5.15.133+-x86_64-with-glibc2.31\nGPU: Tesla P100-PCIE-16GB\nPyTorch: 2.1.2\nCUDA: 12.1\ncudnn: 8900\nPython Version: 3.10.13\n","output_type":"stream"}]},{"cell_type":"code","source":"# List package versions\n!pip freeze","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:00:20.371855Z","iopub.execute_input":"2024-06-23T10:00:20.372534Z","iopub.status.idle":"2024-06-23T10:00:23.598765Z","shell.execute_reply.started":"2024-06-23T10:00:20.372483Z","shell.execute_reply":"2024-06-23T10:00:23.597274Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"absl-py==1.4.0\naccelerate==0.27.2\naccess==1.1.9\naffine==2.4.0\naiobotocore==2.11.2\naiofiles==22.1.0\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1701099469104/work\naiohttp-cors==0.7.0\naioitertools==0.11.0\naiorwlock==1.3.0\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1667935791922/work\naiosqlite==0.19.0\nalbumentations==1.4.0\nalembic==1.13.1\naltair==5.2.0\nannotated-types @ file:///home/conda/feedstock_root/build_artifacts/annotated-types_1696634205638/work\nannoy==1.17.3\nanyio @ file:///home/conda/feedstock_root/build_artifacts/anyio_1702909220329/work\napache-beam==2.46.0\naplus==0.11.0\nappdirs==1.4.4\narchspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386546427/work\narray-record==0.5.0\narrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\narviz==0.17.0\nastroid==3.0.3\nastropy==6.0.0\nastropy-iers-data==0.2024.2.19.0.28.47\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\nastunparse==1.6.3\nasync-lru==2.0.4\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1691763562544/work\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1704011227531/work\naudioread==3.0.1\nautopep8==2.0.4\nBabel==2.14.0\nbackoff==2.2.1\nbayesian-optimization==1.4.3\nbayespy==0.5.28\nbeatrix_jupyterlab @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-gpu_1704941576253/work/packages/beatrix_jupyterlab-2023.128.151533.tar.gz#sha256=8c6941d08ce18f5b9ea7719574d611c18163074ff8254e0734342014eb064a48\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1680888073205/work\nbidict==0.23.1\nbiopython==1.83\nblake3==0.2.1\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\nblessed==1.20.0\nblinker==1.7.0\nblis @ file:///home/conda/feedstock_root/build_artifacts/cython-blis_1696148805003/work\nblosc2==2.5.1\nbokeh @ file:///home/conda/feedstock_root/build_artifacts/bokeh_1706215790147/work\nboltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\nBoruta==0.3\nboto3==1.26.100\nbotocore==1.34.34\nbq_helper==0.4.1\nbqplot==0.12.43\nbranca==0.7.1\nbrewer2mpl==1.4.1\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work\nbrotlipy==0.7.0\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\ncachetools==4.2.4\nCartopy @ file:///home/conda/feedstock_root/build_artifacts/cartopy_1698172724393/work\ncatalogue @ file:///home/conda/feedstock_root/build_artifacts/catalogue_1695626339626/work\ncatalyst @ git+https://github.com/Philmod/catalyst.git@9420384a98c4b9d3b17b959e66f845b98457b545\ncatboost==1.2.2\ncategory-encoders==2.6.3\ncertifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1707022139797/work/certifi\ncesium==0.12.1\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\nchex==0.1.85\ncleverhans==4.0.0\nclick @ file:///home/conda/feedstock_root/build_artifacts/click_1692311806742/work\nclick-plugins==1.1.1\ncligj==0.7.2\ncloud-tpu-client==0.10\ncloud-tpu-profiler==2.4.0\ncloudpathlib @ file:///home/conda/feedstock_root/build_artifacts/cloudpathlib-meta_1697837790453/work\ncloudpickle==2.2.1\ncmdstanpy==1.2.1\ncmudict==1.0.18\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\ncolorcet==3.0.1\ncolorful==0.5.6\ncolorlog==6.8.2\ncolorlover==0.3.0\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1704278392174/work\nconda @ file:///home/conda/feedstock_root/build_artifacts/conda_1694556045812/work\nconda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1690880668143/work/src\nconda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\nconda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\nconfection @ file:///home/conda/feedstock_root/build_artifacts/confection_1701179074719/work\ncontextily==1.5.0\ncontourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1699041363598/work\nconvertdate==2.4.0\ncrcmod==1.7\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1701563205069/work\ncuda-python @ file:///opt/conda/conda-bld/cuda-python_1696638333144/work\ncudf @ file:///opt/conda/conda-bld/work/python/cudf\ncufflinks==0.17.3\ncuml @ file:///opt/conda/conda-bld/work/python\ncupy @ file:///home/conda/feedstock_root/build_artifacts/cupy-split_1707093121318/work\nCVXcanon==0.1.2\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\ncymem @ file:///home/conda/feedstock_root/build_artifacts/cymem_1695443485440/work\ncysignals==1.11.4\nCython==3.0.8\ncytoolz @ file:///home/conda/feedstock_root/build_artifacts/cytoolz_1706897049115/work\ndaal==2024.1.0\ndaal4py==2024.1.0\ndacite==1.8.1\ndask==2024.2.0\ndask-cuda @ file:///opt/conda/conda-bld/work\ndask-cudf @ file:///opt/conda/conda-bld/work/python/dask_cudf\ndataclasses-json==0.6.4\ndataproc_jupyter_plugin==0.1.66\ndatasets==2.1.0\ndatashader==0.16.0\ndatatile==1.0.3\ndb-dtypes==1.2.0\ndeap==1.4.1\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1695534290310/work\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\ndeepdiff==6.7.1\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\nDelorean==1.0.0\nDeprecated==1.2.14\ndeprecation==2.1.0\ndescartes==1.1.0\ndill==0.3.8\ndipy==1.8.0\ndistlib==0.3.8\ndistributed @ file:///home/conda/feedstock_root/build_artifacts/distributed_1689891044039/work\ndistro @ file:///home/conda/feedstock_root/build_artifacts/distro_1704321475663/work\ndm-tree==0.1.8\ndocker==7.0.0\ndocker-pycreds==0.4.0\ndocopt==0.6.2\ndocstring-parser==0.15\ndocstring-to-markdown==0.15\ndocutils==0.20.1\nearthengine-api==0.1.391\neasydict==1.12\neasyocr==1.7.1\necos==2.0.13\neli5==0.13.0\nemoji==2.10.1\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl#sha256=ab70aeb6172cde82508f7739f35ebc9918a3d07debeed637403c8f794ba3d3dc\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\nephem==4.1.5\nesda==2.5.1\nessentia==2.1b6.dev1110\net-xmlfile==1.1.0\netils==1.6.0\nexceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\nexplainable-ai-sdk==1.3.3\nFarama-Notifications==0.0.4\nfastai==2.7.14\nfastapi==0.108.0\nfastavro==1.9.3\nfastcore==1.5.29\nfastdownload==0.0.7\nfasteners==0.19\nfastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1703780968325/work/dist\nfastprogress==1.0.3\nfastrlock @ file:///home/conda/feedstock_root/build_artifacts/fastrlock_1702696298817/work\nfasttext==0.9.2\nfbpca==1.0\nfeather-format==0.4.1\nfeaturetools==1.29.0\nfilelock==3.13.1\nfiona==1.9.5\nfitter==1.7.0\nflake8==7.0.0\nflashtext==2.7\nFlask==3.0.2\nflatbuffers==23.5.26\nflax==0.8.1\nfolium==0.15.1\nfonttools==4.47.0\nfqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\nfrozendict==2.4.0\nfrozenlist @ file:///home/conda/feedstock_root/build_artifacts/frozenlist_1702645481127/work\nfsspec @ file:///home/conda/feedstock_root/build_artifacts/fsspec_1707102468451/work\nfuncy==2.0\nfury==0.9.0\nfuture==1.0.0\nfuzzywuzzy==0.18.0\ngast==0.5.4\ngatspy==0.3\ngcsfs==2023.12.2.post1\ngensim==4.3.2\ngeographiclib==2.0\nGeohash==1.0\ngeojson==3.1.0\ngeopandas==0.14.3\ngeoplot==0.5.1\ngeopy==2.4.1\ngeoviews==1.11.1\nggplot @ https://github.com/hbasria/ggpy/archive/0.11.5.zip#sha256=7df947ba3fd86d3757686afec264785ad8df38dc50ffb2d2d31064fb355f69b1\ngiddy==2.3.5\ngitdb==4.0.11\nGitPython==3.1.41\ngoogle-ai-generativelanguage==0.4.0\ngoogle-api-core==2.11.1\ngoogle-api-python-client==2.118.0\ngoogle-apitools==0.5.31\ngoogle-auth==2.26.1\ngoogle-auth-httplib2==0.1.1\ngoogle-auth-oauthlib==1.2.0\ngoogle-cloud-aiplatform==0.6.0a1\ngoogle-cloud-artifact-registry==1.10.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==2.34.4\ngoogle-cloud-bigtable==1.7.3\ngoogle-cloud-core==2.4.1\ngoogle-cloud-datastore==2.19.0\ngoogle-cloud-dlp==3.14.0\ngoogle-cloud-jupyter-config==0.0.5\ngoogle-cloud-language==2.13.1\ngoogle-cloud-monitoring==2.18.0\ngoogle-cloud-pubsub==2.19.0\ngoogle-cloud-pubsublite==1.9.0\ngoogle-cloud-recommendations-ai==0.7.1\ngoogle-cloud-resource-manager==1.11.0\ngoogle-cloud-spanner==3.40.1\ngoogle-cloud-storage==1.44.0\ngoogle-cloud-translate==3.12.1\ngoogle-cloud-videointelligence==2.13.1\ngoogle-cloud-vision==2.8.0\ngoogle-crc32c==1.5.0\ngoogle-generativeai==0.3.2\ngoogle-pasta==0.2.0\ngoogle-resumable-media==2.7.0\ngoogleapis-common-protos==1.62.0\ngplearn==0.4.2\ngpustat==1.0.0\ngpxpy==1.6.2\ngraphviz==0.20.1\ngreenlet==3.0.3\ngrpc-google-iam-v1==0.12.7\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpc-split_1677499296072/work\ngrpcio-status @ file:///home/conda/feedstock_root/build_artifacts/grpcio-status_1662108958711/work\ngviz-api==1.10.0\ngym==0.26.2\ngym-notices==0.0.8\ngymnasium==0.29.0\nh11==0.14.0\nh2o==3.44.0.3\nh5netcdf==1.3.0\nh5py==3.10.0\nhaversine==2.8.1\nhdfs==2.7.3\nhep-ml==0.7.2\nhijri-converter==2.3.1\nhmmlearn==0.3.0\nholidays==0.24\nholoviews==1.18.3\nhpsklearn==0.1.0\nhtml5lib==1.1\nhtmlmin==0.1.12\nhttpcore==1.0.4\nhttplib2==0.21.0\nhttptools==0.6.1\nhttpx==0.27.0\nhuggingface-hub==0.20.3\nhumanize==4.9.0\nhunspell==0.5.5\nhusl==4.0.3\nhydra-slayer==0.5.0\nhyperopt==0.2.7\nhypertools==0.8.0\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1701026962277/work\nigraph==0.11.4\nimagecodecs==2024.1.1\nImageHash==4.3.1\nimageio==2.33.1\nimbalanced-learn==0.12.0\nimgaug==0.4.0\nimportlib-metadata==6.11.0\nimportlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1699364556997/work\ninequality==1.0.1\niniconfig==2.0.0\nipydatawidgets==4.3.5\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1703631723894/work\nipyleaflet==0.18.2\nipympl==0.7.0\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1704718870316/work\nipython-genutils==0.2.0\nipython-sql==0.5.0\nipyvolume==0.6.3\nipyvue==1.10.1\nipyvuetify==1.8.10\nipywebrtc==0.6.0\nipywidgets==7.7.1\nisoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\nisort==5.13.2\nisoweek==1.3.3\nitsdangerous==2.1.2\nJanome==0.5.0\njaraco.classes==3.3.0\njax==0.4.23\njax-jumpy==1.0.0\njaxlib @ file:///tmp/jax/jaxlib-0.4.23.dev20240116-cp310-cp310-manylinux2014_x86_64.whl#sha256=2adde6b0fff8a64af0b461e617ac514b80d8ee4aa52f1b1cf9a9139f427be8ba\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\njeepney==0.8.0\njieba==0.42.1\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1654302431367/work\njmespath==1.0.1\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1691577114857/work\njson5==0.9.14\njsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\njsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1700159890288/work\njsonschema-specifications @ file:///tmp/tmpkv1z7p57/src\njupyter-console==6.6.3\njupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1699285872613/work\njupyter-http-over-ws==0.0.8\njupyter-lsp==1.5.1\njupyter-server-mathjax==0.2.6\njupyter-ydoc==0.2.5\njupyter_client==7.4.9\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1704727030956/work\njupyter_server==2.12.5\njupyter_server_fileid==0.9.1\njupyter_server_proxy==4.1.0\njupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1703611053195/work\njupyter_server_ydoc==0.8.0\njupyterlab==4.1.2\njupyterlab-lsp==5.0.3\njupyterlab-widgets==3.0.9\njupyterlab_git==0.44.0\njupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1700744013163/work\njupyterlab_server==2.25.2\njupytext==1.16.0\nkaggle==1.6.6\nkaggle-environments==1.14.3\nkagglehub==0.1.9\nkeras==3.0.5\nkeras-cv==0.8.2\nkeras-nlp==0.8.1\nkeras-tuner==1.4.6\nkernels-mixer==0.0.7\nkeyring==24.3.0\nkeyrings.google-artifactregistry-auth==1.1.2\nkfp==2.5.0\nkfp-pipeline-spec==0.2.2\nkfp-server-api==2.0.5\nkiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379902431/work\nkmapper==2.0.1\nkmodes==0.12.2\nkorean-lunar-calendar==0.3.1\nkornia==0.7.1\nkt-legacy==1.0.5\nkubernetes==26.1.0\nlangcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1636741340529/work\nlangid==1.1.6\nlazy_loader==0.3\nlearntools @ git+https://github.com/Kaggle/learntools@183cdad0530e7c898cd4658a63b579c54e91f056\nleven==1.0.4\nLevenshtein==0.25.0\nlibclang==16.0.6\nlibmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1692866066721/work/libmambapy\nlibpysal==4.9.2\nlibrosa==0.10.1\nlightgbm @ file:///tmp/lightgbm/lightgbm-4.2.0-py3-none-manylinux_2_31_x86_64.whl#sha256=26ed21477c12bb26edc4d6d51336cd43d5a8f7daf55ebbe27b0faf50ce96db23\nlightning-utilities==0.10.1\nlime==0.2.0.1\nline-profiler==4.1.2\nlinkify-it-py==2.0.3\nllvmlite==0.41.1\nlml==0.1.0\nlocket @ file:///home/conda/feedstock_root/build_artifacts/locket_1650660393415/work\nloguru==0.7.2\nLunarCalendar==0.0.9\nlxml==5.1.0\nlz4 @ file:///home/conda/feedstock_root/build_artifacts/lz4_1704831084136/work\nMako==1.3.2\nmamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1692866066721/work/mamba\nmapclassify==2.6.1\nmarisa-trie==1.1.0\nMarkdown==3.5.2\nmarkdown-it-py @ file:///home/conda/feedstock_root/build_artifacts/markdown-it-py_1686175045316/work\nmarkovify==0.9.4\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1695367434228/work\nmarshmallow==3.20.2\nmatplotlib==3.7.5\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work\nmatplotlib-venn==0.11.10\nmccabe==0.7.0\nmdit-py-plugins==0.4.0\nmdurl @ file:///home/conda/feedstock_root/build_artifacts/mdurl_1704317613764/work\nmemory-profiler==0.61.0\nmenuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\nmercantile==1.2.1\nmgwr==2.2.1\nmissingno==0.5.2\nmistune==0.8.4\nmizani==0.11.0\nml-dtypes==0.2.0\nmlcrate==0.2.0\nmlens==0.2.3\nmlxtend==0.23.1\nmmh3==4.1.0\nmne==1.6.1\nmnist==0.2.2\nmock==5.1.0\nmomepy==0.7.0\nmore-itertools==10.2.0\nmpld3==0.5.10\nmpmath==1.3.0\nmsgpack @ file:///home/conda/feedstock_root/build_artifacts/msgpack-python_1700926504817/work\nmsgpack-numpy==0.4.8\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1696716075096/work\nmultimethod==1.10\nmultipledispatch==1.0.0\nmultiprocess==0.70.16\nmunkres==1.1.4\nmurmurhash @ file:///home/conda/feedstock_root/build_artifacts/murmurhash_1695449783955/work\nmypy-extensions==1.0.0\nnamex==0.0.7\nnb-conda-kernels @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_kernels_1699980974206/work\nnb_conda @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_1704789357480/work\nnbclassic @ file:///home/conda/feedstock_root/build_artifacts/nbclassic_1683202081046/work\nnbclient==0.5.13\nnbconvert==6.4.5\nnbdime==3.2.0\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1690814868471/work\nndindex==1.8\nnest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1697083700168/work\nnetworkx==3.2.1\nnibabel==5.2.0\nnilearn==0.10.3\nninja==1.11.1.1\nnltk==3.2.4\nnose==1.3.7\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1680870634737/work\nnotebook_executor @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-gpu_1704941576253/work/packages/notebook_executor\nnotebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1682360583588/work\nnumba==0.58.1\nnumexpr==2.9.0\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\nnvidia-ml-py==11.495.46\nnvtx @ file:///home/conda/feedstock_root/build_artifacts/nvtx_1708093799817/work\noauth2client==4.1.3\noauthlib==3.2.2\nobjsize==0.6.1\nodfpy==1.4.1\nolefile==0.47\nonnx==1.15.0\nopencensus==0.11.4\nopencensus-context==0.1.3\nopencv-contrib-python==4.9.0.80\nopencv-python==4.9.0.80\nopencv-python-headless==4.9.0.80\nopenpyxl==3.1.2\nopenslide-python==1.3.1\nopentelemetry-api==1.22.0\nopentelemetry-exporter-otlp==1.22.0\nopentelemetry-exporter-otlp-proto-common==1.22.0\nopentelemetry-exporter-otlp-proto-grpc==1.22.0\nopentelemetry-exporter-otlp-proto-http==1.22.0\nopentelemetry-proto==1.22.0\nopentelemetry-sdk==1.22.0\nopentelemetry-semantic-conventions==0.43b0\nopt-einsum==3.3.0\noptax==0.1.9\noptuna==3.5.0\norbax-checkpoint==0.5.3\nordered-set==4.1.0\norderedmultidict==1.0.1\norjson==3.9.10\nortools==9.4.1874\nosmnx==1.9.1\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1691338815398/work\npackaging==21.3\npandas==2.1.4\npandas-datareader==0.10.0\npandas-profiling==3.6.6\npandas-summary==0.2.0\npandasql==0.7.3\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\npanel==1.3.8\npapermill==2.5.0\nparam==2.0.2\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\npartd @ file:///home/conda/feedstock_root/build_artifacts/partd_1695667515973/work\npath==16.10.0\npath.py==12.5.0\npathos==0.3.2\npathy @ file:///croot/pathy_1703688110387/work\npatsy==0.5.6\npdf2image==1.17.0\npettingzoo==1.24.0\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1667297516076/work\nphik==0.12.4\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\nPillow==9.5.0\npkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\nplatformdirs==4.2.0\nplotly==5.18.0\nplotly-express==0.4.1\nplotnine==0.13.0\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\npointpats==2.4.0\npolars==0.20.10\npolyglot==16.7.4\npooch==1.8.1\npox==0.3.4\nppca==0.0.4\nppft==1.7.6.8\npreprocessing==0.1.13\npreshed @ file:///home/conda/feedstock_root/build_artifacts/preshed_1695644760607/work\nprettytable==3.9.0\nprogressbar2==4.3.2\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1700579315247/work\npromise==2.3\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1702399386289/work\npronouncing==0.2.0\nprophet==1.1.1\nproto-plus @ file:///home/conda/feedstock_root/build_artifacts/proto-plus_1702003338643/work\nprotobuf==3.20.3\npsutil==5.9.3\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\npudb==2024.1\nPuLP==2.8.0\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\npy-cpuinfo==9.0.0\npy-spy==0.3.14\npy4j==0.10.9.7\npyaml==23.12.0\nPyArabic==0.6.15\npyarrow==11.0.0\npyasn1 @ file:///home/conda/feedstock_root/build_artifacts/pyasn1_1701287008248/work\npyasn1-modules @ file:///home/conda/feedstock_root/build_artifacts/pyasn1-modules_1695107857548/work\nPyAstronomy==0.20.0\npybind11==2.11.1\npyclipper==1.3.0.post5\npycodestyle==2.11.1\npycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\npycryptodome==3.20.0\npyct==0.5.0\npycuda==2024.1\npydantic==2.5.3\npydantic_core==2.14.6\npydegensac==0.1.2\npydicom==2.4.4\npydocstyle==6.3.0\npydot==1.4.2\npydub==0.25.1\npyemd==1.0.0\npyerfa==2.0.1.1\npyexcel-io==0.6.6\npyexcel-ods==0.6.0\npyfasttext==0.4.6\npyflakes==3.2.0\npygltflib==1.16.1\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1700607939962/work\nPyJWT==2.8.0\npykalman==0.9.5\npyLDAvis==3.4.1\npylibraft @ file:///opt/conda/conda-bld/work/python/pylibraft\npylint==3.0.3\npymc3==3.11.4\nPyMeeus==0.5.12\npymongo==3.13.0\nPympler==1.0.1\npynndescent==0.5.11\npynvml @ file:///home/conda/feedstock_root/build_artifacts/pynvml_1639061605391/work\npynvrtc==9.2\npyocr==0.8.5\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1698795453264/work\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1690737849915/work\npypdf==4.0.2\npyproj @ file:///home/conda/feedstock_root/build_artifacts/pyproj_1702028071709/work\npysal==24.1\npyshp @ file:///home/conda/feedstock_root/build_artifacts/pyshp_1659002966020/work\nPySocks @ file:///home/builder/ci_310/pysocks_1640793678128/work\npytesseract==0.3.10\npytest==8.0.1\npython-bidi==0.4.2\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\npython-dotenv==1.0.0\npython-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\npython-Levenshtein==0.25.0\npython-louvain==0.16\npython-lsp-jsonrpc==1.1.2\npython-lsp-server==1.10.0\npython-slugify==8.0.4\npython-utils==3.8.2\npythreejs==2.4.2\npytoolconfig==1.3.1\npytools==2023.1.1\npytorch-ignite==0.4.13\npytorch-lightning==2.2.0.post0\npytz==2023.3.post1\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\nPyUpSet==0.1.1.post7\npyviz_comms==3.0.1\nPyWavelets==1.5.0\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1695373428874/work\npyzmq==24.0.1\nqgrid==1.3.1\nqtconsole==5.5.1\nQtPy==2.4.1\nquantecon==0.7.1\nquantities==0.15.0\nqudida==0.0.4\nraft-dask @ file:///opt/conda/conda-bld/work/python/raft-dask\nrapidfuzz==3.6.1\nrasterio==1.3.9\nrasterstats==0.19.0\nray==2.9.0\nray-cpp==2.9.0\nreferencing @ file:///home/conda/feedstock_root/build_artifacts/referencing_1704489226496/work\nregex==2023.12.25\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\nrequests-oauthlib==1.3.1\nrequests-toolbelt==0.10.1\nresponses==0.18.0\nretrying==1.3.3\nrfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\nrfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\nrgf-python==3.12.0\nrich @ file:///home/conda/feedstock_root/build_artifacts/rich-split_1700160075651/work/dist\nrich-click==1.7.3\nrmm @ file:///opt/conda/conda-bld/work/python\nrope==1.12.0\nrpds-py @ file:///home/conda/feedstock_root/build_artifacts/rpds-py_1703822618592/work\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1658328885051/work\nRtree==1.2.0\nruamel-yaml-conda @ file:///home/builder/ci_310/ruamel_yaml_1640794439226/work\nruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1698138615000/work\nruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\ns2sphere==0.2.5\ns3fs==2024.2.0\ns3transfer==0.6.2\nsafetensors==0.4.2\nscattertext==0.1.19\nscikit-image==0.22.0\nscikit-learn==1.2.2\nscikit-learn-intelex==2024.1.0\nscikit-multilearn==0.2.0\nscikit-optimize==0.9.0\nscikit-plot==0.3.7\nscikit-surprise==1.1.3\nscipy==1.11.4\nseaborn==0.12.2\nSecretStorage==3.3.3\nsegment_anything @ git+https://github.com/facebookresearch/segment-anything.git@6fdee8f2727f4506cfbbe553e23b895e27956588\nsegregation==2.5\nsemver==3.0.2\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1682601222253/work\nsentencepiece==0.2.0\nsentry-sdk==1.40.5\nsetproctitle==1.3.3\nsetuptools-git==1.2\nsetuptools-scm==8.0.4\nshap==0.44.1\nShapely==1.8.5.post1\nshellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1698144360966/work\nShimmy==1.3.0\nsimpervisor==1.0.0\nSimpleITK==2.3.1\nsimplejson==3.19.2\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\nsklearn-pandas==2.2.0\nslicer==0.0.7\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_split_1694066705667/work/dist\nsmhasher==0.150.1\nsmmap==5.0.1\nsniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1662051266223/work\nsnowballstemmer==2.2.0\nsnuggs==1.4.7\nsortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1621217038088/work\nsoundfile==0.12.1\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\nsoxr==0.3.7\nspacy @ file:///home/conda/feedstock_root/build_artifacts/spacy_1699194962107/work\nspacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1674550301837/work\nspacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1694527114282/work\nspaghetti==1.7.5.post1\nspectral==0.23.1\nspglm==1.1.0\nsphinx-rtd-theme==0.2.4\nspint==1.0.7\nsplot==1.1.5.post1\nspopt==0.6.0\nspreg==1.4.2\nspvcm==0.3.0\nSQLAlchemy==2.0.25\nsqlparse==0.4.4\nsquarify==0.4.3\nsrsly @ file:///home/conda/feedstock_root/build_artifacts/srsly_1695653949688/work\nstable-baselines3==2.1.0\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\nstanio==0.3.0\nstarlette==0.32.0.post1\nstatsmodels==0.14.1\nstemming==1.0.1\nstop-words==2018.7.23\nstopit==1.1.2\nstumpy==1.12.0\nsympy==1.12\ntables==3.9.2\ntabulate==0.9.0\ntangled-up-in-unicode==0.2.0\ntbb==2021.11.0\ntblib @ file:///home/conda/feedstock_root/build_artifacts/tblib_1702066284995/work\ntenacity==8.2.3\ntensorboard==2.15.1\ntensorboard-data-server==0.7.2\ntensorboard-plugin-profile==2.15.0\ntensorboardX==2.6.2.2\ntensorflow==2.15.0\ntensorflow-cloud==0.1.16\ntensorflow-datasets==4.9.4\ntensorflow-decision-forests==1.8.1\ntensorflow-estimator==2.15.0\ntensorflow-hub==0.16.1\ntensorflow-io==0.35.0\ntensorflow-io-gcs-filesystem==0.35.0\ntensorflow-metadata==0.14.0\ntensorflow-probability==0.23.0\ntensorflow-serving-api==2.14.1\ntensorflow-text==2.15.0\ntensorflow-transform==0.14.0\ntensorpack==0.11\ntensorstore==0.1.53\ntermcolor==2.4.0\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1699810101464/work\ntestpath==0.6.0\ntext-unidecode==1.3\ntextblob==0.18.0.post0\ntexttable==1.7.0\ntf-keras==2.15.0\ntfp-nightly @ git+https://github.com/tensorflow/probability.git@fbc5ebe9b1d343113fb917010096cfd88b32eecf\nTheano==1.0.5\nTheano-PyMC==1.1.2\nthinc @ file:///home/conda/feedstock_root/build_artifacts/thinc_1703842165913/work\nthreadpoolctl==3.2.0\ntifffile==2023.12.9\ntimm==0.9.16\ntinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1666100256010/work\ntobler==0.11.2\ntokenizers==0.15.2\ntoml==0.10.2\ntomli==2.0.1\ntomlkit==0.12.3\ntoolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1706112571092/work\ntorch @ file:///tmp/torch/torch-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=ae3259980b8d6551608b32fde2695baca64c72ed15ab2332023a248c113815a8\ntorchaudio @ file:///tmp/torch/torchaudio-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=10966b20361b49bc41b6c6ba842d3ea842320fb8c589823b4120f24a98013b4a\ntorchdata==0.7.1\ntorchinfo==1.8.0\ntorchmetrics==1.3.1\ntorchtext @ file:///tmp/torch/torchtext-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=a2a382655a08e1f6eeab6a307d0c8d78139cfa04cc329a7dc15a3f7c1e6e7a19\ntorchvision @ file:///tmp/torch/torchvision-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=105901a20924f652ee62df0bb57580c67725eb21f11a349658952c4be2050d94\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1695373560918/work\nTPOT==0.12.1\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1691671248568/work\ntraceml==1.0.8\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1675110562325/work\ntraittypes==0.2.1\ntransformers==4.38.1\ntreelite==3.2.0\ntreelite-runtime==3.2.0\ntrueskill==0.4.5\ntruststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\ntrx-python==0.2.9\ntsfresh==0.20.2\ntypeguard==4.1.5\ntyper @ file:///home/conda/feedstock_root/build_artifacts/typer_1683029246636/work\ntypes-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1704512562698/work\ntyping-inspect==0.9.0\ntyping-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1702176139754/work\ntzdata==2023.4\ntzlocal==5.2\nuc-micro-py==1.0.3\nucx-py @ file:///opt/conda/conda-bld/work\nujson==5.9.0\numap-learn==0.5.5\nunicodedata2 @ file:///home/conda/feedstock_root/build_artifacts/unicodedata2_1695847980273/work\nUnidecode==1.3.8\nupdate-checker==0.18.0\nuri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\nuritemplate==3.0.1\nurllib3==1.26.18\nurwid==2.6.4\nurwid_readline==0.13\nuvicorn==0.25.0\nuvloop==0.19.0\nvaex==4.17.0\nvaex-astro==0.9.3\nvaex-core==4.17.1\nvaex-hdf5==0.14.1\nvaex-jupyter==0.8.2\nvaex-ml==0.18.3\nvaex-server==0.9.0\nvaex-viz==0.5.4\nvec_noise==1.1.4\nvecstack==0.4.0\nvirtualenv==20.21.0\nvisions==0.7.5\nvowpalwabbit==9.9.0\nvtk==9.3.0\nWand==0.6.13\nwandb==0.16.3\nwasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1686131297168/work\nwatchfiles==0.21.0\nwavio==0.0.8\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\nweasel @ file:///home/conda/feedstock_root/build_artifacts/weasel_1699295455892/work\nwebcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1679900785843/work\nwebencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\nwebsocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1701630677416/work\nwebsockets==12.0\nWerkzeug==3.0.1\nwfdb==4.1.2\nwhatthepatch==1.0.5\nwidgetsnbextension==3.6.6\nwitwidget==1.8.1\nwoodwork==0.28.0\nwordcloud==1.9.3\nwordsegment==1.3.1\nwrapt==1.14.1\nxarray==2024.2.0\nxarray-einstats==0.7.0\nxgboost==2.0.3\nxvfbwrapper==0.2.9\nxxhash==3.4.1\nxyzservices @ file:///home/conda/feedstock_root/build_artifacts/xyzservices_1698325309404/work\ny-py==0.6.2\nyapf==0.40.2\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1701168553642/work\nydata-profiling==4.6.4\nyellowbrick==1.5\nypy-websocket==0.8.4\nzict @ file:///home/conda/feedstock_root/build_artifacts/zict_1681770155528/work\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1695255097490/work\nzstandard==0.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"######################################\n### CREATE CLUTTERED MNIST DATASET ###\n######################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Transformation classes\n\nclass RandomPlacement(object):\n  def __call__(self, img):\n    canvas = torch.zeros(1,100,100)\n    x = torch.randint(0, 73, (1,))\n    y = torch.randint(0, 73, (1,))\n    canvas[:, x:x+28, y:y+28] = img\n\n    return canvas\n\nclass RandomCropAndCombine(object):\n  def __init__(self, dataset):\n    self.dataset = dataset\n\n  def __call__(self, canvas):\n    for _ in range(8):\n      img, _ = random.choice(self.dataset)\n      img = transforms.ToTensor()(img)\n      x = torch.randint(0, 91, (1,))\n      y = torch.randint(0, 91, (1,))\n      patch = transforms.RandomCrop((9,9))(img)\n      canvas[:, x:x+9, y:y+9] += patch\n      canvas = canvas.clamp(0, 1)\n\n    return canvas","metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1711009738485,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"YM6ay7S8Vu6-","execution":{"iopub.status.busy":"2024-06-23T10:00:28.079645Z","iopub.execute_input":"2024-06-23T10:00:28.079981Z","iopub.status.idle":"2024-06-23T10:00:28.089266Z","shell.execute_reply.started":"2024-06-23T10:00:28.079953Z","shell.execute_reply":"2024-06-23T10:00:28.088198Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create cluttered MNIST dataset, split datasets and create DataLoaders.\n\n# Set seed for reproducability\ntorch.manual_seed(1)\nnp.random.seed(1)\ngenerator = torch.Generator().manual_seed(1)\n\n# Set batch size parameter\nBATCH_SIZE = 128\n\n# Define data transformations\noriginal_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\nmnist_original = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=None)\naugmented_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,)),\n    #transforms.RandomRotation(30),\n    RandomPlacement(),\n    RandomCropAndCombine(mnist_original),\n])\n\n# Train datasets\nmnist_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=original_transform)\naugmented_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=augmented_transform)\n\n# Test datasets\naugmented_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=augmented_transform)\nmnist_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=original_transform)\n\n# Split train dataset into 90% train and 10% validation data\nmnist_train, mnist_val = torch.utils.data.random_split(dataset=mnist_dataset_train, lengths=[0.9, 0.1], generator=generator)\naugmented_train, augmented_val = torch.utils.data.random_split(dataset=augmented_dataset_train, lengths=[0.9, 0.1], generator=generator)\n\n# Create data loaders for original and augmented datasets\n\n# Load train data\nmnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=BATCH_SIZE, shuffle=True)\ntrain_loader = torch.utils.data.DataLoader(dataset=augmented_train, batch_size=BATCH_SIZE, shuffle=True)\n# Load validation data\nmnist_val_loader = torch.utils.data.DataLoader(dataset=mnist_val, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset=augmented_val, batch_size=BATCH_SIZE, shuffle=True)\n# Load test data\ntest_loader = torch.utils.data.DataLoader(dataset=augmented_dataset_test, batch_size=BATCH_SIZE, shuffle=False)\nmnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_dataset_test, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:00:31.140479Z","iopub.execute_input":"2024-06-23T10:00:31.140821Z","iopub.status.idle":"2024-06-23T10:00:33.172785Z","shell.execute_reply.started":"2024-06-23T10:00:31.140797Z","shell.execute_reply":"2024-06-23T10:00:33.171804Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 45905266.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1530998.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 12046093.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 4122598.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the original and the augmented dataset\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\nfor i in range(4):\n  original_img, _ = mnist_original[i]\n  original_img = transforms.ToTensor()(original_img).squeeze(0)\n  axes[0, i].imshow(original_img, cmap='gray')\n  axes[0, i].axis('off')\n  axes[0, i].set_title('Original')\n\n  augmented_img, _ = augmented_dataset_train[i]\n  augmented_img = augmented_img.squeeze(0)\n  axes[1, i].imshow(augmented_img, cmap='gray')\n  axes[1, i].axis('off')\n  axes[1, i].set_title('Transformed')\n    \nplt.tight_layout()\nplt.show()","metadata":{"executionInfo":{"elapsed":822,"status":"ok","timestamp":1711014574594,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"kGbbSYiscR-9","outputId":"94d74291-72ba-4227-c66c-289378c48520","execution":{"iopub.status.busy":"2024-06-23T10:00:40.849134Z","iopub.execute_input":"2024-06-23T10:00:40.849492Z","iopub.status.idle":"2024-06-23T10:00:41.739421Z","shell.execute_reply.started":"2024-06-23T10:00:40.849462Z","shell.execute_reply":"2024-06-23T10:00:41.738555Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 8 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"###############################################################\n### Helper Trainer Class to faciliate training the networks ###\n###############################################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer():\n    def __init__(self, model, optimizer, train_loader, val_loader, test_loader,\n                 num_epochs, estimate_step=100, save_checkpoints=True, path='model'):\n        \n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n        self.criterion = nn.CrossEntropyLoss()\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.num_epochs = num_epochs\n        self.estimate_step = estimate_step\n        self.model_name = type(self.model).__name__\n        self.path = path\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.save_checkpoints = save_checkpoints\n        self.running_loss_train = []\n        self.running_loss_val = []\n        self.train_time_per_epoch = []\n        self.total_epochs_trained = 0\n        self.test_accuracy = None\n        self.inference_time = None\n\n    \n    def train(self):\n        '''\n        Function to train the model. Trains the model on a training dataset and evaluates the current performance\n        on a validation dataset at the end of each epoch. Reduces the learning rate, if there is no\n        improvement in the validation loss for 10 epochs. \n        '''\n        self.model.to(self.device)\n        self.model.train()\n        for epoch in range(self.num_epochs):\n            # Start timer\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            start_epoch = time.time()\n            \n            # Training process for one epoch\n            self.model.train(True)\n            running_loss_train = 0.00\n            for batch_idx, (data, target) in enumerate(self.train_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                self.optimizer.zero_grad(set_to_none=True)\n                output = self.model(data)\n                loss = self.criterion(output, target)\n                running_loss_train += loss.item()\n                loss.backward()\n                self.optimizer.step()\n                if batch_idx % self.estimate_step == 0:\n                    print(f'Epoch {epoch+1}/{self.num_epochs}, Batch {batch_idx}/{len(self.train_loader)}, Train Loss: {loss.item():.4f}')     \n            avg_loss_train = running_loss_train / len(self.train_loader)\n            self.running_loss_train.append(avg_loss_train)\n            \n            # Validate model at the end of each epoch\n            self.model.eval()\n            running_loss_val = 0.00\n            with torch.no_grad():\n                for i, (data_val, target_val) in enumerate(self.val_loader):\n                    data_val, target_val = data_val.to(self.device), target_val.to(self.device)\n                    output_val = self.model(data_val)\n                    loss_val = self.criterion(output_val, target_val)\n                    running_loss_val += loss_val.item()\n                avg_loss_val = running_loss_val / len(self.val_loader)\n                self.running_loss_val.append(avg_loss_val)\n            \n            # Recuce LR if model does not improve for 10 epochs\n            self.scheduler.step(avg_loss_val)\n            \n            # Track training time for each epoch\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            end_epoch = time.time()\n            self.train_time_per_epoch.append(end_epoch-start_epoch)\n            print(f'Model {self.model_name} at epoch {epoch+1}/{self.num_epochs}: Avg Train Loss: {avg_loss_train:.4f}, Avg Val Loss: {avg_loss_val:.4f}')\n            \n            # Increase epoch counter\n            self.total_epochs_trained += 1\n            \n            # Save checkpoint at the end of each epoch\n            if self.save_checkpoints:\n                self.save_checkpoint(self.path)\n            \n        # Print total training time at the end\n        train_time = \"{:.2f} minutes\".format(sum(self.train_time_per_epoch) / 60)\n        print(f'Model {self.model_name} took {train_time} to run on {self.total_epochs_trained} epochs.')\n        \n                \n    def eval(self):\n        '''\n        Function to evaluate the performance of the model.\n        Therefore, the models accuracy on a test dataset is measured.\n        '''\n        self.model.to(self.device)\n        self.model.eval()\n        correct = 0\n        total = 0\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        start_eval = time.time()\n        with torch.no_grad():\n            for data, target in self.test_loader:\n                data, target = data.to(self.device), target.to(self.device)\n                output = self.model(data)\n                _, predicted = torch.max(output.data, 1)\n                total += target.size(0)\n                correct += (predicted == target).sum().item()\n        self.test_accuracy = correct / total\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        end_eval = time.time()\n        self.inference_time = end_eval - start_eval\n        print(f'Test Accuracy for {self.model_name}: {self.test_accuracy:.4f} - in {self.inference_time} seconds.')\n        \n    def save_checkpoint(self, path):\n        '''\n        Function to save the current state of the model, optimizer and scheduler.\n        Also saves the model metrics training loss, validation loss, accuracy,\n        training and inference time.\n        '''\n        torch.save({'epoch': self.total_epochs_trained,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'scheduler_state_dict': self.scheduler.state_dict(),\n                    'loss': self.running_loss_train[-1],\n                    'running_loss_train': self.running_loss_train,\n                    'running_loss_val': self.running_loss_val,\n                    'test_accuracy': self.test_accuracy,\n                    'train_time': self.train_time_per_epoch,\n                    'inference_time': self.inference_time}, \n                    f'{path}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:00:44.111824Z","iopub.execute_input":"2024-06-23T10:00:44.112164Z","iopub.status.idle":"2024-06-23T10:00:44.137093Z","shell.execute_reply.started":"2024-06-23T10:00:44.112137Z","shell.execute_reply":"2024-06-23T10:00:44.136159Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"###############################################\n### CNN model for MNIST and cluttered MNIST ###\n###############################################\n# NOTE: Only difference if the models is the linear layer fc1. Input features needs adjustment as the size of the input images is different.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n####### CNN Model MNIST #######\n###############################\nclass CNN_MNIST(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(CNN_MNIST, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(9216, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:00:46.460785Z","iopub.execute_input":"2024-06-23T10:00:46.461504Z","iopub.status.idle":"2024-06-23T10:00:46.469477Z","shell.execute_reply.started":"2024-06-23T10:00:46.461474Z","shell.execute_reply":"2024-06-23T10:00:46.468598Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#################################\n####### CNN Model Clutter #######\n#################################\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(147456, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x","metadata":{"id":"Wdk5Gp7tlc4s","executionInfo":{"status":"ok","timestamp":1711019808528,"user_tz":-60,"elapsed":1920959,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"357f0e45-2497-42e1-bb5c-1f23c3ae1434","execution":{"iopub.status.busy":"2024-06-23T10:00:47.561704Z","iopub.execute_input":"2024-06-23T10:00:47.562051Z","iopub.status.idle":"2024-06-23T10:00:47.570416Z","shell.execute_reply.started":"2024-06-23T10:00:47.562024Z","shell.execute_reply":"2024-06-23T10:00:47.569571Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"###############################################\n### VAN model for MNIST and cluttered MNIST ###\n###############################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###############################\n####### VAN Model MNIST #######\n###############################\nclass Downsampling_MNIST(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block_MNIST(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA_MNIST(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN_MNIST(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN_MNIST(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA_MNIST(nn.Module):\n  def __init__(self, in_channels, out_channels, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=5, groups=in_channels)#DW-Conv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=5,\n                           dilation=3, groups=in_channels, padding=8)#DW-D-Conv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1) #1x1 Conv\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN_MNIST(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling_MNIST(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block_MNIST(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:02:58.919544Z","iopub.execute_input":"2024-06-23T10:02:58.919948Z","iopub.status.idle":"2024-06-23T10:02:58.943659Z","shell.execute_reply.started":"2024-06-23T10:02:58.919918Z","shell.execute_reply":"2024-06-23T10:02:58.942715Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#################################\n####### VAN Model Clutter #######\n#################################\nclass Downsampling(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) \n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA(nn.Module):\n  def __init__(self, in_channels, out_channels, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    \n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=5, groups=in_channels)#DW-Conv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=5,\n                           dilation=3, groups=in_channels, padding=8)#DW-D-Conv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1) #1x1 Conv\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:03:23.449571Z","iopub.execute_input":"2024-06-23T10:03:23.450178Z","iopub.status.idle":"2024-06-23T10:03:23.474357Z","shell.execute_reply.started":"2024-06-23T10:03:23.450145Z","shell.execute_reply":"2024-06-23T10:03:23.473562Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"################################\n### TRAINING OF THE NETWORKS ###\n################################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################\n### CNN Training ###\n####################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize CNN on MNIST\ncnn_mnist = CNN_MNIST()\ncnn_mnist_optimizer = optim.AdamW(cnn_mnist.parameters(), lr=1e-3)\ncnn_mnist_trainer = Trainer(model=cnn_mnist, optimizer=cnn_mnist_optimizer,\n                            train_loader=mnist_train_loader, val_loader=mnist_val_loader, test_loader=mnist_test_loader,\n                            num_epochs=25, save_checkpoints=True, path=f'CNN_MNIST()')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:45:25.629419Z","iopub.execute_input":"2024-06-21T18:45:25.629791Z","iopub.status.idle":"2024-06-21T18:45:25.649282Z","shell.execute_reply.started":"2024-06-21T18:45:25.629763Z","shell.execute_reply":"2024-06-21T18:45:25.648549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train CNN on MNIST\ncnn_mnist_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:45:29.574739Z","iopub.execute_input":"2024-06-21T18:45:29.575445Z","iopub.status.idle":"2024-06-21T18:50:46.680737Z","shell.execute_reply.started":"2024-06-21T18:45:29.575415Z","shell.execute_reply":"2024-06-21T18:50:46.679709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate CNN on MNIST\ncnn_mnist_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:50:46.682415Z","iopub.execute_input":"2024-06-21T18:50:46.682734Z","iopub.status.idle":"2024-06-21T18:50:48.573576Z","shell.execute_reply.started":"2024-06-21T18:50:46.682703Z","shell.execute_reply":"2024-06-21T18:50:48.572666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize CNN on cluterred MNIST\ncnn_clutter = CNN()\ncnn_clutter_optimizer = optim.AdamW(cnn_clutter.parameters(), lr=1e-3)\ncnn_clutter_trainer = Trainer(model=cnn_clutter, optimizer=cnn_clutter_optimizer,\n                            train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                            num_epochs=50, save_checkpoints=True, path=f'CNN_CLUTTER()')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:00:33.264197Z","iopub.execute_input":"2024-06-21T18:00:33.265015Z","iopub.status.idle":"2024-06-21T18:00:33.453917Z","shell.execute_reply.started":"2024-06-21T18:00:33.264981Z","shell.execute_reply":"2024-06-21T18:00:33.453077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train CNN on cluttered MNIST\ncnn_clutter_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:00:40.724465Z","iopub.execute_input":"2024-06-21T18:00:40.725184Z","iopub.status.idle":"2024-06-21T18:36:36.229263Z","shell.execute_reply.started":"2024-06-21T18:00:40.725152Z","shell.execute_reply":"2024-06-21T18:36:36.227779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate CNN on cluterred MNIST\ncnn_clutter_trainer.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################\n### VAN Training ###\n####################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize VAN on MNIST\nvan_mnist = VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_mnist_optimizer = optim.AdamW(van_mnist.parameters(), lr=1e-3)\nvan_mnist_trainer = Trainer(model=van_mnist, optimizer=van_mnist_optimizer,\n                            train_loader=mnist_train_loader, val_loader=mnist_val_loader, test_loader=mnist_test_loader,\n                            num_epochs=25, save_checkpoints=True, path=f'VAN_MNIST(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])')","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:03:30.198068Z","iopub.execute_input":"2024-06-23T10:03:30.198423Z","iopub.status.idle":"2024-06-23T10:03:30.217720Z","shell.execute_reply.started":"2024-06-23T10:03:30.198395Z","shell.execute_reply":"2024-06-23T10:03:30.216856Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Train VAN on MNIST\nvan_mnist_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:03:32.137562Z","iopub.execute_input":"2024-06-23T10:03:32.137915Z","iopub.status.idle":"2024-06-23T10:03:50.082831Z","shell.execute_reply.started":"2024-06-23T10:03:32.137886Z","shell.execute_reply":"2024-06-23T10:03:50.081558Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/25, Batch 0/422, Train Loss: 2.3085\nEpoch 1/25, Batch 100/422, Train Loss: 0.1981\nEpoch 1/25, Batch 200/422, Train Loss: 0.1124\nEpoch 1/25, Batch 300/422, Train Loss: 0.0540\nEpoch 1/25, Batch 400/422, Train Loss: 0.0688\nModel VAN_MNIST at epoch 1/25: Avg Train Loss: 0.3032, Avg Val Loss: 0.0836\nEpoch 2/25, Batch 0/422, Train Loss: 0.0560\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train VAN on MNIST\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvan_mnist_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 45\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, target)\n\u001b[1;32m     47\u001b[0m running_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[12], line 120\u001b[0m, in \u001b[0;36mVAN_MNIST.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    117\u001b[0m     x \u001b[38;5;241m=\u001b[39m blk(x)\n\u001b[1;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate VAN on MNIST\nvan_mnist_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:03:53.235127Z","iopub.execute_input":"2024-06-23T10:03:53.235489Z","iopub.status.idle":"2024-06-23T10:03:55.524339Z","shell.execute_reply.started":"2024-06-23T10:03:53.235461Z","shell.execute_reply":"2024-06-23T10:03:55.523387Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN_MNIST: 0.9794 - in 2.2821242809295654 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize VAN on cluttered MNIST\nvan_clutter = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_clutter_optimizer = optim.AdamW(van_clutter.parameters(), lr=1e-3)\nvan_clutter_trainer = Trainer(model=van_clutter, optimizer=van_clutter_optimizer,\n                              train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                              num_epochs=50, save_checkpoints=True, path=f'VAN_CLUTTER(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])')","metadata":{"execution":{"iopub.status.busy":"2024-06-22T07:27:09.050714Z","iopub.execute_input":"2024-06-22T07:27:09.051648Z","iopub.status.idle":"2024-06-22T07:27:09.068212Z","shell.execute_reply.started":"2024-06-22T07:27:09.051614Z","shell.execute_reply":"2024-06-22T07:27:09.067209Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train VAN on cluttered MNIST\nvan_clutter_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T07:27:12.899814Z","iopub.execute_input":"2024-06-22T07:27:12.900504Z","iopub.status.idle":"2024-06-22T07:28:08.427015Z","shell.execute_reply.started":"2024-06-22T07:27:12.900470Z","shell.execute_reply":"2024-06-22T07:28:08.425412Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/50, Batch 0/422, Train Loss: 2.3171\nEpoch 1/50, Batch 100/422, Train Loss: 1.3822\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train VAN on cluttered MNIST\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvan_clutter_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m running_loss_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m     43\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:359\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Normalize a float tensor image with mean and standard deviation.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03mThis transform does not support PIL Image.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m--> 359\u001b[0m     \u001b[43m_log_api_usage_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/utils.py:582\u001b[0m, in \u001b[0;36m_log_api_usage_once\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, FunctionType):\n\u001b[1;32m    581\u001b[0m     name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 582\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_api_usage_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Evaluate VAN on cluttered MNIST\nvan_clutter_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T07:28:12.914968Z","iopub.execute_input":"2024-06-22T07:28:12.915348Z","iopub.status.idle":"2024-06-22T07:28:50.765583Z","shell.execute_reply.started":"2024-06-22T07:28:12.915317Z","shell.execute_reply":"2024-06-22T07:28:50.764435Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN: 0.3547 - in 37.84108352661133 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"###Import function for checkpoints!###","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST CMAP\n! pip install grad-cam","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:05:11.026611Z","iopub.execute_input":"2024-06-23T10:05:11.026960Z","iopub.status.idle":"2024-06-23T10:05:37.003084Z","shell.execute_reply.started":"2024-06-23T10:05:11.026934Z","shell.execute_reply":"2024-06-23T10:05:37.001994Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Collecting grad-cam\n  Downloading grad-cam-1.5.2.tar.gz (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from grad-cam) (9.5.0)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (2.1.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from grad-cam) (0.16.2)\nCollecting ttach (from grad-cam)\n  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.66.1)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from grad-cam) (4.9.0.80)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from grad-cam) (3.7.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from grad-cam) (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->grad-cam) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->grad-cam) (2.31.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->grad-cam) (2.8.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->grad-cam) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.8.2->grad-cam) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\nDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nBuilding wheels for collected packages: grad-cam\n  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.5.2-py3-none-any.whl size=38336 sha256=8c0706e4a539fe7551cedf0356817765dc93f3635bd2b12fa9f0626c83096dc8\n  Stored in directory: /root/.cache/pip/wheels/b4/68/bb/d10381e86dc0de1c9354bce3d86bffcd247305058c40ce2e55\nSuccessfully built grad-cam\nInstalling collected packages: ttach, grad-cam\nSuccessfully installed grad-cam-1.5.2 ttach-0.0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import models, transforms\nfrom PIL import Image\n\n# Load the pre-trained model\n\ndef get_gradcam(model, img_tensor, target_layer):\n    def hook_function(module, grad_in, grad_out):\n        global gradients\n        gradients = grad_out[0]\n    \n    target_layer.register_forward_hook(hook_function)\n    \n    output = model(img_tensor)\n    pred_class = output.argmax(dim=1).item()\n    \n    model.zero_grad()\n    class_loss = output[0, pred_class]\n    class_loss.backward()\n    \n    grads = gradients\n    activations = target_layer.output[0]\n    \n    weights = torch.mean(grads, dim=(2, 3), keepdim=True)\n    cam = torch.sum(weights * activations, dim=1).squeeze().detach().numpy()\n    cam = np.maximum(cam, 0)\n    cam = cv2.resize(cam, (img_tensor.shape[2], img_tensor.shape[3]))\n    cam = cam - np.min(cam)\n    cam = cam / np.max(cam)\n    \n    return cam","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:27:39.965901Z","iopub.execute_input":"2024-06-23T10:27:39.966588Z","iopub.status.idle":"2024-06-23T10:27:39.989251Z","shell.execute_reply.started":"2024-06-23T10:27:39.966547Z","shell.execute_reply":"2024-06-23T10:27:39.988563Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef get_gradcam(model, image, target_layer):\n    activations = []\n    gradients = []\n\n    def forward_hook(module, input, output):\n        activations.append(output)\n\n    def backward_hook(module, grad_in, grad_out):\n        gradients.append(grad_out[0])\n\n    # Register hooks\n    hook_handles = []\n    hook_handles.append(target_layer.register_forward_hook(forward_hook))\n    hook_handles.append(target_layer.register_backward_hook(backward_hook))\n\n    # Add batch dimension and prepare the input\n    image = img_tensor.unsqueeze(0).unsqueeze(0)  # shape: [1, 1, 28, 28]\n\n    # Forward pass\n    model.eval()\n    output = model(image)\n    pred_class = output.argmax(dim=1).item()\n\n    # Backward pass\n    model.zero_grad()\n    output[0, pred_class].backward()\n\n    # Remove hooks\n    for handle in hook_handles:\n        handle.remove()\n\n    # Get gradients and activations\n    gradients = gradients[0].cpu().data.numpy()[0]\n    activations = activations[0].cpu().data.numpy()[0]\n\n    # Compute weights\n    weights = np.mean(gradients, axis=(1, 2))\n    cam = np.zeros(activations.shape[1:], dtype=np.float32)\n    for i, w in enumerate(weights):\n        cam += w * activations[i]\n\n    cam = np.maximum(cam, 0)\n    cam = cv2.resize(cam, (image.shape[2], image.shape[3]))  # Resize to input image dimensions\n    cam = cam - np.min(cam)\n    cam = cam / np.max(cam)\n\n    return cam\n\n# Get the Grad-CAM for the target layer (e.g., final block's FFN.conv3)\n\n# Overlay the Grad-CAM on the original image\ndef overlay_cam_on_image(image, cam, alpha=0.4):\n    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_MAGMA)\n    heatmap = np.float32(heatmap) / 255\n    image = image.numpy().transpose(1, 2, 0)\n    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n    overlay = heatmap + np.float32(image)\n    overlay = overlay / np.max(overlay)\n    return np.uint8(255 * overlay)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:54:26.446284Z","iopub.execute_input":"2024-06-23T10:54:26.446666Z","iopub.status.idle":"2024-06-23T10:54:26.459552Z","shell.execute_reply.started":"2024-06-23T10:54:26.446636Z","shell.execute_reply":"2024-06-23T10:54:26.458640Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# Import model\nckpt = torch.load('/kaggle/input/van-final/pytorch/van-clutter-mnist-final/1/VAN(channels64 128 stages2 l1 1 expansion_ratio2 4)_50_epochs_Acc_9922.pth', map_location='cpu')\nckpt_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nckpt_model.load_state_dict(ckpt['model_state_dict'])\nckpt_optimizer = optim.AdamW(ckpt_model.parameters(), lr=1e-3)\nckpt_optimizer.load_state_dict(ckpt['optimizer_state_dict'])\nckpt_trainer = Trainer(model=ckpt_model, optimizer=ckpt_optimizer,\n                       train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                       num_epochs=30, save_checkpoints=False, path=f'Ckpt_VAN()')\nckpt_trainer.scheduler.load_state_dict(ckpt['scheduler_state_dict'])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:34:04.791416Z","iopub.execute_input":"2024-06-23T10:34:04.792100Z","iopub.status.idle":"2024-06-23T10:34:04.882355Z","shell.execute_reply.started":"2024-06-23T10:34:04.792069Z","shell.execute_reply":"2024-06-23T10:34:04.881572Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"model = ckpt_model.cpu()\nmodel.eval()\n\naugmented_img, label = augmented_dataset_train[759]\ntarget_layer = model.cpu().block_2[-1].FFN.conv3  # Adjust according to the actual block/layer you want\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:43:48.852177Z","iopub.execute_input":"2024-06-23T10:43:48.852860Z","iopub.status.idle":"2024-06-23T10:43:48.866784Z","shell.execute_reply.started":"2024-06-23T10:43:48.852830Z","shell.execute_reply":"2024-06-23T10:43:48.865813Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"6\n","output_type":"stream"}]},{"cell_type":"code","source":"augmented_img = augmented_img.squeeze(0)\nimg_tensor = augmented_img\n\nimage = img_tensor.unsqueeze(0).to('cpu')\n\ncam = get_gradcam(model, image, target_layer)\noverlay = overlay_cam_on_image(image, cam)\n\n# Plot the result\nplt.imshow(overlay)\nplt.axis('off')\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:54:28.869716Z","iopub.execute_input":"2024-06-23T10:54:28.870328Z","iopub.status.idle":"2024-06-23T10:54:29.077810Z","shell.execute_reply.started":"2024-06-23T10:54:28.870298Z","shell.execute_reply":"2024-06-23T10:54:29.076866Z"},"trusted":true},"execution_count":116,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:52:19.192564Z","iopub.execute_input":"2024-06-23T10:52:19.192952Z","iopub.status.idle":"2024-06-23T10:52:19.197207Z","shell.execute_reply.started":"2024-06-23T10:52:19.192924Z","shell.execute_reply":"2024-06-23T10:52:19.196374Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objects as go\nimport torch\nimport torchvision.transforms as transforms\n\n# Assuming `cam` is the Grad-CAM heatmap and `image` is the original image tensor\n# Convert image tensor to numpy array for visualization\nimage_np = image.numpy().transpose(1, 2, 0)\n\n# Normalize and resize Grad-CAM heatmap\ncam_normalized = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))\ncam_resized = cv2.resize(cam_normalized, (image_np.shape[1], image_np.shape[0]))\n\n# Define custom colormap (blue to red)\ncolors = [(0, 'rgb(0, 0, 255)'), (1, 'rgb(255, 0, 0)')]  # Blue (low) to Red (high)\n\n# Create custom colorscale with blue for lowest values\ncolorscale = [\n    [0.0, 'rgb(0, 255, 0)'],\n    [np.min(cam_resized), 'rgb(0, 255, 0)'],\n    [np.min(cam_resized) + 0.001, 'rgb(255, 255, 255)'],\n    [1.0, 'rgb(128, 0, 128)']\n]\n\n# Create heatmap figure with Plotly\nfig = go.Figure()\n\n# Add original image as background\nfig.add_trace(go.Image(z=image_np))\n\n# Add heatmap overlay with custom colorscale\nfig.add_trace(go.Heatmap(z=cam_resized, colorscale=colorscale, showscale=False))\n\n# Configure layout\nfig.update_layout(title='Overlay with Custom Colorscale',\n                  xaxis=dict(visible=False),\n                  yaxis=dict(visible=False))\n\n# Show plot\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T10:50:24.578713Z","iopub.execute_input":"2024-06-23T10:50:24.579424Z","iopub.status.idle":"2024-06-23T10:50:24.601768Z","shell.execute_reply.started":"2024-06-23T10:50:24.579378Z","shell.execute_reply":"2024-06-23T10:50:24.600853Z"},"trusted":true},"execution_count":104,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"fd836ee9-7306-4611-8492-ff212e0fb321\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fd836ee9-7306-4611-8492-ff212e0fb321\")) {                    Plotly.newPlot(                        \"fd836ee9-7306-4611-8492-ff212e0fb321\",                        [{\"z\":[[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.08235294],[0.59607846],[0.59607846],[0.99607843],[0.99215686],[0.91764706],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.2901961],[0.9529412],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.32156864],[0.79607844],[0.8745098],[0.99215686],[0.9882353],[0.99215686],[0.9882353],[0.99215686],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.08627451],[0.9882353],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.21176471],[0.92156863],[0.8784314],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.28235295],[0.9137255],[1.0],[0.8352941],[0.4],[0.4],[0.32156864],[0.32156864],[0.8392157],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.07058824],[0.87058824],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.14509805],[0.92156863],[0.87058824],[0.36078432],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0627451],[0.0],[0.0],[0.0],[0.0],[0.0],[0.14901961],[0.6431373],[0.99607843],[0.9607843],[0.93333334],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.02745098],[0.019607844],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.2901961],[0.99607843],[0.99607843],[0.9098039],[0.76862746],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.1254902],[0.7764706],[0.5803922],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.15294118],[0.52156866],[0.4392157],[0.078431375],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.14509805],[0.88235295],[0.99607843],[0.92156863],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.14855757],[0.18674228],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.2758399],[1.0],[1.0],[1.0],[1.0],[0.50494814],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.61950225],[1.0],[1.0],[1.0],[1.0],[0.17401403],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.51767635],[1.0],[1.0],[1.0],[1.0],[0.79705215],[0.56794393],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.42857873],[1.0],[1.0],[1.0],[1.0],[0.77159566],[0.56794393],[0.14833608],[0.0],[0.0],[0.0],[0.0],[0.084916405],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.8115051],[0.56794393],[0.56794393],[0.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.73405635],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.56794393],[0.56794393],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.9631645],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.70859987],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.25038344],[1.0],[1.0],[1.0],[0.50494814],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.47949168],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.8995233],[1.0],[1.0],[1.0],[0.0],[0.12310111],[1.0],[1.0],[1.0],[1.0],[0.21219873],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.034003474],[0.0],[0.0],[0.14855757],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.46676344],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.22492696],[0.084916405],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.70859987],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.9758927],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[0.58131754],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.18674228],[0.42857873],[0.0],[0.3522093],[1.0],[1.0],[1.0],[1.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.09411765],[0.7764706],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.14509805],[0.22745098],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.07058824],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.99215686],[0.67058825],[0.03529412],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.09803922],[0.13725491],[1.0],[0.6627451],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.4],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.90588236],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.6862745],[0.99607843],[1.0],[0.99607843],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.4],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.18039216],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.19215687],[0.5568628],[1.0],[0.5568628],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.4],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.9529412],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.4],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.9607843],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.4],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.9764706],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.011764706],[0.8],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.6431373],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.25882354],[0.99607843],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.7254902],[0.4117647],[0.06666667],[0.0],[0.0],[0.0],[0.0],[0.3529412],[0.99607843],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]],[[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]]],\"type\":\"image\"},{\"colorscale\":[[0.0,\"rgb(0, 255, 0)\"],[0.0,\"rgb(0, 255, 0)\"],[0.001,\"rgb(255, 255, 255)\"],[1.0,\"rgb(128, 0, 128)\"]],\"showscale\":false,\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0000019878344,0.000005963503,0.000009939172,0.0000139148415,0.000023298158,0.000038089125,0.000052880092,0.00006767106,0.00006568323,0.00004691659,0.000028149952,0.000009383318,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000005963503,0.00001789051,0.000029817518,0.000041744523,0.00006989448,0.00011426737,0.00015864026,0.00020301319,0.00019704967,0.00014074978,0.00008444986,0.000028149952,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000009939172,0.000029817518,0.00004969586,0.000069574206,0.000116490795,0.00019044563,0.00026440047,0.0003383553,0.00032841612,0.00023458294,0.00014074976,0.00004691659,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0000139148415,0.000041744523,0.000069574206,0.000097403885,0.00016308711,0.0002666239,0.00037016062,0.00047369747,0.00045978258,0.00032841615,0.00019704967,0.00006568323,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0000139148415,0.000041744523,0.000069574206,0.000097403885,0.00016308711,0.0002666239,0.00037016062,0.00047369747,0.00045978258,0.00032841615,0.00019704967,0.00006568323,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000009939172,0.000029817518,0.00004969586,0.000069574206,0.000116490795,0.00019044563,0.00026440047,0.0003383553,0.00032841612,0.00023458294,0.00014074976,0.00004691659,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000005963503,0.00001789051,0.000029817518,0.000041744523,0.00006989448,0.00011426737,0.00015864026,0.00020301319,0.00019704967,0.00014074978,0.00008444986,0.000028149952,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0000019878344,0.000005963503,0.000009939172,0.0000139148415,0.000023298158,0.000038089125,0.000052880092,0.00006767106,0.00006568323,0.00004691659,0.000028149952,0.000009383318,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0001349094,0.0004047282,0.000674547,0.0009443658,0.0017945112,0.0032249836,0.0046554552,0.0060859276,0.007033198,0.007497268,0.007961337,0.008425406,0.008568974,0.00839204,0.008215106,0.008038171,0.007109595,0.0054293773,0.0037491592,0.0020689415,0.0010752282,0.00076802017,0.0004608121,0.00015360404,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0004047282,0.0012141846,0.002023641,0.0028330975,0.005383534,0.0096749505,0.013966366,0.018257782,0.021099595,0.022491803,0.023884011,0.02527622,0.025706923,0.025176119,0.024645315,0.024114512,0.021328785,0.016288131,0.0112474775,0.0062068244,0.0032256846,0.0023040606,0.0013824363,0.0004608121,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000674547,0.002023641,0.0033727349,0.0047218287,0.008972556,0.016124917,0.023277277,0.030429639,0.03516599,0.03748634,0.039806686,0.04212703,0.042844873,0.0419602,0.041075528,0.040190857,0.035547975,0.027146885,0.018745797,0.010344707,0.0053761406,0.003840101,0.0023040604,0.00076802017,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0009443658,0.0028330975,0.0047218287,0.0066105607,0.012561578,0.022574887,0.032588188,0.042601492,0.04923239,0.052480873,0.05572936,0.058977846,0.05998282,0.058744278,0.05750574,0.056267194,0.049767166,0.038005643,0.026244115,0.014482591,0.0075265975,0.0053761415,0.0032256846,0.0010752282,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00044716516,0.0013414954,0.0022358256,0.0031301563,0.00864801,0.018789388,0.028930763,0.039072145,0.052982066,0.070660524,0.088338986,0.106017455,0.11733456,0.12229031,0.12724605,0.1322018,0.13025162,0.12139547,0.11253931,0.10368316,0.0891112,0.06882343,0.04853565,0.028247874,0.015840985,0.01131499,0.0067889933,0.002262998,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0013414954,0.004024486,0.0067074774,0.009390469,0.02378548,0.049892515,0.075999536,0.10210657,0.13023402,0.16038184,0.19052967,0.22067751,0.23947251,0.24691465,0.25435677,0.26179895,0.25365126,0.22991376,0.20617625,0.18243875,0.15358007,0.11960024,0.08562039,0.051640555,0.030319301,0.021656644,0.012993987,0.0043313294,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0022358256,0.0067074774,0.01117913,0.01565078,0.03892295,0.080995634,0.12306831,0.16514102,0.20748596,0.25010318,0.29272038,0.3353376,0.36161044,0.37153903,0.38146752,0.3913961,0.3770509,0.33843204,0.29981318,0.26119432,0.21804895,0.17037705,0.12270515,0.07503325,0.044797618,0.0319983,0.01919898,0.0063996604,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0031301563,0.009390468,0.01565078,0.021911094,0.05406042,0.11209876,0.17013708,0.22817545,0.2847379,0.33982447,0.39491105,0.44999766,0.48374838,0.49616337,0.50857824,0.52099323,0.50045055,0.44695035,0.39345014,0.3399499,0.28251782,0.22115386,0.15978989,0.09842593,0.05927594,0.042339955,0.025403975,0.008467992,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00013373839,0.00040121513,0.00066869194,0.00093616865,0.0065664216,0.01755945,0.02855248,0.039545506,0.07827917,0.14475349,0.21122777,0.2777021,0.34152973,0.40271062,0.4638916,0.5250726,0.55988514,0.5683295,0.5767738,0.5852182,0.5584862,0.4965782,0.43467015,0.3727621,0.30902907,0.24347112,0.17791317,0.11235522,0.069895215,0.050533168,0.031171132,0.011809093,0.0018620646,0.0013300461,0.0007980277,0.0002660092,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00040121513,0.0012036455,0.0020060758,0.0028085061,0.012544622,0.031214422,0.049884222,0.06855402,0.11157921,0.17895979,0.24634035,0.31372094,0.3778614,0.43876165,0.499662,0.5605623,0.5900208,0.5880375,0.5860542,0.5840709,0.551158,0.48731565,0.42347318,0.3596308,0.29758266,0.23732883,0.17707497,0.11682112,0.07665544,0.056577947,0.036500458,0.016422965,0.0055861934,0.0039901384,0.002394083,0.0007980277,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00066869194,0.0020060756,0.0033434597,0.004680843,0.018522821,0.044869393,0.071215965,0.09756254,0.14487925,0.2131661,0.28145295,0.3497398,0.41419303,0.4748127,0.53543234,0.596052,0.6201564,0.60774547,0.5953346,0.5829237,0.54382986,0.47805306,0.4122763,0.34649953,0.28613627,0.23118651,0.17623675,0.12128701,0.083415665,0.06262272,0.04182978,0.021036837,0.009310323,0.0066502304,0.0039901384,0.0013300461,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00093616865,0.002808506,0.0046808436,0.006553181,0.024501022,0.058524366,0.092547715,0.12657104,0.17817928,0.2473724,0.3165655,0.38575867,0.45052475,0.5108637,0.57120275,0.6315417,0.650292,0.6274535,0.604615,0.58177644,0.53650165,0.46879053,0.40107933,0.33336824,0.27468985,0.22504422,0.17539856,0.12575291,0.09017589,0.0686675,0.04715911,0.02565071,0.013034452,0.009310323,0.0055861934,0.0018620646,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0016217167,0.00486515,0.008108584,0.011352016,0.032148305,0.070497446,0.10884658,0.14719573,0.19995515,0.26712486,0.33429456,0.40146428,0.4642758,0.52272916,0.5811826,0.639636,0.65872985,0.6384644,0.61819893,0.5979334,0.5563088,0.4933251,0.43034145,0.36735776,0.31183985,0.26378778,0.2157357,0.16768363,0.12838674,0.097845025,0.06730331,0.03676159,0.018804392,0.013431709,0.008059025,0.0026863418,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002725336,0.008176008,0.013626681,0.019077351,0.041464668,0.080788635,0.1201126,0.15943655,0.21020685,0.27242348,0.3346401,0.39685673,0.4554464,0.5104091,0.5653719,0.6203346,0.64547,0.6407782,0.6360864,0.6313945,0.60325134,0.5516569,0.5000624,0.448468,0.3975863,0.3474172,0.2972482,0.24707916,0.1980482,0.15015529,0.102262385,0.054369476,0.026620144,0.019014388,0.011408634,0.0038028774,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0038289553,0.011486866,0.019144777,0.026802685,0.050781034,0.09107982,0.13137862,0.17167741,0.22045855,0.2777221,0.3349856,0.39224914,0.44661695,0.49808905,0.54956114,0.6010333,0.63221025,0.643092,0.6539738,0.66485566,0.6501939,0.6099887,0.5697835,0.52957827,0.48333266,0.43104666,0.37876073,0.3264747,0.26770964,0.20246556,0.13722146,0.071977355,0.034435894,0.02459707,0.01475824,0.004919414,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0049325745,0.014797725,0.02466287,0.03452802,0.0600974,0.101371005,0.14264463,0.18391822,0.23071025,0.2830207,0.3353311,0.38764158,0.4377875,0.485769,0.5337504,0.5817319,0.61895037,0.6454058,0.6718613,0.69831675,0.69713646,0.6683205,0.6395045,0.6106885,0.5690791,0.5146761,0.4602732,0.4058702,0.33737114,0.25477585,0.17218053,0.089585245,0.042251647,0.030179748,0.018107848,0.006035949,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000019353558,0.000058060672,0.000096767784,0.00013547491,0.005631032,0.016583439,0.027535843,0.03848825,0.06415416,0.10453357,0.14491299,0.1852924,0.2292881,0.2769001,0.3245121,0.37212414,0.42065388,0.4701015,0.519549,0.5689966,0.6128486,0.65110475,0.6893611,0.7276174,0.73758346,0.7192593,0.70093524,0.6826111,0.6438884,0.5847671,0.5256459,0.4665246,0.38908082,0.29331464,0.1975484,0.10178219,0.047161683,0.033686917,0.020212151,0.0067373835,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000058060672,0.00017418202,0.00029030335,0.00040642472,0.0059243273,0.01684401,0.027763695,0.038683377,0.062951304,0.10056749,0.13818367,0.17579988,0.21619207,0.25936034,0.30252856,0.3456968,0.3952161,0.45108655,0.5069569,0.56282735,0.6139047,0.660189,0.70647323,0.7527575,0.77153486,0.7628053,0.75407565,0.74534595,0.70776075,0.64131975,0.57487875,0.5084378,0.42283884,0.31808197,0.21332505,0.10856817,0.049166005,0.035118572,0.021071143,0.007023715,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000096767784,0.00029030337,0.00048383893,0.00067737454,0.006217622,0.017104581,0.02799154,0.0388785,0.061748464,0.09660143,0.1314544,0.16630733,0.20309606,0.24182054,0.28054503,0.3192695,0.36977834,0.4320716,0.49436483,0.5566581,0.61496085,0.6692731,0.7235854,0.77789766,0.80548626,0.8063511,0.80721605,0.8080809,0.771633,0.69787234,0.62411165,0.550351,0.45659685,0.3428493,0.22910173,0.11535417,0.051170323,0.03655023,0.02193014,0.0073100463,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00013547491,0.00040642472,0.0006773744,0.00094832433,0.0065109176,0.017365154,0.02821939,0.039073627,0.06054561,0.09263535,0.12472507,0.15681481,0.19000003,0.22428077,0.25856146,0.29284218,0.34434056,0.41305667,0.48177272,0.5504888,0.616017,0.67835724,0.74069744,0.8030378,0.83943766,0.84989697,0.8603565,0.8708158,0.8355053,0.7544249,0.67334455,0.5922642,0.49035487,0.36761665,0.24487838,0.122140154,0.05317464,0.037981886,0.022789134,0.0075963777,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00013547491,0.00040642472,0.0006773744,0.00094832433,0.0061587817,0.016308745,0.02645871,0.036608677,0.055721913,0.083798416,0.111874916,0.13995142,0.17058286,0.20376924,0.23695561,0.270142,0.32474652,0.40076923,0.47679195,0.55281466,0.62602836,0.6964331,0.76683784,0.83724266,0.87692577,0.8858872,0.8948487,0.90381014,0.86570585,0.7805358,0.6953658,0.6101958,0.504191,0.37735143,0.25051188,0.123672366,0.052721005,0.03765786,0.022594716,0.0075315717,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000096767784,0.00029030337,0.00048383893,0.00067737454,0.0051612146,0.013935359,0.022709504,0.03148365,0.047277357,0.07009063,0.0929039,0.11571717,0.14484453,0.18028599,0.21572743,0.25116888,0.31099617,0.39520934,0.47942245,0.56363565,0.64499503,0.7235007,0.80200636,0.8805121,0.91795045,0.9143216,0.91069275,0.90706384,0.86223453,0.776205,0.6901753,0.6041457,0.49810517,0.3720537,0.24600224,0.11995077,0.049809396,0.035578143,0.021346886,0.007115628,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000058060672,0.00017418202,0.00029030335,0.00040642472,0.004163648,0.011561972,0.018960299,0.026358623,0.038832806,0.056382846,0.07393288,0.091482915,0.119106196,0.15680271,0.19449924,0.23219576,0.29724583,0.3896494,0.482053,0.5744566,0.6639617,0.75056833,0.83717495,0.9237816,0.95897526,0.94275606,0.9265368,0.9103176,0.85876334,0.77187407,0.6849849,0.5980957,0.4920194,0.366756,0.24149258,0.116229184,0.046897795,0.033498425,0.020099055,0.006699685,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000019353558,0.000058060672,0.000096767784,0.00013547491,0.0031660814,0.009188587,0.015211093,0.021233598,0.030388253,0.042675056,0.05496186,0.067248665,0.09336786,0.13331947,0.17327106,0.21322264,0.28349546,0.3840895,0.48468354,0.5852776,0.6829284,0.77763593,0.87234354,0.967051,1.0,0.97119045,0.94238085,0.9135713,0.8552921,0.76754326,0.6797945,0.59204566,0.4859336,0.3614583,0.23698293,0.1125076,0.043986186,0.031418707,0.018851224,0.0062837414,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.002656488,0.007969464,0.01328244,0.018595414,0.02602106,0.035559375,0.045097686,0.054635998,0.080126636,0.12156959,0.16301255,0.2044555,0.27627143,0.37846032,0.48064926,0.5828382,0.67922646,0.7698144,0.86040217,0.95098996,0.977877,0.9410633,0.9042495,0.8674357,0.8052523,0.7176993,0.63014627,0.5425933,0.4417922,0.32774308,0.21369396,0.099644825,0.037292726,0.026637662,0.015982598,0.005327532,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0026348683,0.007904605,0.013174341,0.018444078,0.025731226,0.035035796,0.04434036,0.05364493,0.07938251,0.121553116,0.1637237,0.2058943,0.2755737,0.37276188,0.4699501,0.5671383,0.6528561,0.72710365,0.8013511,0.8755985,0.89260626,0.8523745,0.8121426,0.77191085,0.708644,0.6223421,0.5360403,0.44973853,0.3595952,0.26561043,0.17162564,0.07764086,0.026817404,0.01915529,0.011493174,0.003831058,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0026132483,0.007839745,0.013066242,0.018292738,0.025441397,0.034512218,0.043583035,0.052653853,0.07863839,0.12153663,0.16443488,0.20733312,0.274876,0.3670635,0.459251,0.55143845,0.62648576,0.6843928,0.74229985,0.800207,0.80733556,0.76368564,0.7200358,0.6763859,0.61203563,0.526985,0.44193438,0.35688376,0.27739823,0.2034778,0.12955734,0.055636894,0.016342085,0.011672918,0.0070037507,0.0023345836,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0025916286,0.0077748853,0.012958144,0.0181414,0.025151564,0.03398864,0.04282571,0.05166278,0.07789426,0.121520154,0.16514605,0.20877194,0.27417827,0.36136505,0.44855183,0.5357386,0.60011536,0.6416821,0.68324876,0.7248154,0.7220648,0.6749969,0.6279289,0.580861,0.5154273,0.43162784,0.34782842,0.26402903,0.19520125,0.14134514,0.08748903,0.033632927,0.0058667636,0.0041905455,0.0025143272,0.0008381091,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0022582165,0.0067746486,0.011291081,0.015807515,0.022086866,0.03012914,0.03817141,0.046213686,0.07119365,0.1131113,0.15502895,0.19694659,0.25575635,0.33145818,0.40716007,0.4828619,0.5355203,0.5651352,0.5947501,0.62436503,0.6161365,0.5700644,0.5239923,0.47792023,0.41734362,0.34226257,0.26718152,0.19210045,0.13531855,0.096835844,0.058353152,0.019870454,0.0005504654,0.00039318964,0.00023591377,0.000078637924,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0016130117,0.0048390348,0.008065058,0.011291081,0.016247302,0.022933722,0.02962014,0.036306564,0.058536533,0.09631007,0.1340836,0.17185712,0.21961024,0.27734292,0.33507562,0.3928083,0.4327005,0.45475224,0.476804,0.49885574,0.48955047,0.44888818,0.40822586,0.36756364,0.3177847,0.25888914,0.19999358,0.14109804,0.09775014,0.06994992,0.042149693,0.014349472,0.0003931896,0.00028084972,0.00016850983,0.000056169945,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00096780696,0.002903421,0.004839035,0.006774649,0.010407738,0.015738305,0.021068873,0.026399441,0.045879427,0.07950883,0.11313824,0.14676765,0.1834641,0.22322764,0.26299116,0.3027547,0.32988074,0.3443693,0.35885787,0.37334642,0.36296445,0.32771197,0.2924595,0.257207,0.21822573,0.1755157,0.13280568,0.09009563,0.06018173,0.04306398,0.025946235,0.008828489,0.00023591377,0.00016850984,0.0001011059,0.000033701966,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00032260234,0.00096780696,0.0016130117,0.0022582165,0.0045681754,0.008542889,0.012517601,0.016492318,0.033222314,0.062707596,0.09219288,0.12167816,0.14731799,0.16911237,0.19090672,0.2127011,0.22706099,0.23398632,0.24091174,0.24783713,0.23637848,0.20653579,0.17669307,0.1468504,0.1186668,0.09214227,0.06561775,0.03909322,0.02261332,0.016178044,0.009742777,0.003307507,0.000078637924,0.000056169945,0.000033701966,0.000011233989,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0014423446,0.0043270336,0.0072117224,0.010096412,0.023532039,0.04751861,0.071505174,0.095491745,0.11308931,0.12429788,0.13550645,0.14671502,0.1536947,0.15644552,0.15919635,0.16194716,0.15144978,0.1277042,0.10395866,0.080213085,0.0602764,0.044148605,0.02802081,0.011893013,0.0033504737,0.0023931956,0.0014359175,0.00047863912,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.001030246,0.0030907383,0.00515123,0.0072117224,0.0168086,0.033941865,0.051075127,0.06820839,0.08077808,0.088784195,0.09679032,0.10479644,0.109781936,0.1117468,0.11371168,0.115676545,0.108178414,0.0912173,0.07425618,0.05729506,0.043054573,0.031534716,0.020014863,0.008495009,0.0023931956,0.0017094255,0.0010256553,0.0003418851,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00061814766,0.0018544429,0.0030907383,0.0043270336,0.01008516,0.020365119,0.030645076,0.040925033,0.048466846,0.05327052,0.058074195,0.06287786,0.06586915,0.06704807,0.06822701,0.06940593,0.06490705,0.054730378,0.044553712,0.034377035,0.025832742,0.01892083,0.0120089175,0.005097005,0.0014359173,0.0010256553,0.0006153932,0.00020513106,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00020604921,0.00061814766,0.001030246,0.0014423446,0.00336172,0.006788373,0.010215025,0.013641678,0.016155615,0.01775684,0.019358065,0.020959288,0.021956386,0.02234936,0.022742335,0.023135308,0.021635683,0.01824346,0.014851236,0.011459012,0.008610914,0.0063069435,0.0040029725,0.0016990018,0.00047863912,0.0003418851,0.00020513106,0.00006837702,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000008206045,0.000024618135,0.000041030224,0.000057442314,0.000081335194,0.00011270887,0.00014408253,0.0001754562,0.00018692306,0.0001784831,0.00017004315,0.0001616032,0.00013771032,0.000098364515,0.00005901871,0.000019672903,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000024618135,0.00007385441,0.00012309068,0.00017232694,0.00024400557,0.0003381266,0.00043224762,0.0005263686,0.0005607692,0.0005354493,0.00051012944,0.0004848096,0.00041313097,0.00029509354,0.00017705614,0.00005901871,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000041030224,0.00012309068,0.00020515111,0.0002872116,0.00040667594,0.00056354434,0.0007204127,0.00087728095,0.00093461527,0.0008924155,0.0008502158,0.00080801605,0.0006885516,0.0004918226,0.00029509354,0.000098364515,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000057442314,0.00017232695,0.00028721156,0.00040209622,0.00056934636,0.00078896206,0.0010085778,0.0012281934,0.0013084614,0.0012493817,0.0011903021,0.0011312224,0.00096397224,0.0006885516,0.00041313097,0.00013771032,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000061693456,0.00018508035,0.00030846725,0.00043185416,0.0006086758,0.00083893235,0.0010691887,0.001299445,0.0014002577,0.0013716265,0.0013429954,0.0013143644,0.0011375425,0.00081253046,0.0004875183,0.00016250608,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.00005378364,0.00016135092,0.0002689182,0.00037648546,0.0005246644,0.000713455,0.0009022455,0.0010910361,0.0012100043,0.0012591501,0.0013082959,0.0013574417,0.0012092628,0.00086375914,0.00051825546,0.00017275182,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000045873825,0.00013762148,0.00022936912,0.0003211168,0.00044065298,0.0005879777,0.0007353024,0.0008826271,0.0010197508,0.0011466736,0.0012735963,0.001400519,0.0012809829,0.0009149877,0.00054899266,0.00018299757,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000037964015,0.00011389204,0.00018982006,0.0002657481,0.00035664157,0.0004625004,0.0005683593,0.0006742181,0.0008294974,0.0010341972,0.0012388967,0.0014435964,0.001352703,0.0009662164,0.00057972985,0.0001932433,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000029757968,0.00008927391,0.00014878984,0.00020830576,0.00027530635,0.00034979152,0.00042427675,0.0004987619,0.0006478477,0.0008715341,0.0010952206,0.0013189069,0.0012519063,0.00089421886,0.0005365313,0.00017884377,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000021255692,0.000063767075,0.00010627846,0.00014878984,0.00019664738,0.0002498511,0.0003030548,0.0003562585,0.0004748018,0.0006586847,0.0008425676,0.0010264504,0.0009785929,0.00069899496,0.000419397,0.00013979898,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.000012753415,0.000038260245,0.000063767075,0.0000892739,0.000117988435,0.00014991066,0.00018183289,0.0002137551,0.0003017559,0.00044583526,0.0005899147,0.00073399406,0.0007052795,0.00050377107,0.00030226263,0.000100754216,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0000042511383,0.000012753415,0.000021255692,0.000029757968,0.00003932948,0.00004997022,0.000060610964,0.0000712517,0.00012871,0.00023298587,0.00033726174,0.00044153762,0.0004319661,0.00030854723,0.00018512833,0.00006170944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000036913672,0.00011074102,0.00018456836,0.0002583957,0.0002583957,0.00018456836,0.00011074102,0.000036913672,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00002636691,0.000079100726,0.00013183455,0.00018456836,0.00018456836,0.00013183455,0.000079100726,0.00002636691,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000015820146,0.000047460435,0.000079100726,0.00011074102,0.00011074102,0.000079100726,0.000047460435,0.000015820146,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0000052733817,0.000015820146,0.00002636691,0.000036913672,0.000036913672,0.00002636691,0.000015820146,0.0000052733817,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"visible\":false},\"yaxis\":{\"visible\":false},\"title\":{\"text\":\"Overlay with Custom Colorscale\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('fd836ee9-7306-4611-8492-ff212e0fb321');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Computational Cost Comparison**","metadata":{}},{"cell_type":"code","source":"def plot_loss(train_loss, val_loss):\n    epochs = range(1, len(train_loss) + 1)\n    plt.plot(epochs, train_loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n\nplot_loss(trainer.running_loss_train, trainer.running_loss_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:55:13.614931Z","iopub.execute_input":"2024-04-19T11:55:13.615645Z","iopub.status.idle":"2024-04-19T11:55:13.915562Z","shell.execute_reply.started":"2024-04-19T11:55:13.615611Z","shell.execute_reply":"2024-04-19T11:55:13.914671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:45:28.052599Z","iopub.execute_input":"2024-04-19T10:45:28.052910Z","iopub.status.idle":"2024-04-19T10:45:31.272907Z","shell.execute_reply.started":"2024-04-19T10:45:28.052885Z","shell.execute_reply":"2024-04-19T10:45:31.271735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_weights_equal(model1, model2):\n    # Check if models have the same number of parameters\n    if sum(p.numel() for p in model1.parameters()) != sum(p.numel() for p in model2.parameters()):\n        return False\n    \n    # Check if parameters are the same\n    for p1, p2 in zip(model1.parameters(), model2.parameters()):\n        if not torch.all(torch.eq(p1.data, p2.data)):\n            return False\n    \n    return True","metadata":{"execution":{"iopub.status.busy":"2024-04-13T13:24:25.892067Z","iopub.execute_input":"2024-04-13T13:24:25.892740Z","iopub.status.idle":"2024-04-13T13:24:25.898837Z","shell.execute_reply.started":"2024-04-13T13:24:25.892707Z","shell.execute_reply":"2024-04-13T13:24:25.897756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Visual Attention Network ###","metadata":{"id":"O57xJG03K7-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#############################################################\n##### Own Implementation of the Visual Attention Network ####\n#############################################################\n'''\nNotes on the architecture from the paper:\n- Simple hierarchical structure\n  -> Sequence of four stages e.g\n  -> Decreasig output spatial resolution:\n    H/4 x W/4 -> H/8 x W/8 -> H/16 x W/16 -> H/32 x W/32 - Maybe start a 2**1??\n  -> With decreasing resolution, number of channels increases.\n  -> Each stage: First downsample the input with the stride number (-> Convolution)\n     --- In this step, we decrease the resolution and increase the dimensions\n         -> (First iteration: 100x100x1 as input and ?x?xdim[0] as output)\n         -> (Second iteration: 25x25xdim[0] as input and ?x?xdim[1] as output)\n  -> During each stage, the resolution (H & W) and the channels (C) remain the same and do not change\n     until the next stage starts\n  -> At each stage L-Groups (Blocks) of:\n    - Batch Norm\n    - 1x1 Conv\n    - GELU Activation\n    - LKA ()\n    - FFN (1x1 Conv. depthwise, 3x3 Conv, GELU, 1x1 Conv.)\n'''\n\nclass Downsampling(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=kernel_size, groups=in_channels)#DWConv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=kernel_size,\n                           dilation=dilation, groups=in_channels, padding=8)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711009784026,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"mYJOZ10DUg-P","execution":{"iopub.status.busy":"2024-06-21T17:23:46.528338Z","iopub.execute_input":"2024-06-21T17:23:46.528731Z","iopub.status.idle":"2024-06-21T17:23:46.553840Z","shell.execute_reply.started":"2024-06-21T17:23:46.528699Z","shell.execute_reply":"2024-06-21T17:23:46.552913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nvan_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_optimizer = optim.AdamW(van_model.parameters(), lr=1e-3)\nvan_trainer = Trainer(model=van_model, optimizer=van_optimizer,\n                      train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                      num_epochs=30, save_checkpoints=True, path=f'VAN()')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:03:15.576090Z","iopub.execute_input":"2024-04-19T12:03:15.576479Z","iopub.status.idle":"2024-04-19T12:03:15.594482Z","shell.execute_reply.started":"2024-04-19T12:03:15.576450Z","shell.execute_reply":"2024-04-19T12:03:15.593648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:50:36.640470Z","iopub.execute_input":"2024-04-19T13:50:36.641161Z","iopub.status.idle":"2024-04-19T14:52:10.202946Z","shell.execute_reply.started":"2024-04-19T13:50:36.641128Z","shell.execute_reply":"2024-04-19T14:52:10.201954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:52:10.204576Z","iopub.execute_input":"2024-04-19T14:52:10.204896Z","iopub.status.idle":"2024-04-19T14:52:40.364649Z","shell.execute_reply.started":"2024-04-19T14:52:10.204869Z","shell.execute_reply":"2024-04-19T14:52:40.363712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt = torch.load('/kaggle/input/van-final/pytorch/van-clutter-mnist-final/1/VAN(channels64 128 stages2 l1 1 expansion_ratio2 4)_50_epochs_Acc_9922.pth', map_location='cpu')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:23:52.327880Z","iopub.execute_input":"2024-06-21T17:23:52.328324Z","iopub.status.idle":"2024-06-21T17:23:52.416516Z","shell.execute_reply.started":"2024-06-21T17:23:52.328289Z","shell.execute_reply":"2024-06-21T17:23:52.415486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:16:49.211501Z","iopub.execute_input":"2024-06-21T17:16:49.211921Z","iopub.status.idle":"2024-06-21T17:16:49.219849Z","shell.execute_reply.started":"2024-06-21T17:16:49.211870Z","shell.execute_reply":"2024-06-21T17:16:49.218561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt['test_accuracy']","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:23:54.661174Z","iopub.execute_input":"2024-06-21T17:23:54.661895Z","iopub.status.idle":"2024-06-21T17:23:54.668115Z","shell.execute_reply.started":"2024-06-21T17:23:54.661860Z","shell.execute_reply":"2024-06-21T17:23:54.667094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt['loss']","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:59.057906Z","iopub.execute_input":"2024-06-21T17:06:59.058369Z","iopub.status.idle":"2024-06-21T17:06:59.065549Z","shell.execute_reply.started":"2024-06-21T17:06:59.058333Z","shell.execute_reply":"2024-06-21T17:06:59.064328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Check reproducability","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:58:16.204296Z","iopub.execute_input":"2024-04-19T14:58:16.204665Z","iopub.status.idle":"2024-04-19T14:58:46.234582Z","shell.execute_reply.started":"2024-04-19T14:58:16.204637Z","shell.execute_reply":"2024-04-19T14:58:46.233655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_optimizer = optim.AdamW(van_model.parameters(), lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:02:25.092595Z","iopub.execute_input":"2024-04-19T15:02:25.093506Z","iopub.status.idle":"2024-04-19T15:02:25.099207Z","shell.execute_reply.started":"2024-04-19T15:02:25.093472Z","shell.execute_reply":"2024-04-19T15:02:25.098223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt['scheduler_state_dict']","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:10:44.840597Z","iopub.execute_input":"2024-04-19T15:10:44.841527Z","iopub.status.idle":"2024-04-19T15:10:44.847559Z","shell.execute_reply.started":"2024-04-19T15:10:44.841492Z","shell.execute_reply":"2024-04-19T15:10:44.846717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Wrap checkpoint loading into a function.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nckpt_model.load_state_dict(ckpt['model_state_dict'])\nckpt_optimizer = optim.AdamW(ckpt_model.parameters(), lr=1e-3)\nckpt_optimizer.load_state_dict(ckpt['optimizer_state_dict'])\nckpt_trainer = Trainer(model=ckpt_model, optimizer=ckpt_optimizer,\n                       train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                       num_epochs=30, save_checkpoints=False, path=f'Ckpt_VAN()')\nckpt_trainer.scheduler.load_state_dict(ckpt['scheduler_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:24:28.293120Z","iopub.execute_input":"2024-06-21T17:24:28.293560Z","iopub.status.idle":"2024-06-21T17:24:28.320823Z","shell.execute_reply.started":"2024-06-21T17:24:28.293530Z","shell.execute_reply":"2024-06-21T17:24:28.319911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:27:39.732022Z","iopub.execute_input":"2024-06-21T17:27:39.732761Z","iopub.status.idle":"2024-06-21T17:28:10.100599Z","shell.execute_reply.started":"2024-06-21T17:27:39.732730Z","shell.execute_reply":"2024-06-21T17:28:10.099689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:26:45.387132Z","iopub.execute_input":"2024-06-21T17:26:45.387519Z","iopub.status.idle":"2024-06-21T17:26:45.393486Z","shell.execute_reply.started":"2024-06-21T17:26:45.387493Z","shell.execute_reply":"2024-06-21T17:26:45.392559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt['epoch']","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:28:45.718595Z","iopub.execute_input":"2024-06-21T17:28:45.718966Z","iopub.status.idle":"2024-06-21T17:28:45.724959Z","shell.execute_reply.started":"2024-06-21T17:28:45.718940Z","shell.execute_reply":"2024-06-21T17:28:45.724021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################\n### ABLATION STUDY ###\n######################","metadata":{"id":"euX4LKFiCmla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementation of the VAN without an Attention Mechanism\nclass Downsampling_ablation(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block_ablation(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    #self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.abl_FFN = FFN_ablation(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    #x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.abl_FFN(x)\n\n    return x\n\n\nclass FFN_ablation(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\nclass VAN_ablation(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler_ablation = Downsampling_ablation(in_channels=1 if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block_ablation = nn.ModuleList([Block_ablation(channels=self.channels[j],\n                                      expansion_ratio=self.expansion_ratio[j],\n                                      dropout=dropout)\n                                      for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler_ablation)\n      setattr(self, f'block_{j+1}', block_ablation)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"id":"PfX0_Pu6Cmei","executionInfo":{"status":"ok","timestamp":1711012063764,"user_tz":-60,"elapsed":208,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"execution":{"iopub.status.busy":"2024-03-26T19:42:01.421882Z","iopub.execute_input":"2024-03-26T19:42:01.422639Z","iopub.status.idle":"2024-03-26T19:42:01.440940Z","shell.execute_reply.started":"2024-03-26T19:42:01.422607Z","shell.execute_reply":"2024-03-26T19:42:01.440077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nabl_model = VAN_ablation(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nabl_optimizer = optim.AdamW(abl_model.parameters(), lr=1e-3)\nabl_trainer = Trainer(model=vabl_model, optimizer=abl_optimizer,\n                      train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                      num_epochs=50, save_checkpoints=True, path=f'VAN_Ablation()')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abl_trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abl_trainer.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########################\n### ACCURACY COMPARISON ###\n###########################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#####################################\n### COMPUTATIONAL COST COMPARISON ###\n#####################################","metadata":{"id":"q80dXxsWAsh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nTODO: Check torchinfo Profiler\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare number of modueles\n\ndef count_modules(model):\n    # Use model.modules() for all modules including nested ones,\n    # or model.children() for immediate children only.\n    num_modules = sum(1 for _ in model.modules())\n    return num_modules\n\nbaseline = BaselineCNN()\nvan = VAN()\n\nnum_modules_cnn = count_modules(baseline)\nnum_modules_van = count_modules(van)\n\nprint(\"Number of modules in CNN:\", num_modules_cnn)\nprint(\"Number of modules in VAN:\", num_modules_van)","metadata":{"id":"6a5e_FegAoGs","executionInfo":{"status":"ok","timestamp":1711019998475,"user_tz":-60,"elapsed":336,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"85dbf9d1-b18e-46b1-b7d1-4ff66b5b309c","execution":{"iopub.status.busy":"2024-03-21T11:39:11.847181Z","iopub.execute_input":"2024-03-21T11:39:11.847897Z","iopub.status.idle":"2024-03-21T11:39:11.924267Z","shell.execute_reply.started":"2024-03-21T11:39:11.847864Z","shell.execute_reply":"2024-03-21T11:39:11.923437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of parameters for the baseline CNN model\ntrainable_params = sum(p.numel() for p in baseline.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in baseline.parameters())\n\"{:,}\".format(trainable_params), \"{:,}\".format(total_params)","metadata":{"id":"95prYojcBLah","executionInfo":{"status":"ok","timestamp":1711020097212,"user_tz":-60,"elapsed":230,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"857675c9-8beb-4fea-a514-810f8645a599","execution":{"iopub.status.busy":"2024-03-21T11:39:16.161026Z","iopub.execute_input":"2024-03-21T11:39:16.161748Z","iopub.status.idle":"2024-03-21T11:39:16.168610Z","shell.execute_reply.started":"2024-03-21T11:39:16.161715Z","shell.execute_reply":"2024-03-21T11:39:16.167723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of parameters for VAN\ntotal_params_van = sum(p.numel() for p in van.parameters())\nprint(f' Total parameters of the VAN model are: {\"{:,}\".format(total_params_van)}')","metadata":{"id":"NJIg4rfgBNHh","executionInfo":{"status":"ok","timestamp":1711020070331,"user_tz":-60,"elapsed":407,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"50aedc59-dcc0-4ee5-ec32-f1a56f34eae6","execution":{"iopub.status.busy":"2024-03-21T11:39:18.306852Z","iopub.execute_input":"2024-03-21T11:39:18.307471Z","iopub.status.idle":"2024-03-21T11:39:18.313188Z","shell.execute_reply.started":"2024-03-21T11:39:18.307441Z","shell.execute_reply":"2024-03-21T11:39:18.312277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install deepspeed\nfrom deepspeed.profiling.flops_profiler import FlopsProfiler","metadata":{"id":"5npplbR9v-vu","outputId":"3c1e8282-709e-4771-ae20-ee0d3d59ae2c","execution":{"iopub.status.busy":"2024-03-26T18:06:35.292615Z","iopub.execute_input":"2024-03-26T18:06:35.293076Z","iopub.status.idle":"2024-03-26T18:07:19.351944Z","shell.execute_reply.started":"2024-03-26T18:06:35.293044Z","shell.execute_reply":"2024-03-26T18:07:19.350905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = VAN(num_classes=14, stages=2, channels=[64, 128], image_channels=3, l=[1,1], expansion_ratio=[2,4])\nprofile_model(input_model=m1, data_loader=pc_train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:52:16.531727Z","iopub.execute_input":"2024-03-25T17:52:16.532454Z","iopub.status.idle":"2024-03-25T17:52:19.048782Z","shell.execute_reply.started":"2024-03-25T17:52:16.532421Z","shell.execute_reply":"2024-03-25T17:52:19.047886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def profile_model(input_model, data_loader=train_loader):\n    # Profile a model to get the FLOPS and Latency\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model = input_model\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n    prof = FlopsProfiler(model)\n    # Profile at step 5 to warmup\n    profile_step = 5\n    for batch_idx, (data, target) in enumerate(data_loader):\n      if batch_idx == profile_step:\n        prof.start_profile()\n\n      data, target = data.to(device), target.to(device)\n      optimizer.zero_grad()\n      output = model(data)\n      loss = criterion(output, target)\n\n      if batch_idx == profile_step:\n        prof.stop_profile()\n        flops = prof.get_total_flops()\n        macs = prof.get_total_macs()\n        params = prof.get_total_params()\n        prof.print_model_profile(profile_step=profile_step)\n        prof.end_profile()\n\n      loss.backward()\n      optimizer.step()\n\n      if batch_idx == profile_step:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:47:37.606860Z","iopub.execute_input":"2024-03-25T17:47:37.607618Z","iopub.status.idle":"2024-03-25T17:47:37.616235Z","shell.execute_reply.started":"2024-03-25T17:47:37.607586Z","shell.execute_reply":"2024-03-25T17:47:37.615214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FLOPs for VAN\nfor data, target in augmented_loader:\n  input_data, input_target = data.to(device), target.to(device)\n  break\n\nflops_van, params = profile(van, inputs=(input_data,))\nprint(f'Estimated Params for VAN:, {(\"{:,}\".format(params))}')\nprint(f'Estimated FLOPs for VAN:, {(\"{:,}\".format(flops_van))}')","metadata":{"id":"zqHb0WdSA3Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for Baseline CNN\n\n# Define your model and input data\nbaseline = BaselineCNN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = baseline(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"6vf3Yhg3BFbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for VAN\n\n# Define your model and input data\nvan = VAN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = van(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"jvtS_uZKBFSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare convolution speed ###\nfrom torch.autograd import profiler\ninput = torch.randn((128, 32, 50, 50), device=\"cuda\")\nm1 = LKA(32, 32).to(\"cuda\")\nm2 = LSKA(32, 32).to(\"cuda\")\nm3 = KA(32, 32).to(\"cuda\")\n\nwith profiler.profile(record_shapes=True, use_cuda=True) as prof:\n    with profiler.record_function(\"model_inference\"):\n        # Your PyTorch operations here\n        output = m3(input)\nprint(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))","metadata":{"id":"_rsVqxX4BFIW","execution":{"iopub.status.busy":"2024-03-22T09:19:14.996033Z","iopub.execute_input":"2024-03-22T09:19:14.996978Z","iopub.status.idle":"2024-03-22T09:19:15.029116Z","shell.execute_reply.started":"2024-03-22T09:19:14.996939Z","shell.execute_reply":"2024-03-22T09:19:15.028133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#######################################################\n### Compare difference in speed using fp32 and fp16 ###\n#######################################################","metadata":{"execution":{"iopub.status.busy":"2024-03-26T18:14:10.948549Z","iopub.execute_input":"2024-03-26T18:14:10.948985Z","iopub.status.idle":"2024-03-26T18:14:10.954385Z","shell.execute_reply.started":"2024-03-26T18:14:10.948955Z","shell.execute_reply":"2024-03-26T18:14:10.953437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda_loader = torch.utils.data.DataLoader(dataset=augmented_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T20:02:06.293855Z","iopub.execute_input":"2024-03-26T20:02:06.294762Z","iopub.status.idle":"2024-03-26T20:02:06.300379Z","shell.execute_reply.started":"2024-03-26T20:02:06.294726Z","shell.execute_reply":"2024-03-26T20:02:06.299351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4]).cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T19:22:35.929570Z","iopub.execute_input":"2024-03-26T19:22:35.930169Z","iopub.status.idle":"2024-03-26T19:22:35.951426Z","shell.execute_reply.started":"2024-03-26T19:22:35.930136Z","shell.execute_reply":"2024-03-26T19:22:35.950730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### FP32\n\n# Creates model and optimizer in default precision\nmodel = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4])\nmodel.to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\nwith torch.autograd.profiler.profile(use_cuda=True) as prof:\n    for epoch in range(1):\n        print(f'Epoch {epoch+1} started')\n\n        for i, (input, target) in enumerate(cuda_loader):\n            #input, target = input.to('cuda'), target.to('cuda')\n            optimizer.zero_grad()\n\n            output = model(input)\n            loss = criterion(output, target)\n\n            loss.backward()\n\n            optimizer.step()\n            if i == 10:\n                break\n        print(f'Epoch {epoch+1} finished')\nprint(prof.key_averages())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T20:02:09.897192Z","iopub.execute_input":"2024-03-26T20:02:09.898064Z","iopub.status.idle":"2024-03-26T20:02:14.591720Z","shell.execute_reply.started":"2024-03-26T20:02:09.898009Z","shell.execute_reply":"2024-03-26T20:02:14.590115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import autocast\nfrom torch.cuda.amp import GradScaler\n\n### FP16\n\n# Creates model and optimizer in default precision\nmodel = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4])\nmodel.to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\n# Creates a GradScaler once at the beginning of training.\nscaler = GradScaler()\nwith torch.autograd.profiler.profile(use_cuda=True) as prof:\n    for epoch in range(1):\n        print(f'Epoch {epoch+1} started')\n\n        for i, (input, target) in enumerate(train_loader):\n            input, target = input.to('cuda'), target.to('cuda')\n            optimizer.zero_grad()\n\n            # Runs the forward pass with autocasting.\n            with autocast(device_type='cuda', dtype=torch.float16):\n                output = model(input)\n                loss = criterion(output, target)\n\n            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n            # Backward passes under autocast are not recommended.\n            # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n            scaler.scale(loss).backward()\n\n            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n            # otherwise, optimizer.step() is skipped.\n            scaler.step(optimizer)\n\n            # Updates the scale for next iteration.\n            scaler.update()\n            if i == 10 :\n                break\n                \n        print(f'Epoch {epoch+1} finished')\nprint(prof.key_averages())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T19:49:18.065962Z","iopub.execute_input":"2024-03-26T19:49:18.066371Z","iopub.status.idle":"2024-03-26T19:50:37.974789Z","shell.execute_reply.started":"2024-03-26T19:49:18.066341Z","shell.execute_reply":"2024-03-26T19:50:37.973862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################## ARCHIVE CODE ##########################\n'''\ndef evaluate_significance(model_1, model_2, test_loader):\n    accuracy_m1 = {}\n    accuracy_m2 = {}\n    # For model_1\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model_1.to(device)\n    model_2.to(device)\n    with torch.no_grad():\n        for i, (data, target) in enumerate(test_loader):\n            data, target = data.to(device), target.to(device)\n            output_1 = model_1(data)\n            output_2 = model_2(data)\n            _, predicted_1 = torch.max(output_1.data, 1)\n            _, predicted_2 = torch.max(output_2.data, 1)\n            total = target.size(0)\n            correct_1 = (predicted_1 == target).sum().item()\n            correct_2 = (predicted_2 == target).sum().item()\n            test_accuracy_1 = correct_1 / total\n            test_accuracy_2 = correct_2 / total\n            accuracy_m1[i] = test_accuracy_1\n            accuracy_m2[i] = test_accuracy_2\n    return accuracy_m1, accuracy_m2\n\nimport numpy as np\nmean_m1 = np.mean(list(acc_m1.values())).round(4)\nmean_m2 = np.mean(list(acc_m2.values())).round(4)\nmean_m1, mean_m2\n\nstd_m1 = np.std(list(acc_m1.values())).round(4)\nstd_m2 = np.std(list(acc_m2.values())).round(4)\nstd_m1, std_m2\n\nimport scipy\nscipy.stats.ttest_rel(list(acc_m1.values()), list(acc_m2.values()))\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#############################\n### Create Baseline Model ###\n#############################\n\nclass BaselineCNN(nn.Module):\n  def __init__(self,):\n    super().__init__()\n    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n    self.relu1 = nn.ReLU()\n    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n    self.relu2 = nn.ReLU()\n    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    self.flatten = nn.Flatten()\n    self.fc1 = nn.Linear(64 * 25 * 25, 128) # TODO: Make input size dynamic\n\n    self.relu3 = nn.ReLU()\n    self.fc2 = nn.Linear(128, 10)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.relu1(x)\n    x = self.pool1(x)\n\n    x = self.conv2(x)\n    x = self.relu2(x)\n    x = self.pool2(x)\n\n    x = self.flatten(x)\n    x = self.fc1(x)\n    x = self.relu3(x)\n    x = self.fc2(x)\n    return x\n    '''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nFURTHER ATTENTION BLOCKS\n------------------------------------\nclass LSKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    \n    # When groups == in_channels and out_channels == K * in_channels,\n    # where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    self.conv1_1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=(1, kernel_size), groups=in_channels)#DWConv\n    self.conv1_2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=(kernel_size, 1), groups=in_channels)#DWConv\n    self.conv2_1 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=(1, kernel_size),\n                             dilation=dilation, groups=in_channels, padding=4)#DWDilationConv\n    self.conv2_2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=(kernel_size, 1),\n                             dilation=dilation, groups=in_channels, padding=4)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1_1(x)\n    attn = self.conv1_2(attn)\n    attn = self.conv2_1(attn)\n    attn = self.conv2_2(attn)\n    attn = self.conv3(attn)\n    print(attn.shape)\n    return input * attn\n-----------------------------------\nclass KA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    # When groups == in_channels and out_channels == K * in_channels,\n    # where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=13, padding='same')\n\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n\n    return input * attn\n    \n'''","metadata":{},"execution_count":null,"outputs":[]}]}