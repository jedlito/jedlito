{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Xi9z2tGsLgV_OMGB36wWYdspsBzsG8Sb","authorship_tag":"ABX9TyPua6D/VG55KQLJKEi/Yp89"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":7565076,"sourceType":"datasetVersion","datasetId":4404888}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook contains the empirical study regarding the attention mechanism.","metadata":{}},{"cell_type":"markdown","source":"# TODO's:\n* Gather information about current runtime (GPU name, RAM etc.) and package / python versions - python / pytorch / cuda version are most important\n* Store LR?\n* Implement Early Stopping\n* Store Accuracy for models -> method in Trainer class to save accuracy metrics. -> Information does not get lost! DONE\n* Reproducability? At least when loading in the final model -> ideally ensure, that the computed accuracy stays identical.\n* Specify how to split the PC Components Dataset. (Maybe CV?)\n* Specify VAN for PC Components Dataset\n________________\n# FINAL STEPS:\n* Train networks on MNIST for X epochs\n* Train networks for augmented MNIST for X epochs\n* Train networks on PC Parts for X epochs (Maybe CIFAR10 or skip completely.)\n* Ablation Study (VAN without LKA)\n* Compare Computational Costs (Deepspeed Profiler?)\n - Training time\n - Number of Modules\n - Number of parameters\n - FLOPs\n ","metadata":{}},{"cell_type":"code","source":"# Installation and import of relevant packages\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nimport platform\nimport random\nimport time\nimport torch\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import v2\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.profiler import profile, record_function, ProfilerActivity","metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1711009733593,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"hj481hNsaSLk","execution":{"iopub.status.busy":"2024-04-19T15:04:32.118313Z","iopub.execute_input":"2024-04-19T15:04:32.119126Z","iopub.status.idle":"2024-04-19T15:04:32.125665Z","shell.execute_reply.started":"2024-04-19T15:04:32.119086Z","shell.execute_reply":"2024-04-19T15:04:32.124733Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Get information about current runtime and package versions.\n\n# Check if CUDA is available\ncuda_available = torch.cuda.is_available()\n\n# Get CUDA device count\ncuda_device_count = torch.cuda.device_count() if cuda_available else 0\n\n# Get current CUDA device index\ncuda_device_index = torch.cuda.current_device() if cuda_available else None\n\n# Get name of current CUDA device\ncuda_device_name = torch.cuda.get_device_name(cuda_device_index) if cuda_available else None\n\n# Get CUDA capability of the device\ncuda_capability = torch.cuda.get_device_capability(cuda_device_index) if cuda_available else None\n\n# Get CUDA version\ncuda_version = torch.version.cuda if cuda_available else None\n\n# Get cuDNN version\ncudnn_version = torch.backends.cudnn.version() if cuda_available else None\n\n# Get PyTorch version\npytorch_version = torch.__version__\n\n# Get OS information\nos_info = platform.platform()\n\npython_version = platform.python_version()\n\n# Print the information\nenvironment_dict = {\"OS:\", os_info,\n                    \"GPU:\", cuda_device_name,\n                    \"PyTorch:\", pytorch_version,\n                    \"CUDA:\", cuda_version,\n                    \"cudnn:\", cudnn_version,\n                    \"Python Version:\", python_version\n                   }\nprint(\"OS:\", os_info)\nprint(\"GPU:\", cuda_device_name)\nprint(\"PyTorch:\", pytorch_version)\nprint(\"CUDA:\", cuda_version)\nprint(\"cudnn:\", cudnn_version)\nprint(\"Python Version:\", python_version)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:04:39.425648Z","iopub.execute_input":"2024-04-19T15:04:39.426493Z","iopub.status.idle":"2024-04-19T15:04:39.436197Z","shell.execute_reply.started":"2024-04-19T15:04:39.426459Z","shell.execute_reply":"2024-04-19T15:04:39.435128Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"OS: Linux-5.15.133+-x86_64-with-glibc2.31\nGPU: Tesla P100-PCIE-16GB\nPyTorch: 2.1.2\nCUDA: 12.1\ncudnn: 8900\nPython Version: 3.10.13\n","output_type":"stream"}]},{"cell_type":"code","source":"!pipfile","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:12:07.305618Z","iopub.execute_input":"2024-04-19T15:12:07.306398Z","iopub.status.idle":"2024-04-19T15:12:08.284572Z","shell.execute_reply.started":"2024-04-19T15:12:07.306368Z","shell.execute_reply":"2024-04-19T15:12:08.283506Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"/bin/bash: pipfile: command not found\n","output_type":"stream"}]},{"cell_type":"code","source":"torchvision.__version__","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:06:50.009617Z","iopub.execute_input":"2024-04-19T15:06:50.010423Z","iopub.status.idle":"2024-04-19T15:06:50.016296Z","shell.execute_reply.started":"2024-04-19T15:06:50.010390Z","shell.execute_reply":"2024-04-19T15:06:50.015389Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'0.16.2'"},"metadata":{}}]},{"cell_type":"code","source":"# Create Transformation classes\nclass RandomPlacement(object):\n  def __call__(self, img):\n    canvas = torch.zeros(1,100,100)\n    x = torch.randint(0, 73, (1,))\n    y = torch.randint(0, 73, (1,))\n    canvas[:, x:x+28, y:y+28] = img\n\n    return canvas\n\n\nclass RandomCropAndCombine(object):\n  def __init__(self, dataset):\n    self.dataset = dataset\n\n  def __call__(self, canvas):\n    for _ in range(8):\n      img, _ = random.choice(self.dataset)\n      img = transforms.ToTensor()(img)\n      x = torch.randint(0, 91, (1,))\n      y = torch.randint(0, 91, (1,))\n      patch = transforms.RandomCrop((9,9))(img)\n      canvas[:, x:x+9, y:y+9] += patch\n      canvas = canvas.clamp(0, 1)\n\n    return canvas\n\n\nclass AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n\n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\n\nclass AddSaltandPepperNoise(object):\n    def __init__(self, prob_salt=0.05, prob_pepper=0.05):\n        self.prob_salt = prob_salt\n        self.prob_pepper = prob_pepper\n\n    def __call__(self, tensor):\n\n        random_values = torch.rand_like(tensor)\n        # Create a tensor with the same size as the input, where each element is 0 by default\n        custom_tensor = torch.zeros_like(tensor)\n\n        # Apply thresholds based on probabilities to set values to 1 or -1\n        custom_tensor[random_values < self.prob_pepper] = 1\n        custom_tensor[random_values > (1 - self.prob_salt)] = -1\n        X = tensor + custom_tensor\n        X = X.clamp(min=0, max=1)\n        return X\n\n\nclass AddSpecleNoise(object):\n    def __init__(self, mean=0, std=0.1):\n      self.mean = mean\n      self.std = std\n\n\n    def __call__(self, tensor):\n      X = torch.randn(tensor.size()) * self.std + self.mean\n      #X = X.clamp(min=0, max=1)\n\n      return tensor * X\n","metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1711009738485,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"YM6ay7S8Vu6-","execution":{"iopub.status.busy":"2024-04-19T08:53:45.592160Z","iopub.execute_input":"2024-04-19T08:53:45.592547Z","iopub.status.idle":"2024-04-19T08:53:45.607333Z","shell.execute_reply.started":"2024-04-19T08:53:45.592519Z","shell.execute_reply":"2024-04-19T08:53:45.606219Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(1)\nnp.random.seed(1)\ngenerator = torch.Generator().manual_seed(1)\n\n# Define data transformations\noriginal_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\nmnist_original = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=None)\naugmented_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,)),\n    #transforms.RandomRotation(30),\n    RandomPlacement(),\n    RandomCropAndCombine(mnist_original),\n])\n\n# Train datasets\nmnist_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=original_transform)\naugmented_dataset_train = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=True, download=True, transform=augmented_transform)\n\n# Test datasets\naugmented_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=augmented_transform)\nmnist_dataset_test = datasets.MNIST(root='/content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/', train=False, download=True, transform=original_transform)\n\n# Split train dataset into 90% train and 10% validation data\nmnist_train, mnist_val = torch.utils.data.random_split(dataset=mnist_dataset_train, lengths=[0.9, 0.1], generator=generator)\naugmented_train, augmented_val = torch.utils.data.random_split(dataset=augmented_dataset_train, lengths=[0.9, 0.1], generator=generator)\n\n# Create data loaders for original and augmented datasets\nBATCH_SIZE = 128\n# Load train data\nmnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=BATCH_SIZE, shuffle=True)\ntrain_loader = torch.utils.data.DataLoader(dataset=augmented_train, batch_size=BATCH_SIZE, shuffle=True)\n# Load validation data\nmnist_val_laoder = torch.utils.data.DataLoader(dataset=mnist_val, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset=augmented_val, batch_size=BATCH_SIZE, shuffle=True)\n# Load test data\ntest_loader = torch.utils.data.DataLoader(dataset=augmented_dataset_test, batch_size=BATCH_SIZE, shuffle=False)\nmnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_dataset_test, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T08:53:48.013894Z","iopub.execute_input":"2024-04-19T08:53:48.014595Z","iopub.status.idle":"2024-04-19T08:53:49.099520Z","shell.execute_reply.started":"2024-04-19T08:53:48.014561Z","shell.execute_reply":"2024-04-19T08:53:49.098492Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 130102582.12it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 48318984.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 36098481.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 8243413.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/Colab Notebooks/Masterarbeit - Coding/data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the original and the augmented dataset\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\nfor i in range(4):\n  original_img, _ = mnist_original[i]\n  original_img = transforms.ToTensor()(original_img).squeeze(0)\n  axes[0, i].imshow(original_img, cmap='gray')\n  axes[0, i].axis('off')\n  axes[0, i].set_title('Original')\n\n  augmented_img, _ = augmented_dataset_train[i]\n  augmented_img = augmented_img.squeeze(0)\n  axes[1, i].imshow(augmented_img, cmap='gray')\n  axes[1, i].axis('off')\n  axes[1, i].set_title('Transformed')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":610},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1711014574594,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"kGbbSYiscR-9","outputId":"94d74291-72ba-4227-c66c-289378c48520","execution":{"iopub.status.busy":"2024-04-19T08:53:56.205698Z","iopub.execute_input":"2024-04-19T08:53:56.206059Z","iopub.status.idle":"2024-04-19T08:53:57.136103Z","shell.execute_reply.started":"2024-04-19T08:53:56.206030Z","shell.execute_reply":"2024-04-19T08:53:57.135190Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 8 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Get device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Create single input\nfor item in train_loader:\n  x = item\n  break\nx = x[0]\ninput_data = x.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1711009753878,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"KyCjZLfnHGEV","outputId":"5816ebb3-077c-4571-a9dd-3d437ba05eaa","execution":{"iopub.status.busy":"2024-04-19T08:51:09.952142Z","iopub.execute_input":"2024-04-19T08:51:09.952580Z","iopub.status.idle":"2024-04-19T08:51:10.334373Z","shell.execute_reply.started":"2024-04-19T08:51:09.952545Z","shell.execute_reply":"2024-04-19T08:51:10.333066Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Trainer():\n    def __init__(self, model, optimizer, train_loader, val_loader, test_loader,\n                 num_epochs, estimate_step=100, save_checkpoints=True, path='model'):\n        \n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n        self.criterion = nn.CrossEntropyLoss()\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.num_epochs = num_epochs\n        self.estimate_step = estimate_step\n        self.model_name = type(self.model).__name__\n        self.path = path\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.save_checkpoints = save_checkpoints\n        self.running_loss_train = []\n        self.running_loss_val = []\n        self.train_time_per_epoch = []\n        self.total_epochs_trained = 0\n        self.test_accuracy = None\n        self.inference_time = None\n\n    \n    def train(self):\n        '''\n        Function to train the model. Trains the model on a training dataset and evaluates the current performance\n        on a validation dataset at the end of each epoch. Reduces the learning rate, if there is no\n        improvement in the validation loss for 10 epochs. \n        '''\n        self.model.to(self.device)\n        self.model.train()\n        for epoch in range(self.num_epochs):\n            # Start timer\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            start_epoch = time.time()\n            \n            # Training process for one epoch\n            self.model.train(True)\n            running_loss_train = 0.00\n            for batch_idx, (data, target) in enumerate(self.train_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                self.optimizer.zero_grad(set_to_none=True)\n                output = self.model(data)\n                loss = self.criterion(output, target)\n                running_loss_train += loss.item()\n                loss.backward()\n                self.optimizer.step()\n                if batch_idx % self.estimate_step == 0:\n                    print(f'Epoch {epoch+1}/{self.num_epochs}, Batch {batch_idx}/{len(self.train_loader)}, Train Loss: {loss.item():.4f}')     \n            avg_loss_train = running_loss_train / len(self.train_loader)\n            self.running_loss_train.append(avg_loss_train)\n            \n            # Validate model at the end of each epoch\n            self.model.eval()\n            running_loss_val = 0.00\n            with torch.no_grad():\n                for i, (data_val, target_val) in enumerate(self.val_loader):\n                    data_val, target_val = data_val.to(self.device), target_val.to(self.device)\n                    output_val = self.model(data_val)\n                    loss_val = self.criterion(output_val, target_val)\n                    running_loss_val += loss_val.item()\n                avg_loss_val = running_loss_val / len(self.test_loader)\n                self.running_loss_val.append(avg_loss_val)\n            \n            # Recuce LR if model does not improve for 10 epochs\n            self.scheduler.step(avg_loss_val)\n            \n            # Track training time for each epoch\n            #torch.cuda.synchronize() if self.device == 'cuda' else None\n            end_epoch = time.time()\n            self.train_time_per_epoch.append(end_epoch-start_epoch)\n            print(f'Model {self.model_name} at epoch {epoch+1}/{self.num_epochs}: Avg Train Loss: {avg_loss_train:.4f}, Avg Val Loss: {avg_loss_val:.4f}')\n            \n            # Increase epoch counter\n            self.total_epochs_trained += 1\n            \n            # Save checkpoint at the end of each epoch\n            if self.save_checkpoints:\n                self.save_checkpoint(self.path)\n            \n        # Print total training time at the end\n        train_time = \"{:.2f} minutes\".format(sum(self.train_time_per_epoch) / 60)\n        print(f'Model {self.model_name} took {train_time} to run on {self.total_epochs_trained} epochs.')\n        \n                \n    def eval(self):\n        '''\n        Function to evaluate the performance of the model.\n        Therefore, the models accuracy on a test dataset is measured.\n        '''\n        self.model.to(self.device)\n        self.model.eval()\n        correct = 0\n        total = 0\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        start_eval = time.time()\n        with torch.no_grad():\n            for data, target in self.test_loader:\n                data, target = data.to(self.device), target.to(self.device)\n                output = self.model(data)\n                _, predicted = torch.max(output.data, 1)\n                total += target.size(0)\n                correct += (predicted == target).sum().item()\n        self.test_accuracy = correct / total\n        \n        #torch.cuda.synchronize() if self.device == 'cuda' else None\n        end_eval = time.time()\n        self.inference_time = end_eval - start_eval\n        print(f'Test Accuracy for {self.model_name}: {self.test_accuracy:.4f} - in {self.inference_time} seconds.')\n        \n    def save_checkpoint(self, path):\n        '''\n        Function to save the current state of the model, optimizer and scheduler.\n        Also saves the model metrics training loss, validation loss, accuracy,\n        training and inference time.\n        '''\n        torch.save({'epoch': self.total_epochs_trained,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'scheduler_state_dict': self.scheduler.state_dict(),\n                    'loss': self.running_loss_train[-1],\n                    'running_loss_train': self.running_loss_train,\n                    'running_loss_val': self.running_loss_val,\n                    'test_accuracy': self.test_accuracy,\n                    'inference_time': self.inference_time}, \n                    f'{path}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:10:29.708618Z","iopub.execute_input":"2024-04-19T09:10:29.709069Z","iopub.status.idle":"2024-04-19T09:10:29.733563Z","shell.execute_reply.started":"2024-04-19T09:10:29.709037Z","shell.execute_reply":"2024-04-19T09:10:29.732527Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"##########################\n##### Baseline Model #####\n##########################\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=10, image_channels=1):\n        super(ConvNet, self).__init__()\n        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(147456, 128)\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return F.softmax(x, dim=1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wdk5Gp7tlc4s","executionInfo":{"status":"ok","timestamp":1711019808528,"user_tz":-60,"elapsed":1920959,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"357f0e45-2497-42e1-bb5c-1f23c3ae1434","execution":{"iopub.status.busy":"2024-04-19T08:54:02.971783Z","iopub.execute_input":"2024-04-19T08:54:02.972494Z","iopub.status.idle":"2024-04-19T08:54:02.981137Z","shell.execute_reply.started":"2024-04-19T08:54:02.972465Z","shell.execute_reply":"2024-04-19T08:54:02.980084Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nmodel = ConvNet()\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\ntrainer = Trainer(model=model, optimizer=optimizer,\n                  train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                  num_epochs=30, save_checkpoints=True, path=f'ConvNet()')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:10:33.120062Z","iopub.execute_input":"2024-04-19T09:10:33.120771Z","iopub.status.idle":"2024-04-19T09:10:33.312244Z","shell.execute_reply.started":"2024-04-19T09:10:33.120737Z","shell.execute_reply":"2024-04-19T09:10:33.311442Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer.num_epochs","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:48:06.186476Z","iopub.execute_input":"2024-04-19T10:48:06.187430Z","iopub.status.idle":"2024-04-19T10:48:06.192975Z","shell.execute_reply.started":"2024-04-19T10:48:06.187394Z","shell.execute_reply":"2024-04-19T10:48:06.191995Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:48:09.812258Z","iopub.execute_input":"2024-04-19T10:48:09.813005Z","iopub.status.idle":"2024-04-19T11:50:44.173528Z","shell.execute_reply.started":"2024-04-19T10:48:09.812970Z","shell.execute_reply":"2024-04-19T11:50:44.172531Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/20, Batch 0/422, Train Loss: 1.7848\nEpoch 1/20, Batch 100/422, Train Loss: 1.7305\nEpoch 1/20, Batch 200/422, Train Loss: 1.7939\nEpoch 1/20, Batch 300/422, Train Loss: 1.8599\nEpoch 1/20, Batch 400/422, Train Loss: 1.7198\nModel ConvNet at epoch 1/20: Avg Train Loss: 1.8268, Avg Val Loss: 1.0173\nEpoch 2/20, Batch 0/422, Train Loss: 1.8096\nEpoch 2/20, Batch 100/422, Train Loss: 1.7992\nEpoch 2/20, Batch 200/422, Train Loss: 1.8011\nEpoch 2/20, Batch 300/422, Train Loss: 1.7505\nEpoch 2/20, Batch 400/422, Train Loss: 1.7669\nModel ConvNet at epoch 2/20: Avg Train Loss: 1.8201, Avg Val Loss: 1.0155\nEpoch 3/20, Batch 0/422, Train Loss: 1.8378\nEpoch 3/20, Batch 100/422, Train Loss: 1.7729\nEpoch 3/20, Batch 200/422, Train Loss: 1.8327\nEpoch 3/20, Batch 300/422, Train Loss: 1.8249\nEpoch 3/20, Batch 400/422, Train Loss: 1.8425\nModel ConvNet at epoch 3/20: Avg Train Loss: 1.8116, Avg Val Loss: 1.0159\nEpoch 4/20, Batch 0/422, Train Loss: 1.8943\nEpoch 4/20, Batch 100/422, Train Loss: 1.8335\nEpoch 4/20, Batch 200/422, Train Loss: 1.7239\nEpoch 4/20, Batch 300/422, Train Loss: 1.8064\nEpoch 4/20, Batch 400/422, Train Loss: 1.8378\nModel ConvNet at epoch 4/20: Avg Train Loss: 1.8053, Avg Val Loss: 1.0186\nEpoch 5/20, Batch 0/422, Train Loss: 1.7590\nEpoch 5/20, Batch 100/422, Train Loss: 1.8188\nEpoch 5/20, Batch 200/422, Train Loss: 1.8331\nEpoch 5/20, Batch 300/422, Train Loss: 1.7768\nEpoch 5/20, Batch 400/422, Train Loss: 1.8056\nModel ConvNet at epoch 5/20: Avg Train Loss: 1.8094, Avg Val Loss: 1.0126\nEpoch 6/20, Batch 0/422, Train Loss: 1.7564\nEpoch 6/20, Batch 100/422, Train Loss: 1.7712\nEpoch 6/20, Batch 200/422, Train Loss: 1.7552\nEpoch 6/20, Batch 300/422, Train Loss: 1.8190\nEpoch 6/20, Batch 400/422, Train Loss: 1.7905\nModel ConvNet at epoch 6/20: Avg Train Loss: 1.7982, Avg Val Loss: 1.0099\nEpoch 7/20, Batch 0/422, Train Loss: 1.7439\nEpoch 7/20, Batch 100/422, Train Loss: 1.8802\nEpoch 7/20, Batch 200/422, Train Loss: 1.7574\nEpoch 7/20, Batch 300/422, Train Loss: 1.8193\nEpoch 7/20, Batch 400/422, Train Loss: 1.7557\nModel ConvNet at epoch 7/20: Avg Train Loss: 1.7943, Avg Val Loss: 0.9985\nEpoch 8/20, Batch 0/422, Train Loss: 1.8342\nEpoch 8/20, Batch 100/422, Train Loss: 1.7864\nEpoch 8/20, Batch 200/422, Train Loss: 1.8179\nEpoch 8/20, Batch 300/422, Train Loss: 1.8327\nEpoch 8/20, Batch 400/422, Train Loss: 1.7457\nModel ConvNet at epoch 8/20: Avg Train Loss: 1.7902, Avg Val Loss: 1.0175\nEpoch 9/20, Batch 0/422, Train Loss: 1.8518\nEpoch 9/20, Batch 100/422, Train Loss: 1.7956\nEpoch 9/20, Batch 200/422, Train Loss: 1.7221\nEpoch 9/20, Batch 300/422, Train Loss: 1.7899\nEpoch 9/20, Batch 400/422, Train Loss: 1.7571\nModel ConvNet at epoch 9/20: Avg Train Loss: 1.7887, Avg Val Loss: 0.9958\nEpoch 10/20, Batch 0/422, Train Loss: 1.7512\nEpoch 10/20, Batch 100/422, Train Loss: 1.8088\nEpoch 10/20, Batch 200/422, Train Loss: 1.7817\nEpoch 10/20, Batch 300/422, Train Loss: 1.8057\nEpoch 10/20, Batch 400/422, Train Loss: 1.7805\nModel ConvNet at epoch 10/20: Avg Train Loss: 1.7885, Avg Val Loss: 1.0196\nEpoch 11/20, Batch 0/422, Train Loss: 1.8088\nEpoch 11/20, Batch 100/422, Train Loss: 1.7880\nEpoch 11/20, Batch 200/422, Train Loss: 1.7964\nEpoch 11/20, Batch 300/422, Train Loss: 1.8007\nEpoch 11/20, Batch 400/422, Train Loss: 1.7936\nModel ConvNet at epoch 11/20: Avg Train Loss: 1.7844, Avg Val Loss: 0.9922\nEpoch 12/20, Batch 0/422, Train Loss: 1.7355\nEpoch 12/20, Batch 100/422, Train Loss: 1.7884\nEpoch 12/20, Batch 200/422, Train Loss: 1.7753\nEpoch 12/20, Batch 300/422, Train Loss: 1.7930\nEpoch 12/20, Batch 400/422, Train Loss: 1.7777\nModel ConvNet at epoch 12/20: Avg Train Loss: 1.7745, Avg Val Loss: 1.0061\nEpoch 13/20, Batch 0/422, Train Loss: 1.7256\nEpoch 13/20, Batch 100/422, Train Loss: 1.7999\nEpoch 13/20, Batch 200/422, Train Loss: 1.7321\nEpoch 13/20, Batch 300/422, Train Loss: 1.7306\nEpoch 13/20, Batch 400/422, Train Loss: 1.7890\nModel ConvNet at epoch 13/20: Avg Train Loss: 1.7730, Avg Val Loss: 0.9955\nEpoch 14/20, Batch 0/422, Train Loss: 1.7591\nEpoch 14/20, Batch 100/422, Train Loss: 1.7772\nEpoch 14/20, Batch 200/422, Train Loss: 1.7392\nEpoch 14/20, Batch 300/422, Train Loss: 1.7172\nEpoch 14/20, Batch 400/422, Train Loss: 1.8517\nModel ConvNet at epoch 14/20: Avg Train Loss: 1.7719, Avg Val Loss: 1.0070\nEpoch 15/20, Batch 0/422, Train Loss: 1.7808\nEpoch 15/20, Batch 100/422, Train Loss: 1.7489\nEpoch 15/20, Batch 200/422, Train Loss: 1.7434\nEpoch 15/20, Batch 300/422, Train Loss: 1.8209\nEpoch 15/20, Batch 400/422, Train Loss: 1.7486\nModel ConvNet at epoch 15/20: Avg Train Loss: 1.7692, Avg Val Loss: 0.9925\nEpoch 16/20, Batch 0/422, Train Loss: 1.7277\nEpoch 16/20, Batch 100/422, Train Loss: 1.8098\nEpoch 16/20, Batch 200/422, Train Loss: 1.6999\nEpoch 16/20, Batch 300/422, Train Loss: 1.7779\nEpoch 17/20, Batch 100/422, Train Loss: 1.8119\nEpoch 17/20, Batch 200/422, Train Loss: 1.7522\nEpoch 17/20, Batch 300/422, Train Loss: 1.7985\nEpoch 17/20, Batch 400/422, Train Loss: 1.7472\nModel ConvNet at epoch 17/20: Avg Train Loss: 1.7655, Avg Val Loss: 1.0143\nEpoch 18/20, Batch 0/422, Train Loss: 1.8397\nEpoch 18/20, Batch 100/422, Train Loss: 1.7600\nEpoch 18/20, Batch 200/422, Train Loss: 1.7766\nEpoch 18/20, Batch 300/422, Train Loss: 1.6989\nEpoch 18/20, Batch 400/422, Train Loss: 1.7544\nModel ConvNet at epoch 18/20: Avg Train Loss: 1.7599, Avg Val Loss: 0.9919\nEpoch 19/20, Batch 0/422, Train Loss: 1.7321\nEpoch 19/20, Batch 100/422, Train Loss: 1.7747\nEpoch 19/20, Batch 200/422, Train Loss: 1.6764\nEpoch 19/20, Batch 300/422, Train Loss: 1.7052\nEpoch 19/20, Batch 400/422, Train Loss: 1.7239\nModel ConvNet at epoch 19/20: Avg Train Loss: 1.7559, Avg Val Loss: 0.9876\nEpoch 20/20, Batch 0/422, Train Loss: 1.7762\nEpoch 20/20, Batch 100/422, Train Loss: 1.7821\nEpoch 20/20, Batch 200/422, Train Loss: 1.7271\nEpoch 20/20, Batch 300/422, Train Loss: 1.6613\nEpoch 20/20, Batch 400/422, Train Loss: 1.7272\nModel ConvNet at epoch 20/20: Avg Train Loss: 1.7537, Avg Val Loss: 0.9895\nModel ConvNet took 156.41 minutes to run on 20 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:50:44.175350Z","iopub.execute_input":"2024-04-19T11:50:44.175647Z","iopub.status.idle":"2024-04-19T11:51:16.332297Z","shell.execute_reply.started":"2024-04-19T11:50:44.175622Z","shell.execute_reply":"2024-04-19T11:51:16.331324Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Test Accuracy for ConvNet: 0.8171 - in 32.15020942687988 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"def plot_loss(train_loss, val_loss):\n    epochs = range(1, len(train_loss) + 1)\n    plt.plot(epochs, train_loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n\nplot_loss(trainer.running_loss_train, trainer.running_loss_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:55:13.614931Z","iopub.execute_input":"2024-04-19T11:55:13.615645Z","iopub.status.idle":"2024-04-19T11:55:13.915562Z","shell.execute_reply.started":"2024-04-19T11:55:13.615611Z","shell.execute_reply":"2024-04-19T11:55:13.914671Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcDUlEQVR4nO3deVxU5eIG8GcAGUA2QWQRBDTcFc0tJLc0ty5KbpSWmKY39yW76tUU7JqmuaeWldKiuKPmvoELau6mZqSJSgqpGSAKKMP7++P8ZmQEhjMwzMDwfD+f8xnmzJlz3jlS8/CuCiGEABEREZGZsDB1AYiIiIgMieGGiIiIzArDDREREZkVhhsiIiIyKww3REREZFYYboiIiMisMNwQERGRWWG4ISIiIrPCcENERERmheGGyAQGDRoEPz+/Yr03IiICCoXCsAUqY27evAmFQoGoqCijXjcuLg4KhQJxcXGafXL/rUqrzH5+fhg0aJBBzylHVFQUFAoFbt68afRrE5UUww1RHgqFQtaW98uPqKSOHz+OiIgIpKammrooRGbBytQFICpLfvjhB63n33//Pfbv359vf7169Up0na+//hq5ubnFeu+0adMwefLkEl2f5CvJv5Vcx48fR2RkJAYNGgRnZ2et1xISEmBhwb9DifTBcEOUxzvvvKP1/OTJk9i/f3++/S968uQJ7OzsZF+nUqVKxSofAFhZWcHKiv/pGktJ/q0MQalUmvT6ROUR/xwg0lP79u3RsGFDnD17Fm3btoWdnR3++9//AgC2bduGN954A15eXlAqlahVqxY++eQTqFQqrXO82I9D3V/j888/x8qVK1GrVi0olUq0aNECp0+f1npvQX1uFAoFRo0aha1bt6Jhw4ZQKpVo0KAB9uzZk6/8cXFxaN68OWxsbFCrVi189dVXsvvxHD16FH379kWNGjWgVCrh4+OD8ePHIzMzM9/ns7e3x507dxAaGgp7e3u4ublh4sSJ+e5FamoqBg0aBCcnJzg7OyM8PFxW88yZM2egUCjw3Xff5Xtt7969UCgU2LFjBwDg1q1bGDFiBOrUqQNbW1u4urqib9++svqTFNTnRm6Zf/nlFwwaNAg1a9aEjY0NPDw8MHjwYPz999+aYyIiIvDRRx8BAPz9/TVNn+qyFdTn5saNG+jbty9cXFxgZ2eHV155BTt37tQ6Rt1/aMOGDZg1axa8vb1hY2ODjh074vr160V+7sIsX74cDRo0gFKphJeXF0aOHJnvs1+7dg29e/eGh4cHbGxs4O3tjbfeegtpaWmaY/bv349XX30Vzs7OsLe3R506dTT/HRGVFP/8IyqGv//+G926dcNbb72Fd955B+7u7gCkTpj29vaYMGEC7O3tcejQIUyfPh3p6emYN29ekeddu3YtHj16hH//+99QKBSYO3cuevXqhRs3bhRZg3Ds2DFs2bIFI0aMgIODA5YsWYLevXvj9u3bcHV1BQCcP38eXbt2haenJyIjI6FSqTBz5ky4ubnJ+twbN27EkydPMHz4cLi6uuLUqVNYunQp/vzzT2zcuFHrWJVKhS5duqBVq1b4/PPPceDAAcyfPx+1atXC8OHDAQBCCPTs2RPHjh3DBx98gHr16iEmJgbh4eFFlqV58+aoWbMmNmzYkO/49evXo0qVKujSpQsA4PTp0zh+/DjeeusteHt74+bNm1ixYgXat2+PX3/9Va9aN33KvH//fty4cQPvvfcePDw8cOXKFaxcuRJXrlzByZMnoVAo0KtXL/z++++Ijo7GwoULUbVqVQAo9N/kr7/+QuvWrfHkyROMGTMGrq6u+O6779CjRw9s2rQJb775ptbxc+bMgYWFBSZOnIi0tDTMnTsXAwYMwM8//yz7M6tFREQgMjISnTp1wvDhw5GQkIAVK1bg9OnTiI+PR6VKlfD06VN06dIF2dnZGD16NDw8PHDnzh3s2LEDqampcHJywpUrV/Cvf/0LjRs3xsyZM6FUKnH9+nXEx8frXSaiAgkiKtTIkSPFi/+ZtGvXTgAQX375Zb7jnzx5km/fv//9b2FnZyeysrI0+8LDw4Wvr6/meWJiogAgXF1dxcOHDzX7t23bJgCIn376SbNvxowZ+coEQFhbW4vr169r9l28eFEAEEuXLtXsCwkJEXZ2duLOnTuafdeuXRNWVlb5zlmQgj7f7NmzhUKhELdu3dL6fADEzJkztY5t2rSpaNasmeb51q1bBQAxd+5czb6cnBzRpk0bAUCsXr1aZ3mmTJkiKlWqpHXPsrOzhbOzsxg8eLDOcp84cUIAEN9//71mX2xsrAAgYmNjtT5L3n8rfcpc0HWjo6MFAHHkyBHNvnnz5gkAIjExMd/xvr6+Ijw8XPN83LhxAoA4evSoZt+jR4+Ev7+/8PPzEyqVSuuz1KtXT2RnZ2uOXbx4sQAgLl26lO9aea1evVqrTPfu3RPW1taic+fOmmsIIcQXX3whAIhVq1YJIYQ4f/68ACA2btxY6LkXLlwoAIj79+/rLANRcbFZiqgYlEol3nvvvXz7bW1tNT8/evQIDx48QJs2bfDkyRP89ttvRZ43LCwMVapU0Txv06YNAKkZoiidOnVCrVq1NM8bN24MR0dHzXtVKhUOHDiA0NBQeHl5aY576aWX0K1btyLPD2h/vsePH+PBgwdo3bo1hBA4f/58vuM/+OADredt2rTR+iy7du2ClZWVpiYHACwtLTF69GhZ5QkLC8OzZ8+wZcsWzb59+/YhNTUVYWFhBZb72bNn+Pvvv/HSSy/B2dkZ586dk3Wt4pQ573WzsrLw4MEDvPLKKwCg93XzXr9ly5Z49dVXNfvs7e0xbNgw3Lx5E7/++qvW8e+99x6sra01z/X5ncrrwIEDePr0KcaNG6fVwXno0KFwdHTUNIs5OTkBkJoGnzx5UuC51J2mt23bVuqdtaliYrghKobq1atrfWGoXblyBW+++SacnJzg6OgINzc3TWfkvP0NClOjRg2t5+qg888//+j9XvX71e+9d+8eMjMz8dJLL+U7rqB9Bbl9+zYGDRoEFxcXTT+adu3aAcj/+WxsbPI1reQtDyD1hfH09IS9vb3WcXXq1JFVnsDAQNStWxfr16/X7Fu/fj2qVq2K1157TbMvMzMT06dPh4+PD5RKJapWrQo3NzekpqbK+nfJS58yP3z4EGPHjoW7uztsbW3h5uYGf39/APJ+Hwq7fkHXUo/gu3Xrltb+kvxOvXhdIP/ntLa2Rs2aNTWv+/v7Y8KECfjmm29QtWpVdOnSBcuWLdP6vGFhYQgODsb7778Pd3d3vPXWW9iwYQODDhkM+9wQFUPev8jVUlNT0a5dOzg6OmLmzJmoVasWbGxscO7cOUyaNEnW/7gtLS0L3C+EKNX3yqFSqfD666/j4cOHmDRpEurWrYvKlSvjzp07GDRoUL7PV1h5DC0sLAyzZs3CgwcP4ODggO3bt+Ptt9/WGlE2evRorF69GuPGjUNQUBCcnJygUCjw1ltvleoXar9+/XD8+HF89NFHaNKkCezt7ZGbm4uuXbsa7Yu8tH8vCjJ//nwMGjQI27Ztw759+zBmzBjMnj0bJ0+ehLe3N2xtbXHkyBHExsZi586d2LNnD9avX4/XXnsN+/btM9rvDpkvhhsiA4mLi8Pff/+NLVu2oG3btpr9iYmJJizVc9WqVYONjU2BI2XkjJ65dOkSfv/9d3z33XcYOHCgZv/+/fuLXSZfX18cPHgQGRkZWjUhCQkJss8RFhaGyMhIbN68Ge7u7khPT8dbb72ldcymTZsQHh6O+fPna/ZlZWUVa9I8uWX+559/cPDgQURGRmL69Oma/deuXct3Tn1mnPb19S3w/qibPX19fWWfSx/q8yYkJKBmzZqa/U+fPkViYiI6deqkdXyjRo3QqFEjTJs2DcePH0dwcDC+/PJL/O9//wMAWFhYoGPHjujYsSMWLFiATz/9FFOnTkVsbGy+cxHpi81SRAai/msz71/ET58+xfLly01VJC2Wlpbo1KkTtm7dirt372r2X79+Hbt375b1fkD78wkhsHjx4mKXqXv37sjJycGKFSs0+1QqFZYuXSr7HPXq1UOjRo2wfv16rF+/Hp6enlrhUl32F2sqli5dmm9YuiHLXND9AoBFixblO2flypUBQFbY6t69O06dOoUTJ05o9j1+/BgrV66En58f6tevL/ej6KVTp06wtrbGkiVLtD7Tt99+i7S0NLzxxhsAgPT0dOTk5Gi9t1GjRrCwsEB2djYAqbnuRU2aNAEAzTFEJcGaGyIDad26NapUqYLw8HCMGTMGCoUCP/zwQ6lW/+srIiIC+/btQ3BwMIYPHw6VSoUvvvgCDRs2xIULF3S+t27duqhVqxYmTpyIO3fuwNHREZs3b9a770ZeISEhCA4OxuTJk3Hz5k3Ur18fW7Zs0bs/SlhYGKZPnw4bGxsMGTIk34y+//rXv/DDDz/AyckJ9evXx4kTJ3DgwAHNEPnSKLOjoyPatm2LuXPn4tmzZ6hevTr27dtXYE1es2bNAABTp07FW2+9hUqVKiEkJEQTevKaPHkyoqOj0a1bN4wZMwYuLi747rvvkJiYiM2bN5fabMZubm6YMmUKIiMj0bVrV/To0QMJCQlYvnw5WrRooelbdujQIYwaNQp9+/ZF7dq1kZOTgx9++AGWlpbo3bs3AGDmzJk4cuQI3njjDfj6+uLevXtYvnw5vL29tTpKExUXww2Rgbi6umLHjh348MMPMW3aNFSpUgXvvPMOOnbsqJlvxdSaNWuG3bt3Y+LEifj444/h4+ODmTNn4urVq0WO5qpUqRJ++uknTf8JGxsbvPnmmxg1ahQCAwOLVR4LCwts374d48aNw48//giFQoEePXpg/vz5aNq0qezzhIWFYdq0aXjy5InWKCm1xYsXw9LSEmvWrEFWVhaCg4Nx4MCBYv276FPmtWvXYvTo0Vi2bBmEEOjcuTN2796tNVoNAFq0aIFPPvkEX375Jfbs2YPc3FwkJiYWGG7c3d1x/PhxTJo0CUuXLkVWVhYaN26Mn376SVN7UloiIiLg5uaGL774AuPHj4eLiwuGDRuGTz/9VDMPU2BgILp06YKffvoJd+7cgZ2dHQIDA7F7927NSLEePXrg5s2bWLVqFR48eICqVauiXbt2iIyM1Iy2IioJhShLf1YSkUmEhobiypUrBfYHISIqb9jnhqiCeXGphGvXrmHXrl1o3769aQpERGRgrLkhqmA8PT016x3dunULK1asQHZ2Ns6fP4+AgABTF4+IqMTY54aogunatSuio6ORkpICpVKJoKAgfPrppww2RGQ2WHNDREREZoV9boiIiMisMNwQERGRWalwfW5yc3Nx9+5dODg46DXlOREREZmOEAKPHj2Cl5dXkZNVVrhwc/fuXfj4+Ji6GERERFQMSUlJ8Pb21nlMhQs3Dg4OAKSb4+joaOLSEBERkRzp6enw8fHRfI/rUuHCjbopytHRkeGGiIionJHTpYQdiomIiMisMNwQERGRWWG4ISIiIrNS4frcEBGRYeXm5uLp06emLgaZAWtr6yKHecvBcENERMX29OlTJCYmIjc319RFITNgYWEBf39/WFtbl+g8DDdERFQsQggkJyfD0tISPj4+BvmLmyou9SS7ycnJqFGjRokm2mW4ISKiYsnJycGTJ0/g5eUFOzs7UxeHzICbmxvu3r2LnJwcVKpUqdjnYcwmIqJiUalUAFDiJgQiNfXvkvp3q7gYboiIqES4Th8ZiqF+l9gsZSAqFXD0KJCcDHh6Am3aAJaWpi4VERFRxcOaGwPYsgXw8wM6dAD695ce/fyk/UREZP78/PywaNEi2cfHxcVBoVAgNTW11MoEAFFRUXB2di7Va5RFDDcltGUL0KcP8Oef2vvv3JH2M+AQEemmUgFxcUB0tPRYwu4WOikUCp1bREREsc57+vRpDBs2TPbxrVu3RnJyMpycnIp1PdKNzVIloFIBY8cCQuR/TQhAoQDGjQN69mQTFRFRQbZskf4/mvcPRG9vYPFioFcvw18vOTlZ8/P69esxffp0JCQkaPbZ29trfhZCQKVSwcqq6K9KNzc3vcphbW0NDw8Pvd5D8rHmpgSOHs1fY5OXEEBSknQcERFpM0XNt4eHh2ZzcnKCQqHQPP/tt9/g4OCA3bt3o1mzZlAqlTh27Bj++OMP9OzZE+7u7rC3t0eLFi1w4MABrfO+2CylUCjwzTff4M0334SdnR0CAgKwfft2zesvNkupm4/27t2LevXqwd7eHl27dtUKYzk5ORgzZgycnZ3h6uqKSZMmITw8HKGhoXrdgxUrVqBWrVqwtrZGnTp18MMPP2heE0IgIiICNWrUgFKphJeXF8aMGaN5ffny5QgICICNjQ3c3d3Rp08fva5tLAw3JZDnd84gxxERVRRF1XwDUs13aTZRFWby5MmYM2cOrl69isaNGyMjIwPdu3fHwYMHcf78eXTt2hUhISG4ffu2zvNERkaiX79++OWXX9C9e3cMGDAADx8+LPT4J0+e4PPPP8cPP/yAI0eO4Pbt25g4caLm9c8++wxr1qzB6tWrER8fj/T0dGzdulWvzxYTE4OxY8fiww8/xOXLl/Hvf/8b7733HmJjYwEAmzdvxsKFC/HVV1/h2rVr2Lp1Kxo1agQAOHPmDMaMGYOZM2ciISEBe/bsQdu2bfW6vtGICiYtLU0AEGlpaSU+V2ysENJ/hrq32NgSX4qIqMzJzMwUv/76q8jMzNT7vWXh/5+rV68WTk5OecoUKwCIrVu3FvneBg0aiKVLl2qe+/r6ioULF2qeAxDTpk3TPM/IyBAAxO7du7Wu9c8//2jKAkBcv35d855ly5YJd3d3zXN3d3cxb948zfOcnBxRo0YN0bNnT9mfsXXr1mLo0KFax/Tt21d0795dCCHE/PnzRe3atcXTp0/znWvz5s3C0dFRpKenF3q9ktL1O6XP9zdrbkqgTRupbbiwYfkKBeDjIx1HRETPleWa7+bNm2s9z8jIwMSJE1GvXj04OzvD3t4eV69eLbLmpnHjxpqfK1euDEdHR9y7d6/Q4+3s7FCrVi3Nc09PT83xaWlp+Ouvv9CyZUvN65aWlmjWrJlen+3q1asIDg7W2hccHIyrV68CAPr27YvMzEzUrFkTQ4cORUxMDHJycgAAr7/+Onx9fVGzZk28++67WLNmDZ48eaLX9Y2F4aYELC2lTm9A/oCjfr5oETsTExG9yNPTsMcZUuXKlbWeT5w4ETExMfj0009x9OhRXLhwAY0aNSpyJfQXlw9QKBQ6Fxgt6HhRULtdKfLx8UFCQgKWL18OW1tbjBgxAm3btsWzZ8/g4OCAc+fOITo6Gp6enpg+fToCAwNLfTh7cTDclFCvXsCmTUD16tr7vb2l/aXR25+IqLwrTzXf8fHxGDRoEN588000atQIHh4euHnzplHL4OTkBHd3d5w+fVqzT6VS4dy5c3qdp169eoiPj9faFx8fj/r162ue29raIiQkBEuWLEFcXBxOnDiBS5cuAQCsrKzQqVMnzJ07F7/88gtu3ryJQ4cOleCTlQ4OBTeAXr2k4d6coZiISB51zXefPlKQyVtBUdZqvgMCArBlyxaEhIRAoVDg448/1lkDU1pGjx6N2bNn46WXXkLdunWxdOlS/PPPP3otWfDRRx+hX79+aNq0KTp16oSffvoJW7Zs0Yz+ioqKgkqlQqtWrWBnZ4cff/wRtra28PX1xY4dO3Djxg20bdsWVapUwa5du5Cbm4s6deqU1kcuNoYbA7G0BNq3N3UpiIjKD3XNd0Hz3CxaVHZqvhcsWIDBgwejdevWqFq1KiZNmoT09HSjl2PSpElISUnBwIEDYWlpiWHDhqFLly6w1CMBhoaGYvHixfj8888xduxY+Pv7Y/Xq1Wj//19gzs7OmDNnDiZMmACVSoVGjRrhp59+gqurK5ydnbFlyxZEREQgKysLAQEBiI6ORoMGDUrpExefQhi7Qc/E0tPT4eTkhLS0NDg6Opq6OERE5VZWVhYSExPh7+8PGxubYp+Ha/MVT25uLurVq4d+/frhk08+MXVxDELX75Q+39+suSEiIpNizbc8t27dwr59+9CuXTtkZ2fjiy++QGJiIvr372/qopU5DDdGxL9OiIiouCwsLBAVFYWJEydCCIGGDRviwIEDqFevnqmLVuYw3BiJsddPISIi8+Lj45NvpBMVjEPBjYArhxMRERmPScPN7Nmz0aJFCzg4OKBatWoIDQ3VWp21IF9//TXatGmDKlWqoEqVKujUqRNOnTplpBLrryyvn0JERGSOTBpuDh8+jJEjR+LkyZPYv38/nj17hs6dO+Px48eFvicuLg5vv/02YmNjceLECfj4+KBz5864c+eOEUsuH1cOJyIiMi6T9rnZs2eP1vOoqChUq1YNZ8+eLXSl0TVr1mg9/+abb7B582YcPHgQAwcOLLWyFldZXj+FiIjIHJWpDsVpaWkAABcXF9nvefLkCZ49e1boe7Kzs5Gdna15buyJl8ry+ilERETmqMx0KM7NzcW4ceMQHByMhg0byn7fpEmT4OXlhU6dOhX4+uzZs+Hk5KTZfHx8DFVkWfRdP0WlAuLigOho6ZF9cYiIiPRTZsLNyJEjcfnyZaxbt072e+bMmYN169YhJiam0Nkxp0yZgrS0NM2WlJRkqCLLos/K4Vu2AH5+QIcOQP/+0qOfH0dTERGVNe3bt8e4ceM0z/38/LBo0SKd71EoFNi6dWuJr22o8+gSERGBJk2alOo1SlOZCDejRo3Cjh07EBsbC29vb1nv+fzzzzFnzhzs27cPjRs3LvQ4pVIJR0dHrc3Y5KwczuHiRESlLyQkBF27di3wtaNHj0KhUOCXX37R+7ynT5/GsGHDSlo8LYUFjOTkZHTr1s2g1zI3Ju1zI4TA6NGjERMTg7i4OPj7+8t639y5czFr1izs3bsXzZs3L+VSGoaulcOLGi6uUEjDxXv25IzGREQlMWTIEPTu3Rt//vlnvj+mV69ejebNm+v8g7kwbm5uhipikTw8PIx2rfLKpDU3I0eOxI8//oi1a9fCwcEBKSkpSElJQWZmpuaYgQMHYsqUKZrnn332GT7++GOsWrUKfn5+mvdkZGSY4iPoRb1+yttvS4/qoMLh4kRExvGvf/0Lbm5uiIqK0tqfkZGBjRs3YsiQIfj777/x9ttvo3r16rCzs0OjRo0QHR2t87wvNktdu3YNbdu2hY2NDerXr4/9+/fne8+kSZNQu3Zt2NnZoWbNmvj444/x7NkzANLo4cjISFy8eBEKhQIKhUJT5hebpS5duoTXXnsNtra2cHV1xbBhw7S+EwcNGoTQ0FB8/vnn8PT0hKurK0aOHKm5lhy5ubmYOXMmvL29oVQq0aRJE60Rz0+fPsWoUaPg6ekJGxsb+Pr6Yvbs2QCkioyIiAjUqFEDSqUSXl5eGDNmjOxrF4dJa25WrFgBAJql1tVWr16NQYMGAQBu374NCwsLrfc8ffoUffr00XrPjBkzEBERUZrFLTXFGS7OdaqIqMwRAnjyxDTXtrMrfORGHlZWVhg4cCCioqIwdepUKP7/PRs3boRKpcLbb7+NjIwMNGvWDJMmTYKjoyN27tyJd999F7Vq1ULLli2LvEZubi569eoFd3d3/Pzzz0hLS9Pqn6Pm4OCAqKgoeHl54dKlSxg6dCgcHBzwn//8B2FhYbh8+TL27NmDAwcOAACcnJzynePx48fo0qULgoKCcPr0ady7dw/vv/8+Ro0apRXgYmNj4enpidjYWFy/fh1hYWFo0qQJhg4dWuTnAYDFixdj/vz5+Oqrr9C0aVOsWrUKPXr0wJUrVxAQEIAlS5Zg+/bt2LBhA2rUqIGkpCRNH9fNmzdj4cKFWLduHRo0aICUlBRcvHhR1nWLTVQwaWlpAoBIS0szdVE0YmOFkP6voHuLjZWO37xZCG9v7de8vaX9RETGkpmZKX799VeRmZkp7cjIkPc/s9LYMjJkl/vq1asCgIhV/09VCNGmTRvxzjvvFPqeN954Q3z44Yea5+3atRNjx47VPPf19RULFy4UQgixd+9eYWVlJe7cuaN5fffu3QKAiImJKfQa8+bNE82aNdM8nzFjhggMDMx3XN7zrFy5UlSpUkVk5Pn8O3fuFBYWFiIlJUUIIUR4eLjw9fUVOTk5mmP69u0rwsLCCi3Li9f28vISs2bN0jqmRYsWYsSIEUIIIUaPHi1ee+01kZubm+9c8+fPF7Vr1xZPnz4t9Hpq+X6n8tDn+7tMdCiu6PQZLs6Ox0REJVO3bl20bt0aq1atAgBcv34dR48exZAhQwAAKpUKn3zyCRo1agQXFxfY29tj7969uH37tqzzX716FT4+PvDy8tLsCwoKynfc+vXrERwcDA8PD9jb22PatGmyr5H3WoGBgahcubJmX3BwMHJzc7WWM2rQoAEs81Tve3p64t69e7KukZ6ejrt37yI4OFhrf3BwMK5evQpAavq6cOEC6tSpgzFjxmDfvn2a4/r27YvMzEzUrFkTQ4cORUxMDHJycvT6nPpiuCkD5A4XB7hOFRGVYXZ2QEaGaTY7O72KOmTIEGzevBmPHj3C6tWrUatWLbRr1w4AMG/ePCxevBiTJk1CbGwsLly4gC5duuDp06cGu1UnTpzAgAED0L17d+zYsQPnz5/H1KlTDXqNvCpVqqT1XKFQIDc312Dnf/nll5GYmIhPPvkEmZmZ6Nevn6b7iI+PDxISErB8+XLY2tpixIgRaNu2rV59fvTFcFNGyBkuzo7HRFSmKRRA5cqm2WT0t8mrX79+sLCwwNq1a/H9999j8ODBmv438fHx6NmzJ9555x0EBgaiZs2a+P3332Wfu169ekhKSkJyno6SJ0+e1Drm+PHj8PX1xdSpU9G8eXMEBATg1q1bWsdYW1tDVcRfq/Xq1cPFixe11mSMj4+HhYUF6tSpI7vMujg6OsLLywvx8fFa++Pj41G/fn2t48LCwvD1119j/fr12Lx5Mx4+fAgAsLW1RUhICJYsWYK4uDicOHECly5dMkj5ClKmll+o6HQNFwe4ThURkaHY29sjLCwMU6ZMQXp6umYQCwAEBARg06ZNOH78OKpUqYIFCxbgr7/+0voi16VTp06oXbs2wsPDMW/ePKSnp2Pq1KlaxwQEBOD27dtYt24dWrRogZ07dyImJkbrGD8/PyQmJuLChQvw9vaGg4MDlEql1jEDBgzAjBkzEB4ejoiICNy/fx+jR4/Gu+++C3d39+LdnAJ89NFHmDFjBmrVqoUmTZpg9erVuHDhgma9xwULFsDT0xNNmzaFhYUFNm7cCA8PDzg7OyMqKgoqlQqtWrWCnZ0dfvzxR9ja2sLX19dg5XsRa27KmMKGiwNcp4qIyJCGDBmCf/75B126dNHqHzNt2jS8/PLL6NKlC9q3bw8PDw+EhobKPq+FhQViYmKQmZmJli1b4v3338esWbO0junRowfGjx+PUaNGoUmTJjh+/Dg+/vhjrWN69+6Nrl27okOHDnBzcytwOLqdnR327t2Lhw8fokWLFujTpw86duyIL774Qr+bUYQxY8ZgwoQJ+PDDD9GoUSPs2bMH27dvR0BAAABp5NfcuXPRvHlztGjRAjdv3sSuXbtgYWEBZ2dnfP311wgODkbjxo1x4MAB/PTTT3B1dTVoGfNSCFFQDw7zlZ6eDicnJ6SlpZlktuKSUKmk5Rju3Cm4341CITVjJSY+nxyQw8WJqLRkZWUhMTER/v7+hS6BQ6QPXb9T+nx/s+amHOE6VUREREVjuClnuE4VERGRbuxQXA5xnSoiIqLCMdyUU+qOxy/SZ7h4Qe8nIiIq79gsZWY4XJyIjK2CjUuhUmSo3yWGGzPD4eJEZCzq6fxLa1ZdqnjUv0uWJew3wWYpM6Nep6qo4eJt2hi/bERkXqysrGBnZ4f79++jUqVKsLDg38tUfLm5ubh//z7s7OxgZVWyeMJwY2bUw8X79JGCTN6A8+JwcYBz4RBR8SkUCnh6eiIxMTHf0gFExWFhYYEaNWpolsIoLoYbM6QeLj52rHbnYm9vKdj06iU937Kl4GMWL35+DBGRLtbW1ggICGDTFBmEtbW1QWoAOUOxGdNVK6OeC+fFf311WFbPmUNERFQW6PP9zXBTAamXcShsyPiLyzgQERGZGpdfIJ30mQuHiIiovGGfmwpI37lw2OmYiIjKE4abCkifuXDY6ZiIiMobNktVQOq5cAobaadQAD4+wIMHXICTiIjKH4abCkg9Fw6QP+Con8+fD4wfX/gCnIC0AKdKVWrFJCIiKhaGmwpKPRdO9era+729pf1ubux0TERE5RP73FRgvXoBPXsW3Fk4OlreObgAJxERlTUMNxWcpSXQvn3+/fouwMkRVUREVFawWYoKJLfTcZs2UsdiPz+gQwegf3/p0c+PHY6JiMg0GG6oQHI6HS9aBGzbxhFVRERUtjDcUKGK6nTcs6c0Bw5HVBERUVnCPjekk65Ox3Fx8kdUFdSvh4iIqDQw3FCRCut0rO8yDgA7HhMRUeljuKFi03dEFZdyICIiY2CfGyo2fUdUseMxEREZA8MNFZvcEVUAOx4TEZHxMNxQiRQ1oqpXL6mPDZdyICIiY2GfGyoxXSOqAP07HrPTMRERlQTDDRlEYSOqAP06HrPTMRERlRSbpajUye14/OABOx0TEVHJMdxQqZPT8Xj+fGD8eHY6JiKikmO4IaMoquOxm5t+nY5VKmmG5Oho6ZGhh4iI1NjnhoxGV8fj6Gh550hOZr8cIiLSjeGGjKqwjsdyOx1fuwZERORvvlL3y1EPPycioopLIURBvRzMV3p6OpycnJCWlgZHR0dTF4f+n0oF+PlJIaWg30iF4nmTVmHNVwqFVIOTmCiFKA4pJyIyH/p8f5u0z83s2bPRokULODg4oFq1aggNDUVCQkKR79u4cSPq1q0LGxsbNGrUCLt27TJCaak0yel0PHSo/H45W7ZIYalDB6B/f+nRz48jroiIKgKThpvDhw9j5MiROHnyJPbv349nz56hc+fOePz4caHvOX78ON5++20MGTIE58+fR2hoKEJDQ3H58mUjlpxKQ1GdjgMC5J1n2zYOKSciqsjKVLPU/fv3Ua1aNRw+fBht27Yt8JiwsDA8fvwYO3bs0Ox75ZVX0KRJE3z55ZdFXoPNUmVfYc1JcXFSDUxR3NyA+/cLfu3FpisiIiof9Pn+LlMditPS0gAALi4uhR5z4sQJTJgwQWtfly5dsHXr1gKPz87ORnZ2tuZ5enp6yQtKpaqwTsfqyQB19cupWrXwYANoN121b89+OURE5qjMzHOTm5uLcePGITg4GA0bNiz0uJSUFLi7u2vtc3d3R0pKSoHHz549G05OTprNx8fHoOUm45HTL2fAAHnnUg8pZ78cIiLzU2bCzciRI3H58mWsW7fOoOedMmUK0tLSNFtSUpJBz0/GVVS/nJ495Z3n2jX9+uVw0kAiovKjTDRLjRo1Cjt27MCRI0fg7e2t81gPDw/89ddfWvv++usveHh4FHi8UqmEUqk0WFnJ9HRNBqhSFd10Vb068PXXhS/1oFBISz307Cmdk5MGEhGVLyatuRFCYNSoUYiJicGhQ4fg7+9f5HuCgoJw8OBBrX379+9HUFBQaRWTyiB1v5y335Ye1f1kSmNIOUdeERGVLyYNNyNHjsSPP/6ItWvXwsHBASkpKUhJSUFmZqbmmIEDB2LKlCma52PHjsWePXswf/58/Pbbb4iIiMCZM2cwatQoU3wEKoMMNaT8zh2pxoaLeRIRlS8mDTcrVqxAWloa2rdvD09PT822fv16zTG3b99GcnKy5nnr1q2xdu1arFy5EoGBgdi0aRO2bt2qsxMyVTy9egE3bwKxscDatdJjYqK0X+5SD/fv67eYJxERlQ0m7XMjZ4qduLi4fPv69u2Lvn37lkKJyJyUZEi5t7c0X44c6uzNYeVERGVDmRktRWQscvrlLFqUv1mrMJ6eHFZORFSWMNxQhVRUv5xevZ7X8LwYgNQUCsDHB3jwQH6nYw4pJyIqfWVq+QVj4PILlFdRTUnq0VKAdhOWOvCsXw9MmCBvpfJt2ziknIiouMrNquBEplbYkHK1omp43NzkdTqeNYtDyomIjIU1N0QyFFbDEx0t9bEpiosL8PBhwa+9uJgnOyYTEeVXbhfOJCqrCht5JXdYeWHBBtAeUv7wIZuuiIhKis1SRCUgp9OxjkXutWzbxqYrIiJDYLghKgE5w8rHjpV3rjVrOBsyEZEhMNwQlVBRnY6nTi26dsfNTZoRuTAvzobMIeVERIVjuCEyAF3LPcip3RkwQN51kpM5YSARUVEYbogMRNew8qJqd3r2lHeNa9fYL4eIqCgcCk5kRIUN81appNoXXetdqYORnAkD1cGKw8qJyFxwEj+iMqqw2h05TVdDh+q3Srnc5iv23yEic8NwQ1RGFNV0FRAg7zzqfjlymq/Yf4eIzBEn8SMqQ3r1kvrfFNSUFBcn7xzVqgGDBhU+rFyhkIaV5+YC/frlP04dgNQLiAJs3iKi8oV9bojKCTn9cry9gdWrgU6dij6fruHnXPCTiMoa9rkhMkNy+uUsWgTcuyfvfHLm1eGCn0RUHjHcEJUjRfXL6dVL/npXcixezFmTiaj8YbMUUTmkqw+MnOarqlV119zoIzZWGvnFfjlEVJrYLEVk5nRNGCin+WrZMsMt+MlZk4morGG4ITJDRTVf9e1ruAU/OWsyEZU1bJYiMmNFNRVt2ZJ/JJSPj9QxuWdPw8+azKYrIioufb6/GW6IKjhdgUM9GSCgHXDUtTsREcCMGUVfIzYWePhQ/pByhiAiehH73BCRbCVZ8FPurMnbtslvumL/HSIqKdbcEFGRCqtJiYuTwkdR9JkwsE+f/M1g6pqivLMmE1HFwmYpHRhuiAzHkMPODxyQlo1g/x0iKgibpYjIKOQMOx8wQN654uLkr3rOpisi0oXhhohKpKh+OT17GvZ6+vTfUamk0BQdLT1yNmWiioHNUkRkEIU1E5X1BT/ZvEVUPrDPjQ4MN0TGV9SQcnUNj6H670RGSsPUi+qYXNA8P1zxnKhsYp8bIipT5Cz4acj+O3IW/Ny0iTMrE5kr1twQkdHIaQLSNWuyi4u8oedyyG3e0mdkFpu4iEoPm6V0YLghKvtK0n+nShVpNmRD0GdmZTZxEZUuNksRUblW2KzJcpqu5C74KYfckVnqPkVs4iIqG1hzQ0TlTkkX/JTbMVlO09X160CtWoadfJDNW0T5seaGiMxar17AzZtSs9HatdJjYqL8jsnLlkmB48XX8x6nK9gAzycVXL7csJMPcoJCopJjuCGicqkkC3727Wu4kVl//CHvODlNXPo0b3GCQqLCsVmKiMxWUc07hhiZtXAhMH580ccV1cSlDmJymrfkTlBIZE44WkoHhhsiyqukMyur+9wYoo+PHHInKNT12YqD/YDI1NjnhohIppKMzFq0CLC2NlwTlxxyJihUqfTru1NUExf7AVF5w3BDRFQIOTMryznOkIuH6prDR915edYs+X13igouHOZO5RGbpYiIilDSGYrlNHGpg5EhJih0cSn8uBf77vTpU3gT1/r1wIQJhh3mTlRc5aZZ6siRIwgJCYGXlxcUCgW2bt1a5HvWrFmDwMBA2NnZwdPTE4MHD8bff/9d+oUlogpL18gsOcfJaeJavNhwExTKqd2Ji5POp6uJa+RIww5zBzjKi4zDpOHm8ePHCAwMxLJly2QdHx8fj4EDB2LIkCG4cuUKNm7ciFOnTmHo0KGlXFIiopKR08RV1DFTpxY9P4+Li7zyxMUVHVzkdoLWZyZnBiAyClFGABAxMTE6j5k3b56oWbOm1r4lS5aI6tWry75OWlqaACDS0tKKU0wiohLJyREiNlaItWulx5wc/Y7ZvFkIhULapAgibep9kZHa+wvbpk2Td5yczc2t8NcUCiF8fITYuDF/mfOWe/Pm55/P21v7GG/v568b8l5S+aLP93e5CjfHjh0TlSpVEjt37hS5ubkiJSVFtG3bVgwdOrTQ92RlZYm0tDTNlpSUxHBDROVaQQHAx0fan5MjvVZQkMgbNg4ckB9cdJ1LV7AprQBU2D14MQTJDUoMQOWD2YYbIYTYsGGDsLe3F1ZWVgKACAkJEU+fPi30+BkzZggA+TaGGyIqz0pSu6NPCFIHjsLONW6ccWuAcnKefz5dIUjOMep7JbemiEzLbMPNlStXhKenp5g7d664ePGi2LNnj2jUqJEYPHhwoe9hzQ0RVUS6anfyHlNUCCrqXLGxhgs3crYDB/KX5cWye3sXfYy+NUVkevqEmzIzFFyhUCAmJgahoaGFHvPuu+8iKysLGzdu1Ow7duwY2rRpg7t378LT07PI63AoOBFVFHKGZutagiLvUg4lGeZuyBmap00D/vc/w5xLzqrvpbGaO4fMF48+399WRiqTQTx58gRWVtpFtvz/34gyktGIiMoM9dB0XXr1kiYZLOrLtrBzqYe59+kjBYK8/yvOuwr7hAnGC0ByyVn1/ehRaWh9UWt5FRQSC1rvS+5xDEAlVNrVSLo8evRInD9/Xpw/f14AEAsWLBDnz58Xt27dEkIIMXnyZPHuu+9qjl+9erWwsrISy5cvF3/88Yc4duyYaN68uWjZsqXsa3K0FBGR4RXVDFZUE9iGDYbtCG2obdw4w/bvMWQ/oIo2Wqzc9LmJjY0VQP7OvuHh4UIIIcLDw0W7du203rNkyRJRv359YWtrKzw9PcWAAQPEn3/+KfuaDDdERKWjqC/SkgYguR2h1X1ujDHKS27/nuxsw/YDqoijxcplnxtjYZ8bIiLTKaq5RU4fIPV6V0DBzWCbNkmPuo5RLy1hrKayhQuB8eOLPk5OP6AFC4B+/fKXu6DPr+uYXr3kN5MBpm8q0+v7u9SjVhnDmhsiorJNTk2C3NFgJakpMuQw91GjDHcuQ9UmGXpeIbn/dsXFmhsdWHNDRGQeDDGCSVdNkYuLtESEIcituTEmuaPFilpgtTi1QMWhz/c3ww0REVVopb2au7c3cP06UKtW2RsxVpQDB4BBg4peGV5OU1lJA065WRWciIjI1Ep7NfdFiwBr66KPW7as6IVR3dz0+GAGIGeB1aQkYMSIgkObet+4ccZdAJXhhoiIqBCGWM1dXWNR1HF9+xomAHl7Gz8kyZ0zyFjYLEVERFQEY85QXNSIMWONFvP2BlavBjp1KvL2yLJ2rVQ7Vlzsc6MDww0REZV1hhoyX9KQ1LOn4ZbXiI0tesZsXRhudGC4ISIic1Dao8XkzisktxZIvU5XcTHc6MBwQ0RE9JwhFliVUwtkzNFSDDdERERUJEPUApUEw40ODDdERESlozSXaNDn+9vKMJckIiKiik49Z5CpcZ4bIiIiMisMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMwKww0RERGZFYYbIiIiMisMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMxKscJNUlIS/vzzT83zU6dOYdy4cVi5cqXBCkZERERUHMUKN/3790dsbCwAICUlBa+//jpOnTqFqVOnYubMmQYtIBEREZE+ihVuLl++jJYtWwIANmzYgIYNG+L48eNYs2YNoqKiDFk+IiIiIr0UK9w8e/YMSqUSAHDgwAH06NEDAFC3bl0kJycbrnREREREeipWuGnQoAG+/PJLHD16FPv370fXrl0BAHfv3oWrq6tBC0hERESkj2KFm88++wxfffUV2rdvj7fffhuBgYEAgO3bt2uaq4iIiIhMQSGEEMV5o0qlQnp6OqpUqaLZd/PmTdjZ2aFatWoGK6Chpaenw8nJCWlpaXB0dDR1cYiIiEgGfb6/i1Vzk5mZiezsbE2wuXXrFhYtWoSEhIQyHWyIiIjI/BUr3PTs2RPff/89ACA1NRWtWrXC/PnzERoaihUrVhi0gERERET6KFa4OXfuHNq0aQMA2LRpE9zd3XHr1i18//33WLJkiUELSERERKSPYoWbJ0+ewMHBAQCwb98+9OrVCxYWFnjllVdw69YtgxaQiIiISB/FCjcvvfQStm7diqSkJOzduxedO3cGANy7d4+ddImIiMikihVupk+fjokTJ8LPzw8tW7ZEUFAQAKkWp2nTpgYtIBEREZE+ij0UPCUlBcnJyQgMDISFhZSRTp06BUdHR9StW9eghTQkDgUnIiIqf0p9KDgAeHh4oGnTprh7965mhfCWLVvqFWyOHDmCkJAQeHl5QaFQYOvWrUW+Jzs7G1OnToWvry+USiX8/PywatWq4n4MIiIiMjPFCje5ubmYOXMmnJyc4OvrC19fXzg7O+OTTz5Bbm6u7PM8fvwYgYGBWLZsmez39OvXDwcPHsS3336LhIQEREdHo06dOsX5GERERGSGrIrzpqlTp+Lbb7/FnDlzEBwcDAA4duwYIiIikJWVhVmzZsk6T7du3dCtWzfZ192zZw8OHz6MGzduwMXFBQDg5+end/mJiIjIfBWr5ua7777DN998g+HDh6Nx48Zo3LgxRowYga+//hpRUVEGLuJz27dvR/PmzTF37lxUr14dtWvXxsSJE5GZmVlq1yQiIqLypVg1Nw8fPiywb03dunXx8OHDEheqMDdu3MCxY8dgY2ODmJgYPHjwACNGjMDff/+N1atXF/ie7OxsZGdna56np6eXWvmIiIjI9IpVcxMYGIgvvvgi3/4vvvgCjRs3LnGhCpObmwuFQoE1a9agZcuW6N69OxYsWIDvvvuu0Nqb2bNnw8nJSbP5+PiUWvmIiIjI9IpVczN37ly88cYbOHDggGaOmxMnTiApKQm7du0yaAHz8vT0RPXq1eHk5KTZV69ePQgh8OeffyIgICDfe6ZMmYIJEyZonqenpzPgEBERmbFi1dy0a9cOv//+O958802kpqYiNTUVvXr1wpUrV/DDDz8YuowawcHBuHv3LjIyMjT7fv/9d1hYWMDb27vA9yiVSjg6OmptREREZL6KPYlfQS5evIiXX34ZKpVK1vEZGRm4fv06AKBp06ZYsGABOnToABcXF9SoUQNTpkzBnTt3NCuQZ2RkoF69enjllVcQGRmJBw8e4P3330e7du3w9ddfy7omJ/EjIiIqf4wyiZ8hnDlzBk2bNtUs2TBhwgQ0bdoU06dPBwAkJyfj9u3bmuPt7e2xf/9+pKamonnz5hgwYABCQkK4EjkRERFpmLTmxhRYc0NERFT+lJuaGyIiIiJD02u0VK9evXS+npqaWpKyEBEREZWYXuEm7xDswl4fOHBgiQpEREREVBJ6hZvCZgEmIiIiKivY54aIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZMWm4OXLkCEJCQuDl5QWFQoGtW7fKfm98fDysrKzQpEmTUisfERERlT8mDTePHz9GYGAgli1bptf7UlNTMXDgQHTs2LGUSkZERETllZUpL96tWzd069ZN7/d98MEH6N+/PywtLfWq7SEiIiLzV+763KxevRo3btzAjBkzZB2fnZ2N9PR0rY2IiIjMV7kKN9euXcPkyZPx448/wspKXqXT7Nmz4eTkpNl8fHxKuZRERERkSuUm3KhUKvTv3x+RkZGoXbu27PdNmTIFaWlpmi0pKakUS0lERESmZtI+N/p49OgRzpw5g/Pnz2PUqFEAgNzcXAghYGVlhX379uG1117L9z6lUgmlUmns4hIREZGJlJtw4+joiEuXLmntW758OQ4dOoRNmzbB39/fRCUjIiKissSk4SYjIwPXr1/XPE9MTMSFCxfg4uKCGjVqYMqUKbhz5w6+//57WFhYoGHDhlrvr1atGmxsbPLtJyIioorLpOHmzJkz6NChg+b5hAkTAADh4eGIiopCcnIybt++bariERERUTmkEEIIUxfCmNLT0+Hk5IS0tDQ4OjqaujhEREQkgz7f3+VmtBQRERGRHAw3REREZFYYboiIiMisMNwQERGRWWG4ISIiIrPCcENERERmheGGiIiIzArDDREREZkVhhsiIiIyKww3REREZFYYboiIiMisMNwQERGRWWG4ISIiIrPCcGNId+8CFWuRdSIiojKH4cZQsrKA4GCgbVvg9GlTl4aIiKjCYrgxlDNngL/+Ao4dA1q2BAYMAG7fNnWpiIiIKhyGG0N59VXg99+B8HBAoQDWrgVq1wamTAHS001dOiIiogqD4caQvL2BqCipFqd9eyA7G5gzB3jpJeDLL4GcHFOXkIiIyOwx3JSGl18GDh0Ctm2Tam/u3weGDwcCA4Fdu9jpmIiIqBQx3JQWhQLo0QO4fBlYuhRwdQV+/RV44w2ga1cgKcnUJSQiIjJLDDelrVIlYNQo4Pp1YOJEwNoa2LcPaNwY2LTJ1KUjIiIyOww3xuLsDMybJ9XktGgBpKYCffsCQ4YAGRmmLh0REZHZYLgxtoAAID4e+O9/paarVaukPjpnzpi6ZERERGaB4cYUKlUCZs2SOh17ewPXrgFBQcBnnwG5uaYuHRERUbnGcGNK7dsDFy8CffpIw8QnTwY6dQL+/NPUJSMiIiq3GG5MzcUF2LAB+OYbwM4OiI2VOhtv2WLqkhEREZVLDDdlgUIhdSw+fx5o1gz45x+gd2+gSxfg1ClTl46IiKhcYbgpS2rXBo4fl5qnrKykIeOtWgE9e0rNV0RERFQkhpuyxtoamD0bSEiQ1qmysAC2bweaNAHCwoDffjN1CYmIiMo0hpuyqmZNaZ2qK1eAt96S9m3YADRoIIWeGzdMWjwiIqKyiuGmrKtbF4iOlpqlevaUhop//z1Qpw7w739LMx8TERGRBsNNedG4MbB1q9TBuEsXaej4ypVSP53u3aUFOTlHDhEREcNNudOiBbBnD3DkiLQApxDA7t3SgpwBAcD8+cDDh6YuJRERkckw3JRXbdpIoeb334Hx46W1q27ckBbnrF4deP99aWg5ERFRBcNwU94FBAALFkizGq9cCQQGAllZwLffSmtWtW4tTQxIRERUQTDcmIvKlYGhQ6XammPHpBFWVlbAiRNA587AmjWmLiEREZFRMNyYG4UCCA6WRlglJQFvvy11Pn7nHWDJElOXjoiIqNQx3JgzDw/gxx+BsWOl52PHAtOmSZ2QiYiIzBTDjbmzsAAWLgQ+/VR6PmuWND+OSmXachEREZUShpuKQKEApkyROhxbWABffw306yd1PCYiIjIzDDcVydChwMaN0vpVW7ZIk/+lp5u6VERERAbFcFPR9OolTQLo4CANEW/fHvjrL1OXioiIyGBMGm6OHDmCkJAQeHl5QaFQYOvWrTqP37JlC15//XW4ubnB0dERQUFB2Lt3r3EKa046dAAOHwaqVZOGjr/6KnD1KjsaExGRWTBpuHn8+DECAwOxbNkyWccfOXIEr7/+Onbt2oWzZ8+iQ4cOCAkJwXnOxKu/pk2B+HjA319afLN+fak2p3Fj4M03pZmOly8H9u6VXn/2zNQlJiIikkUhRNn4c12hUCAmJgahoaF6va9BgwYICwvD9OnTZR2fnp4OJycnpKWlwdHRsRglNTPJydKEf0eP6q65sbCQAtHy5UDLlsYrHxEREfT7/rYyUplKRW5uLh49egQXF5dCj8nOzkZ2drbmeTo70Grz9JSaqLKzgVu3gD/+kNao+uMP7Z8zM4GzZ6XlHCIjgcmTAUtLU5eeiIgon3Idbj7//HNkZGSgX79+hR4ze/ZsREZGGrFU5ZRSCdSuLW0vEkJau+qjj4D166WJAPfuBX74AfD1NX5ZiYiIdCi3o6XWrl2LyMhIbNiwAdWqVSv0uClTpiAtLU2zJSUlGbGUZkKhAHx8pCUdvv9e6ptz9Ki0SGd0tKlLR0REpKVchpt169bh/fffx4YNG9CpUyedxyqVSjg6OmptVEwKBfDuu8CFC0BQEJCWBvTvL+1LSzN16YiIiACUw3ATHR2N9957D9HR0XjjjTdMXZyKqWZN4MgRICJC6mj8449AkybS6CsiIiITM2m4ycjIwIULF3DhwgUAQGJiIi5cuIDbt28DkJqUBg4cqDl+7dq1GDhwIObPn49WrVohJSUFKSkpSGOtgfFZWQEzZkjNU/7+wM2bQNu2wNSpwC+/AE+fmrqERERUQZl0KHhcXBw6dOiQb394eDiioqIwaNAg3Lx5E3FxcQCA9u3b4/Dhw4UeLweHgpeC9HRg9GipP45apUpAvXrSvDmBgc8f3d1NV04iIiq39Pn+LjPz3BgLw00p2rgR+OIL4OLFwvvgVKsGNGoEuLoC9vZA5crPt7zP7e2BFi2koepERFThMdzowHBjBEIAt29LzVMXLz5/vHZNvyUeLCyAbt2A994DQkKkBT+JiKhCYrjRgeHGhJ48AS5fltaxSksDHj8GMjKkR/Wmfv7ggRSK1KpWBQYMAAYPlpq4iIioQmG40YHhphz5/Xdg9Wrgu++kZSLUXn5ZCjlvvw3omJ2aiIjMhz7f3+VuKDhVILVrA7NnS01cO3cCvXtLHZXPnQNGjZL64wwZItXyEBER/T+GGyr7rKyA7t2BTZuAu3eBRYukpqmnT4FVq6QVzdet068/DxERmS2GGypfqlYFxo6VZkk+dgxo2BC4f19qourRQ1oDi4iIKjSGGyqfFAogOFhaqTwyUmqu2rFDqsX58ksgN9fUJSQiIhNhuKHyzdoamD4dOH8eeOUV4NEjYPhwoEMHqUMyERFVOAw3ZB4aNJCaqRYtAuzspLWvGjcGPvsMyMkxdemIiMiIOBSczE9iIvDvfwP790vPa9WSho/XrCn9XLOmtPn4SJ2ViYiozNPn+5v/Zyfz4+8P7N0rzY8zfjzwxx/S9iIrK8DXVwo69epJ62O99JLxy0tERAbFmhsybw8fSiuX37ihvSUmAtnZ2sdaWwMffgj897/S2lZERFRmcIZiHRhuCIA0mio5+XnYWbsW2LdPes3LC5g7F+jfXxqVRUREJscZiomKYmEBVK8OtGkDhIcDe/YA27ZJTVR37wLvvCO9du6cqUtKRER6YrghAqQamh49gCtXgFmzpBFX8fFA8+ZS5+T7901dQiIikonhhigvGxupz01CgjTrsRDAypXSOldLlkgzIHOCQCKiMo19boh0OXoUGDNGWu5Bzdoa8POTRmX5+0tNWXl/rlLFVKUlIjJb7FCsA8MN6U2lAr75BliwQBpSrlLpPr5JE2DECKlDcuXKRikiEZG5Y7jRgeGGSiQnB0hKkoaSqzf10PLEROCvv54f6+gIDBokLQdRt67JikxEZA4YbnRguKFS9eCBNHngihXaEwe+9ppUm9Ojh7TIJxER6YVDwYlMpWpVaSLA33+Xhpf36CENOz90COjTR+qrExkJXL8udVYmIiKDY80NUWm7dUsacfX119pDyh0dpcU9mzQBAgOlxwYNAFtbU5WUiKjMYrOUDgw3ZDLZ2cCWLcBXXwEnTgBPn+Y/xsJC6p8TGAg0bCjV9NSoIW1eXlzok4gqLIYbHRhuqEx49gz47TdpiPnFi88fHzwo/D2WltKsyr6+UthRL/rZsaMUgoiIzBjDjQ4MN1RmCSEt/aAOO7/9Jo3MunVLeszJKfy99esD3bsDb7wBBAez0zIRmR2GGx0YbqhcUqmAlBTg9m1pu3VLevzlF+D4ce25dxwdgc6dpaDTtSvg4WG6chMRGQjDjQ4MN2R2/vlHWtF81y5g9+7862A1bw68+qr02KIF8NJLUt8eIqJyhOFGB4YbMmu5ucDp01LQ2bkTOHs2/zFOTkCzZlLQUQeeGjWkxUOJiMoohhsdGG6oQklJAQ4cAE6dkkLPhQtAVlb+49zcgFatgNatpa1FC2lldCKiMoLhRgeGG6rQnj0DrlwBzpyRws6ZM1K/nRc7K1tZSfPuqMNO69aAj49JikxEBDDc6MRwQ/SCrCxphNbJk1Ln5Ph44M6d/Md5e0vNWXXqALVrAwEB0qO7O5u0iKjUMdzowHBDJENSkhR01Nv584Wvhu7gIIUc9ebtLe0XovDN2lqajTkwkCunE5EsDDc6MNwQFcPjx1IT1uXL0rpZ6u3mTakTc3EpFFJN0MsvA02bPn+sUsVgRSci88BwowPDDZEBZWdLq5/nDTwpKVJo0bU9fiw1hSUnF3xeX18p5NStC9SqJW01a0q1QpaWxv2MakIAf/8NuLqyGY7IBPT5/uZCNURUfEqlNDty/frFe39KitTkde7c88fERGmSwlu38h9vbS0tNaEOPLVqSYuPNmsmDXEvDZmZwA8/AIsXA7/+Cri4AC1bSqPLWraUtqpVS+faRFQsrLkhorLln3+er7V1/bpUM/THH1IT2LNnhb+vbt3nYaNlSyn0KJXFL8fdu8Dy5cCXX0o1NrrUrPk87KgfTVXDRGSm2CylA8MNUTmlUkkdndVh548/pPBz7pwUfF5kbS0NZ2/RQmriUnd4rlZNd7PS2bPAokXA+vXPw5SfHzBmDPDOO1KN0s8/S9upU0BCQv5z1K0LREYCffpwNmgiA2G40YHhhsgM3b8vzdtz6tTzrbDalhdHd6mHtP/5J7BwIXD06PNjX30VGD8e6NFDmvunIP/8I3W2VoedI0eAtDTptcaNpZDTsyf76RCVEMONDgw3RBWAEFLfHXXQ+fXX56O7ivpfnpUVEBYGjBsnLU+hr7Q0qeZnwQIgPV3a16wZMHMm0K0bQw5RMTHc6MBwQ1SBZWUBN24A165pj/D6/Xfp9cGDgREjgOrVS36thw+Bzz8HliyRRocBQFCQFHI6djR9yBFCKteDB9KWmirNQl2rVuG1VMYmRMnvU2YmsHKl1FTYpYthykUmwXCjA8MNERnV/fvAZ58By5Y9X9erbVugQwepZufRI+mxoJ+FkJrRHBwAR8eCf7a1leYaUqmeb3mf5+YCT59KzXTqIKP+OTs7f3nVI+AaNtTefHyMF8gSE4GpU6XFX0eMAD7+uHhrnZ05AwwcCFy9Kj3/z3+AWbPKTngzluxs6XehnK8XV27CzZEjRzBv3jycPXsWycnJiImJQWhoqM73xMXFYcKECbhy5Qp8fHwwbdo0DBo0SPY1GW6IyCSSk4HZs4GvvpLCRlmhVEoLpzo6Ss12T54UfJyjozSrtK+vNNePq6s0BL6gn+3tixeE/v5bCh/LlmnfI39/aV+3bvLO8+wZ8L//SedSqaRpAtT9oF57DVi3TvrM5uzmTWD3bmk7dEiqwRo/XuoDVk5nBS834Wb37t2Ij49Hs2bN0KtXryLDTWJiIho2bIgPPvgA77//Pg4ePIhx48Zh586d6CKzupHhhohMKilJGmKemioFBnUtjPrnvPsAqQYn76au1VH/nJUlDTu3sJAeX/zZ0lKqqVAHkLybq6v017w6iOTmSrUmly8/3y5dkkaEvbi4qi5eXkCvXtJosVdfLXpYfGam1Hw3e/bzEPL660DfvsAnn0j3DAD69ZP6M3l6Fn6uK1ek2ppz556/Z/ly4MABYMgQqSnOxwfYtEkasm8KKpU00q9GDanmzRCys6XO8OpAo66tepG/vxSwX3/dMNc1Ir2+v0UZAUDExMToPOY///mPaNCggda+sLAw0aVLF9nXSUtLEwBEWlpacYpJRFTxZGcLcemSENHRQixcKMTUqUJ88IEQffsK0aGDEI0bC1G9uhBKZf6VxKpVk449cECIZ8+0z5uTI0RUlBDe3s+PDwwUYu/e58c8eiTEhAlCWFhIrzs6CrF8uRAqVf5zzZv3vAwuLkKsW6d9zOXLQtSuLb1ubS3EypXyPn9GhhDffitEUJD0ecLChFizRoiHD+Xfw5wcIWJjhRgxQggPj+dlnDhRiOvX5Z8nrwcPhPj6ayFCQoSoXFn7vltaCvHqq0LMmiXEuXNC7NghhI/P89cHDpTeX47o8/1drsJNmzZtxNixY7X2rVq1Sjg6Osq+DsMNEVEpyc2VwsjOnUK8954QVapof+G6ugrx/vtC7NkjxK5dUihSv+bjI8T33+cPLWrnzgnRosXz41u1EuLCBem169elL3L1a927C3H3bsHnSU0VIjT0+bFDhgiRmVnwsefPCzF8uBSoCloC1tJSiPbthViwoOCA8uyZFOo++EAKRS++V/2zQiFEt25C/PSTFIJ0efhQiFWrhOjSRfscgBSaBg0SYsOGgoNXeroQo0dL1wOEcHOTQlpuru5rlhFmG24CAgLEp59+qrVv586dAoB48uRJge/JysoSaWlpmi0pKYnhhojIGJ4+lWphhg4VomrVggOCs7NU41JYwMgrJ0eIpUuFcHB4HhD6939ea2FvL9VkFPVlrVIJ8emnz2uDmjcX4uZN6bX0dKlGp3lz7XLWqiXEnDlCxMUJ8d//CtGwYf7PUq+eEJMmSeGioM/s4iLE4MFSsMvMlMJMt27ax/j5Sde5f/95edPShPjhByH+9S8hKlXSPr5JEyE++UQKf4UFwxedOCFEgwbPz9Gt2/PPX4Yx3OQxY8YMASDfxnBDRGREL9ZiKJVCfPihEH//rf+5/vxTiD59tL/k27UT4sYN/c6zb59Um6SuVQoPlwKS+pyVKklNUAcPFhwc/vhDiEWLhHjtNSGsrAoOb66uUtDZu1cKewW5fl26F3lrupRKId55R6plerG5r2FDIWbOFCIhQd8791x2thSKrK2lc1auLNVA/f67EFlZxT9vKdIn3JSZoeAKhaLIDsVt27bFyy+/jEWLFmn2rV69GuPGjUOauhPaC7Kzs5GdZ7hjeno6fHx82KGYiMhUVCrpsaTrb+3cKc0qHRICjB5dvKUubt0CeveWlt1Qq10bGDZM6pgsd1RVaiqwZw+wfTvwyy9SR+q+fYF27eQPPc/MlEZyLVumXR4AqFNHmlyyXz9p1Jqh/PYbMHQocOzY830KhdRp289Pe/P1lTpBq1QFT1+Qd6tcWfq3MaByM1oqLznhZtKkSdi1axcuXbqk2de/f388fPgQe/bskXUdjpYiIiItWVnSXDoPHgCDBknzEJlykkUhpOVEfvxRGjnXrx/QqFHplSk3V5rocNkyaZLLwqYD0IeHhzT9gQGVm3CTkZGB69evAwCaNm2KBQsWoEOHDnBxcUGNGjUwZcoU3LlzB99//z2A50PBR44cicGDB+PQoUMYM2YMh4ITEREZghBSyLt5U9pu3Xr+882b0rB8a+v80xa8+NzVVZqA0YD0+f426TSNZ86cQYcOHTTPJ0yYAAAIDw9HVFQUkpOTcfv2bc3r/v7+2LlzJ8aPH4/FixfD29sb33zzjexgQ0RERDooFFJTnJsb0KKFqUtTbGWmWcpYWHNDRERU/ujz/V2M3ldEREREZRfDDREREZkVhhsiIiIyKww3REREZFYYboiIiMisMNwQERGRWWG4ISIiIrPCcENERERmheGGiIiIzArDDREREZkVhhsiIiIyKww3REREZFYYboiIiMisWJm6AMamXgQ9PT3dxCUhIiIiudTf2+rvcV0qXLh59OgRAMDHx8fEJSEiIiJ9PXr0CE5OTjqPUQg5EciM5Obm4u7du3BwcIBCoZD9vvT0dPj4+CApKQmOjo6lWEICeL+NjffbuHi/jYv327hK634LIfDo0SN4eXnBwkJ3r5oKV3NjYWEBb2/vYr/f0dGR/3EYEe+3cfF+Gxfvt3HxfhtXadzvomps1NihmIiIiMwKww0RERGZFYYbmZRKJWbMmAGlUmnqolQIvN/GxfttXLzfxsX7bVxl4X5XuA7FREREZN5Yc0NERERmheGGiIiIzArDDREREZkVhhsiIiIyKww3Mixbtgx+fn6wsbFBq1atcOrUKVMXyWwcOXIEISEh8PLygkKhwNatW7VeF0Jg+vTp8PT0hK2tLTp16oRr166ZprDl3OzZs9GiRQs4ODigWrVqCA0NRUJCgtYxWVlZGDlyJFxdXWFvb4/evXvjr7/+MlGJy7cVK1agcePGmonMgoKCsHv3bs3rvNela86cOVAoFBg3bpxmH++54UREREChUGhtdevW1bxu6nvNcFOE9evXY8KECZgxYwbOnTuHwMBAdOnSBffu3TN10czC48ePERgYiGXLlhX4+ty5c7FkyRJ8+eWX+Pnnn1G5cmV06dIFWVlZRi5p+Xf48GGMHDkSJ0+exP79+/Hs2TN07twZjx8/1hwzfvx4/PTTT9i4cSMOHz6Mu3fvolevXiYsdfnl7e2NOXPm4OzZszhz5gxee+019OzZE1euXAHAe12aTp8+ja+++gqNGzfW2s97blgNGjRAcnKyZjt27JjmNZPfa0E6tWzZUowcOVLzXKVSCS8vLzF79mwTlso8ARAxMTGa57m5ucLDw0PMmzdPsy81NVUolUoRHR1tghKal3v37gkA4vDhw0II6d5WqlRJbNy4UXPM1atXBQBx4sQJUxXTrFSpUkV88803vNel6NGjRyIgIEDs379ftGvXTowdO1YIwd9vQ5sxY4YIDAws8LWycK9Zc6PD06dPcfbsWXTq1Emzz8LCAp06dcKJEydMWLKKITExESkpKVr338nJCa1ateL9N4C0tDQAgIuLCwDg7NmzePbsmdb9rlu3LmrUqMH7XUIqlQrr1q3D48ePERQUxHtdikaOHIk33nhD694C/P0uDdeuXYOXlxdq1qyJAQMG4Pbt2wDKxr2ucAtn6uPBgwdQqVRwd3fX2u/u7o7ffvvNRKWqOFJSUgCgwPuvfo2KJzc3F+PGjUNwcDAaNmwIQLrf1tbWcHZ21jqW97v4Ll26hKCgIGRlZcHe3h4xMTGoX78+Lly4wHtdCtatW4dz587h9OnT+V7j77dhtWrVClFRUahTpw6Sk5MRGRmJNm3a4PLly2XiXjPcEFVAI0eOxOXLl7XayMnw6tSpgwsXLiAtLQ2bNm1CeHg4Dh8+bOpimaWkpCSMHTsW+/fvh42NjamLY/a6deum+blx48Zo1aoVfH19sWHDBtja2pqwZBI2S+lQtWpVWFpa5uvh/ddff8HDw8NEpao41PeY99+wRo0ahR07diA2Nhbe3t6a/R4eHnj69ClSU1O1juf9Lj5ra2u89NJLaNasGWbPno3AwEAsXryY97oUnD17Fvfu3cPLL78MKysrWFlZ4fDhw1iyZAmsrKzg7u7Oe16KnJ2dUbt2bVy/fr1M/H4z3OhgbW2NZs2a4eDBg5p9ubm5OHjwIIKCgkxYsorB398fHh4eWvc/PT0dP//8M+9/MQghMGrUKMTExODQoUPw9/fXer1Zs2aoVKmS1v1OSEjA7du3eb8NJDc3F9nZ2bzXpaBjx464dOkSLly4oNmaN2+OAQMGaH7mPS89GRkZ+OOPP+Dp6Vk2fr+N0m25HFu3bp1QKpUiKipK/Prrr2LYsGHC2dlZpKSkmLpoZuHRo0fi/Pnz4vz58wKAWLBggTh//ry4deuWEEKIOXPmCGdnZ7Ft2zbxyy+/iJ49ewp/f3+RmZlp4pKXP8OHDxdOTk4iLi5OJCcna7YnT55ojvnggw9EjRo1xKFDh8SZM2dEUFCQCAoKMmGpy6/JkyeLw4cPi8TERPHLL7+IyZMnC4VCIfbt2yeE4L02hryjpYTgPTekDz/8UMTFxYnExEQRHx8vOnXqJKpWrSru3bsnhDD9vWa4kWHp0qWiRo0awtraWrRs2VKcPHnS1EUyG7GxsQJAvi08PFwIIQ0H//jjj4W7u7tQKpWiY8eOIiEhwbSFLqcKus8AxOrVqzXHZGZmihEjRogqVaoIOzs78eabb4rk5GTTFbocGzx4sPD19RXW1tbCzc1NdOzYURNshOC9NoYXww3vueGEhYUJT09PYW1tLapXry7CwsLE9evXNa+b+l4rhBDCOHVERERERKWPfW6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMwKww0RERGZFYYbIiIiMisMN0RUISkUCmzdutXUxSCiUsBwQ0RGN2jQICgUinxb165dTV00IjIDVqYuABFVTF27dsXq1au19imVShOVhojMCWtuiMgklEolPDw8tLYqVaoAkJqMVqxYgW7dusHW1hY1a9bEpk2btN5/6dIlvPbaa7C1tYWrqyuGDRuGjIwMrWNWrVqFBg0aQKlUwtPTE6NGjdJ6/cGDB3jzzTdhZ2eHgIAAbN++XfPaP//8gwEDBsDNzQ22trYICAjIF8aIqGxiuCGiMunjjz9G7969cfHiRQwYMABvvfUWrl69CgB4/PgxunTpgipVquD06dPYuHEjDhw4oBVeVqxYgZEjR2LYsGG4dOkStm/fjpdeeknrGpGRkejXrx9++eUXdO/eHQMGDMDDhw811//111+xe/duXL16FStWrEDVqlWNdwOIqPiMtkQnEdH/Cw8PF5aWlqJy5cpa26xZs4QQ0grmH3zwgdZ7WrVqJYYPHy6EEGLlypWiSpUqIiMjQ/P6zp07hYWFhUhJSRFCCOHl5SWmTp1aaBkAiGnTpmmeZ2RkCABi9+7dQgghQkJCxHvvvWeYD0xERsU+N0RkEh06dMCKFSu09rm4uGh+DgoK0notKCgIFy5cAABcvXoVgYGBqFy5sub14OBg5ObmIiEhAQqFAnfv3kXHjh11lqFx48aanytXrgxHR0fcu3cPADB8+HD07t0b586dQ+fOnREaGorWrVsX67MSkXEx3BCRSVSuXDlfM5Gh2NrayjquUqVKWs8VCgVyc3MBAN26dcOtW7ewa9cu7N+/Hx07dsTIkSPx+eefG7y8RGRY7HNDRGXSyZMn8z2vV68eAKBevXq4ePEiHj9+rHk9Pj4eFhYWqFOnDhwcHODn54eDBw+WqAxubm4IDw/Hjz/+iEWLFmHlypUlOh8RGQdrbojIJLKzs5GSkqK1z8rKStNpd+PGjWjevDleffVVrFmzBqdOncK3334LABgwYABmzJiB8PBwRERE4P79+xg9ejTeffdduLu7AwAiIiLwwQcfoFq1aujWrRsePXqE+Ph4jB49Wlb5pk+fjmbNmqFBgwbIzs7Gjh07NOGKiMo2hhsiMok9e/bA09NTa1+dOnXw22+/AZBGMq1btw4jRoyAp6cnoqOjUb9+fQCAnZ0d9u7di7Fjx6JFixaws7ND7969sWDBAs25wsPDkZWVhYULF2LixImoWrUq+vTpI7t81tbWmDJlCm7evAlbW1u0adMG69atM8AnJ6LSphBCCFMXgogoL4VCgZiYGISGhpq6KERUDrHPDREREZkVhhsiIiIyK+xzQ0RlDlvLiagkWHNDREREZoXhhoiIiMwKww0RERGZFYYbIiIiMisMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZuX/AJNSv7x9zw0eAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"!pip freeze","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:45:28.052599Z","iopub.execute_input":"2024-04-19T10:45:28.052910Z","iopub.status.idle":"2024-04-19T10:45:31.272907Z","shell.execute_reply.started":"2024-04-19T10:45:28.052885Z","shell.execute_reply":"2024-04-19T10:45:31.271735Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"absl-py==1.4.0\naccelerate==0.27.2\naccess==1.1.9\naffine==2.4.0\naiobotocore==2.11.2\naiofiles==22.1.0\naiohttp @ file:///home/conda/feedstock_root/build_artifacts/aiohttp_1701099469104/work\naiohttp-cors==0.7.0\naioitertools==0.11.0\naiorwlock==1.3.0\naiosignal @ file:///home/conda/feedstock_root/build_artifacts/aiosignal_1667935791922/work\naiosqlite==0.19.0\nalbumentations==1.4.0\nalembic==1.13.1\naltair==5.2.0\nannotated-types @ file:///home/conda/feedstock_root/build_artifacts/annotated-types_1696634205638/work\nannoy==1.17.3\nanyio @ file:///home/conda/feedstock_root/build_artifacts/anyio_1702909220329/work\napache-beam==2.46.0\naplus==0.11.0\nappdirs==1.4.4\narchspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\nargon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1692818318753/work\nargon2-cffi-bindings @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi-bindings_1695386546427/work\narray-record==0.5.0\narrow @ file:///home/conda/feedstock_root/build_artifacts/arrow_1696128962909/work\narviz==0.17.0\nastroid==3.0.3\nastropy==6.0.0\nastropy-iers-data==0.2024.2.19.0.28.47\nasttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work\nastunparse==1.6.3\nasync-lru==2.0.4\nasync-timeout @ file:///home/conda/feedstock_root/build_artifacts/async-timeout_1691763562544/work\nattrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1704011227531/work\naudioread==3.0.1\nautopep8==2.0.4\nBabel==2.14.0\nbackoff==2.2.1\nbayesian-optimization==1.4.3\nbayespy==0.5.28\nbeatrix_jupyterlab @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-gpu_1704941576253/work/packages/beatrix_jupyterlab-2023.128.151533.tar.gz#sha256=8c6941d08ce18f5b9ea7719574d611c18163074ff8254e0734342014eb064a48\nbeautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1680888073205/work\nbidict==0.23.1\nbiopython==1.83\nblake3==0.2.1\nbleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1696630167146/work\nblessed==1.20.0\nblinker==1.7.0\nblis @ file:///home/conda/feedstock_root/build_artifacts/cython-blis_1696148805003/work\nblosc2==2.5.1\nbokeh @ file:///home/conda/feedstock_root/build_artifacts/bokeh_1706215790147/work\nboltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\nBoruta==0.3\nboto3==1.26.100\nbotocore==1.34.34\nbq_helper==0.4.1\nbqplot==0.12.43\nbranca==0.7.1\nbrewer2mpl==1.4.1\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work\nbrotlipy==0.7.0\ncached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\ncachetools==4.2.4\nCartopy @ file:///home/conda/feedstock_root/build_artifacts/cartopy_1698172724393/work\ncatalogue @ file:///home/conda/feedstock_root/build_artifacts/catalogue_1695626339626/work\ncatalyst @ git+https://github.com/Philmod/catalyst.git@9420384a98c4b9d3b17b959e66f845b98457b545\ncatboost==1.2.2\ncategory-encoders==2.6.3\ncertifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1707022139797/work/certifi\ncesium==0.12.1\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\nchex==0.1.85\ncleverhans==4.0.0\nclick @ file:///home/conda/feedstock_root/build_artifacts/click_1692311806742/work\nclick-plugins==1.1.1\ncligj==0.7.2\ncloud-tpu-client==0.10\ncloud-tpu-profiler==2.4.0\ncloudpathlib @ file:///home/conda/feedstock_root/build_artifacts/cloudpathlib-meta_1697837790453/work\ncloudpickle==2.2.1\ncmdstanpy==1.2.1\ncmudict==1.0.18\ncolorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\ncolorcet==3.0.1\ncolorful==0.5.6\ncolorlog==6.8.2\ncolorlover==0.3.0\ncomm @ file:///home/conda/feedstock_root/build_artifacts/comm_1704278392174/work\nconda @ file:///home/conda/feedstock_root/build_artifacts/conda_1694556045812/work\nconda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1690880668143/work/src\nconda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\nconda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\nconfection @ file:///home/conda/feedstock_root/build_artifacts/confection_1701179074719/work\ncontextily==1.5.0\ncontourpy @ file:///home/conda/feedstock_root/build_artifacts/contourpy_1699041363598/work\nconvertdate==2.4.0\ncrcmod==1.7\ncryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1701563205069/work\ncuda-python @ file:///opt/conda/conda-bld/cuda-python_1696638333144/work\ncudf @ file:///opt/conda/conda-bld/work/python/cudf\ncufflinks==0.17.3\ncuml @ file:///opt/conda/conda-bld/work/python\ncupy @ file:///home/conda/feedstock_root/build_artifacts/cupy-split_1707093121318/work\nCVXcanon==0.1.2\ncycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1696677705766/work\ncymem @ file:///home/conda/feedstock_root/build_artifacts/cymem_1695443485440/work\ncysignals==1.11.4\nCython==3.0.8\ncytoolz @ file:///home/conda/feedstock_root/build_artifacts/cytoolz_1706897049115/work\ndaal==2024.1.0\ndaal4py==2024.1.0\ndacite==1.8.1\ndask==2024.2.0\ndask-cuda @ file:///opt/conda/conda-bld/work\ndask-cudf @ file:///opt/conda/conda-bld/work/python/dask_cudf\ndataclasses-json==0.6.4\ndataproc_jupyter_plugin==0.1.66\ndatasets==2.1.0\ndatashader==0.16.0\ndatatile==1.0.3\ndb-dtypes==1.2.0\ndeap==1.4.1\ndebugpy @ file:///home/conda/feedstock_root/build_artifacts/debugpy_1695534290310/work\ndecorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\ndeepdiff==6.7.1\ndefusedxml @ file:///home/conda/feedstock_root/build_artifacts/defusedxml_1615232257335/work\nDelorean==1.0.0\nDeprecated==1.2.14\ndeprecation==2.1.0\ndescartes==1.1.0\ndill==0.3.8\ndipy==1.8.0\ndistlib==0.3.8\ndistributed @ file:///home/conda/feedstock_root/build_artifacts/distributed_1689891044039/work\ndistro @ file:///home/conda/feedstock_root/build_artifacts/distro_1704321475663/work\ndm-tree==0.1.8\ndocker==7.0.0\ndocker-pycreds==0.4.0\ndocopt==0.6.2\ndocstring-parser==0.15\ndocstring-to-markdown==0.15\ndocutils==0.20.1\nearthengine-api==0.1.391\neasydict==1.12\neasyocr==1.7.1\necos==2.0.13\neli5==0.13.0\nemoji==2.10.1\nen-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl#sha256=ab70aeb6172cde82508f7739f35ebc9918a3d07debeed637403c8f794ba3d3dc\nen-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\nentrypoints @ file:///home/conda/feedstock_root/build_artifacts/entrypoints_1643888246732/work\nephem==4.1.5\nesda==2.5.1\nessentia==2.1b6.dev1110\net-xmlfile==1.1.0\netils==1.6.0\nexceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1704921103267/work\nexecuting @ file:///home/conda/feedstock_root/build_artifacts/executing_1698579936712/work\nexplainable-ai-sdk==1.3.3\nFarama-Notifications==0.0.4\nfastai==2.7.14\nfastapi==0.108.0\nfastavro==1.9.3\nfastcore==1.5.29\nfastdownload==0.0.7\nfasteners==0.19\nfastjsonschema @ file:///home/conda/feedstock_root/build_artifacts/python-fastjsonschema_1703780968325/work/dist\nfastprogress==1.0.3\nfastrlock @ file:///home/conda/feedstock_root/build_artifacts/fastrlock_1702696298817/work\nfasttext==0.9.2\nfbpca==1.0\nfeather-format==0.4.1\nfeaturetools==1.29.0\nfilelock==3.13.1\nfiona==1.9.5\nfitter==1.7.0\nflake8==7.0.0\nflashtext==2.7\nFlask==3.0.2\nflatbuffers==23.5.26\nflax==0.8.1\nfolium==0.15.1\nfonttools==4.47.0\nfqdn @ file:///home/conda/feedstock_root/build_artifacts/fqdn_1638810296540/work/dist\nfrozendict==2.4.0\nfrozenlist @ file:///home/conda/feedstock_root/build_artifacts/frozenlist_1702645481127/work\nfsspec @ file:///home/conda/feedstock_root/build_artifacts/fsspec_1707102468451/work\nfuncy==2.0\nfury==0.9.0\nfuture==1.0.0\nfuzzywuzzy==0.18.0\ngast==0.5.4\ngatspy==0.3\ngcsfs==2023.12.2.post1\ngensim==4.3.2\ngeographiclib==2.0\nGeohash==1.0\ngeojson==3.1.0\ngeopandas==0.14.3\ngeoplot==0.5.1\ngeopy==2.4.1\ngeoviews==1.11.1\nggplot @ https://github.com/hbasria/ggpy/archive/0.11.5.zip#sha256=7df947ba3fd86d3757686afec264785ad8df38dc50ffb2d2d31064fb355f69b1\ngiddy==2.3.5\ngitdb==4.0.11\nGitPython==3.1.41\ngoogle-ai-generativelanguage==0.4.0\ngoogle-api-core==2.11.1\ngoogle-api-python-client==2.118.0\ngoogle-apitools==0.5.31\ngoogle-auth==2.26.1\ngoogle-auth-httplib2==0.1.1\ngoogle-auth-oauthlib==1.2.0\ngoogle-cloud-aiplatform==0.6.0a1\ngoogle-cloud-artifact-registry==1.10.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==2.34.4\ngoogle-cloud-bigtable==1.7.3\ngoogle-cloud-core==2.4.1\ngoogle-cloud-datastore==2.19.0\ngoogle-cloud-dlp==3.14.0\ngoogle-cloud-jupyter-config==0.0.5\ngoogle-cloud-language==2.13.1\ngoogle-cloud-monitoring==2.18.0\ngoogle-cloud-pubsub==2.19.0\ngoogle-cloud-pubsublite==1.9.0\ngoogle-cloud-recommendations-ai==0.7.1\ngoogle-cloud-resource-manager==1.11.0\ngoogle-cloud-spanner==3.40.1\ngoogle-cloud-storage==1.44.0\ngoogle-cloud-translate==3.12.1\ngoogle-cloud-videointelligence==2.13.1\ngoogle-cloud-vision==2.8.0\ngoogle-crc32c==1.5.0\ngoogle-generativeai==0.3.2\ngoogle-pasta==0.2.0\ngoogle-resumable-media==2.7.0\ngoogleapis-common-protos==1.62.0\ngplearn==0.4.2\ngpustat==1.0.0\ngpxpy==1.6.2\ngraphviz==0.20.1\ngreenlet==3.0.3\ngrpc-google-iam-v1==0.12.7\ngrpcio @ file:///home/conda/feedstock_root/build_artifacts/grpc-split_1677499296072/work\ngrpcio-status @ file:///home/conda/feedstock_root/build_artifacts/grpcio-status_1662108958711/work\ngviz-api==1.10.0\ngym==0.26.2\ngym-notices==0.0.8\ngymnasium==0.29.0\nh11==0.14.0\nh2o==3.44.0.3\nh5netcdf==1.3.0\nh5py==3.10.0\nhaversine==2.8.1\nhdfs==2.7.3\nhep-ml==0.7.2\nhijri-converter==2.3.1\nhmmlearn==0.3.0\nholidays==0.24\nholoviews==1.18.3\nhpsklearn==0.1.0\nhtml5lib==1.1\nhtmlmin==0.1.12\nhttpcore==1.0.4\nhttplib2==0.21.0\nhttptools==0.6.1\nhttpx==0.27.0\nhuggingface-hub==0.20.3\nhumanize==4.9.0\nhunspell==0.5.5\nhusl==4.0.3\nhydra-slayer==0.5.0\nhyperopt==0.2.7\nhypertools==0.8.0\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1701026962277/work\nigraph==0.11.4\nimagecodecs==2024.1.1\nImageHash==4.3.1\nimageio==2.33.1\nimbalanced-learn==0.12.0\nimgaug==0.4.0\nimportlib-metadata==6.11.0\nimportlib-resources @ file:///home/conda/feedstock_root/build_artifacts/importlib_resources_1699364556997/work\ninequality==1.0.1\niniconfig==2.0.0\nipydatawidgets==4.3.5\nipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1703631723894/work\nipyleaflet==0.18.2\nipympl==0.7.0\nipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1704718870316/work\nipython-genutils==0.2.0\nipython-sql==0.5.0\nipyvolume==0.6.3\nipyvue==1.10.1\nipyvuetify==1.8.10\nipywebrtc==0.6.0\nipywidgets==7.7.1\nisoduration @ file:///home/conda/feedstock_root/build_artifacts/isoduration_1638811571363/work/dist\nisort==5.13.2\nisoweek==1.3.3\nitsdangerous==2.1.2\nJanome==0.5.0\njaraco.classes==3.3.0\njax==0.4.23\njax-jumpy==1.0.0\njaxlib @ file:///tmp/jax/jaxlib-0.4.23.dev20240116-cp310-cp310-manylinux2014_x86_64.whl#sha256=2adde6b0fff8a64af0b461e617ac514b80d8ee4aa52f1b1cf9a9139f427be8ba\njedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work\njeepney==0.8.0\njieba==0.42.1\nJinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1654302431367/work\njmespath==1.0.1\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1691577114857/work\njson5==0.9.14\njsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\njsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\njsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema-meta_1700159890288/work\njsonschema-specifications @ file:///tmp/tmpkv1z7p57/src\njupyter-console==6.6.3\njupyter-events @ file:///home/conda/feedstock_root/build_artifacts/jupyter_events_1699285872613/work\njupyter-http-over-ws==0.0.8\njupyter-lsp==1.5.1\njupyter-server-mathjax==0.2.6\njupyter-ydoc==0.2.5\njupyter_client==7.4.9\njupyter_core @ file:///home/conda/feedstock_root/build_artifacts/jupyter_core_1704727030956/work\njupyter_server==2.12.5\njupyter_server_fileid==0.9.1\njupyter_server_proxy==4.1.0\njupyter_server_terminals @ file:///home/conda/feedstock_root/build_artifacts/jupyter_server_terminals_1703611053195/work\njupyter_server_ydoc==0.8.0\njupyterlab==4.1.2\njupyterlab-lsp==5.0.3\njupyterlab-widgets==3.0.9\njupyterlab_git==0.44.0\njupyterlab_pygments @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_pygments_1700744013163/work\njupyterlab_server==2.25.2\njupytext==1.16.0\nkaggle==1.6.6\nkaggle-environments==1.14.3\nkagglehub==0.1.9\nkeras==3.0.5\nkeras-cv==0.8.2\nkeras-nlp==0.8.1\nkeras-tuner==1.4.6\nkernels-mixer==0.0.7\nkeyring==24.3.0\nkeyrings.google-artifactregistry-auth==1.1.2\nkfp==2.5.0\nkfp-pipeline-spec==0.2.2\nkfp-server-api==2.0.5\nkiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1695379902431/work\nkmapper==2.0.1\nkmodes==0.12.2\nkorean-lunar-calendar==0.3.1\nkornia==0.7.1\nkt-legacy==1.0.5\nkubernetes==26.1.0\nlangcodes @ file:///home/conda/feedstock_root/build_artifacts/langcodes_1636741340529/work\nlangid==1.1.6\nlazy_loader==0.3\nlearntools @ git+https://github.com/Kaggle/learntools@183cdad0530e7c898cd4658a63b579c54e91f056\nleven==1.0.4\nLevenshtein==0.25.0\nlibclang==16.0.6\nlibmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1692866066721/work/libmambapy\nlibpysal==4.9.2\nlibrosa==0.10.1\nlightgbm @ file:///tmp/lightgbm/lightgbm-4.2.0-py3-none-manylinux_2_31_x86_64.whl#sha256=26ed21477c12bb26edc4d6d51336cd43d5a8f7daf55ebbe27b0faf50ce96db23\nlightning-utilities==0.10.1\nlime==0.2.0.1\nline-profiler==4.1.2\nlinkify-it-py==2.0.3\nllvmlite==0.41.1\nlml==0.1.0\nlocket @ file:///home/conda/feedstock_root/build_artifacts/locket_1650660393415/work\nloguru==0.7.2\nLunarCalendar==0.0.9\nlxml==5.1.0\nlz4 @ file:///home/conda/feedstock_root/build_artifacts/lz4_1704831084136/work\nMako==1.3.2\nmamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1692866066721/work/mamba\nmapclassify==2.6.1\nmarisa-trie==1.1.0\nMarkdown==3.5.2\nmarkdown-it-py @ file:///home/conda/feedstock_root/build_artifacts/markdown-it-py_1686175045316/work\nmarkovify==0.9.4\nMarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1695367434228/work\nmarshmallow==3.20.2\nmatplotlib==3.7.5\nmatplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work\nmatplotlib-venn==0.11.10\nmccabe==0.7.0\nmdit-py-plugins==0.4.0\nmdurl @ file:///home/conda/feedstock_root/build_artifacts/mdurl_1704317613764/work\nmemory-profiler==0.61.0\nmenuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\nmercantile==1.2.1\nmgwr==2.2.1\nmissingno==0.5.2\nmistune==0.8.4\nmizani==0.11.0\nml-dtypes==0.2.0\nmlcrate==0.2.0\nmlens==0.2.3\nmlxtend==0.23.1\nmmh3==4.1.0\nmne==1.6.1\nmnist==0.2.2\nmock==5.1.0\nmomepy==0.7.0\nmore-itertools==10.2.0\nmpld3==0.5.10\nmpmath==1.3.0\nmsgpack @ file:///home/conda/feedstock_root/build_artifacts/msgpack-python_1700926504817/work\nmsgpack-numpy==0.4.8\nmultidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1696716075096/work\nmultimethod==1.10\nmultipledispatch==1.0.0\nmultiprocess==0.70.16\nmunkres==1.1.4\nmurmurhash @ file:///home/conda/feedstock_root/build_artifacts/murmurhash_1695449783955/work\nmypy-extensions==1.0.0\nnamex==0.0.7\nnb-conda-kernels @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_kernels_1699980974206/work\nnb_conda @ file:///home/conda/feedstock_root/build_artifacts/nb_conda_1704789357480/work\nnbclassic @ file:///home/conda/feedstock_root/build_artifacts/nbclassic_1683202081046/work\nnbclient==0.5.13\nnbconvert==6.4.5\nnbdime==3.2.0\nnbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1690814868471/work\nndindex==1.8\nnest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1697083700168/work\nnetworkx==3.2.1\nnibabel==5.2.0\nnilearn==0.10.3\nninja==1.11.1.1\nnltk==3.2.4\nnose==1.3.7\nnotebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1680870634737/work\nnotebook_executor @ file:///home/kbuilder/miniconda3/conda-bld/dlenv-tf-2-15-gpu_1704941576253/work/packages/notebook_executor\nnotebook_shim @ file:///home/conda/feedstock_root/build_artifacts/notebook-shim_1682360583588/work\nnumba==0.58.1\nnumexpr==2.9.0\nnumpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1707225380409/work/dist/numpy-1.26.4-cp310-cp310-linux_x86_64.whl#sha256=51131fd8fc130cd168aecaf1bc0ea85f92e8ffebf211772ceb16ac2e7f10d7ca\nnvidia-ml-py==11.495.46\nnvtx @ file:///home/conda/feedstock_root/build_artifacts/nvtx_1708093799817/work\noauth2client==4.1.3\noauthlib==3.2.2\nobjsize==0.6.1\nodfpy==1.4.1\nolefile==0.47\nonnx==1.15.0\nopencensus==0.11.4\nopencensus-context==0.1.3\nopencv-contrib-python==4.9.0.80\nopencv-python==4.9.0.80\nopencv-python-headless==4.9.0.80\nopenpyxl==3.1.2\nopenslide-python==1.3.1\nopentelemetry-api==1.22.0\nopentelemetry-exporter-otlp==1.22.0\nopentelemetry-exporter-otlp-proto-common==1.22.0\nopentelemetry-exporter-otlp-proto-grpc==1.22.0\nopentelemetry-exporter-otlp-proto-http==1.22.0\nopentelemetry-proto==1.22.0\nopentelemetry-sdk==1.22.0\nopentelemetry-semantic-conventions==0.43b0\nopt-einsum==3.3.0\noptax==0.1.9\noptuna==3.5.0\norbax-checkpoint==0.5.3\nordered-set==4.1.0\norderedmultidict==1.0.1\norjson==3.9.10\nortools==9.4.1874\nosmnx==1.9.1\noverrides @ file:///home/conda/feedstock_root/build_artifacts/overrides_1691338815398/work\npackaging==21.3\npandas==2.1.4\npandas-datareader==0.10.0\npandas-profiling==3.6.6\npandas-summary==0.2.0\npandasql==0.7.3\npandocfilters @ file:///home/conda/feedstock_root/build_artifacts/pandocfilters_1631603243851/work\npanel==1.3.8\npapermill==2.5.0\nparam==2.0.2\nparso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\npartd @ file:///home/conda/feedstock_root/build_artifacts/partd_1695667515973/work\npath==16.10.0\npath.py==12.5.0\npathos==0.3.2\npathy @ file:///croot/pathy_1703688110387/work\npatsy==0.5.6\npdf2image==1.17.0\npettingzoo==1.24.0\npexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1667297516076/work\nphik==0.12.4\npickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\nPillow==9.5.0\npkgutil_resolve_name @ file:///home/conda/feedstock_root/build_artifacts/pkgutil-resolve-name_1694617248815/work\nplatformdirs==4.2.0\nplotly==5.18.0\nplotly-express==0.4.1\nplotnine==0.13.0\npluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\npointpats==2.4.0\npolars==0.20.10\npolyglot==16.7.4\npooch==1.8.1\npox==0.3.4\nppca==0.0.4\nppft==1.7.6.8\npreprocessing==0.1.13\npreshed @ file:///home/conda/feedstock_root/build_artifacts/preshed_1695644760607/work\nprettytable==3.9.0\nprogressbar2==4.3.2\nprometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1700579315247/work\npromise==2.3\nprompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1702399386289/work\npronouncing==0.2.0\nprophet==1.1.1\nproto-plus @ file:///home/conda/feedstock_root/build_artifacts/proto-plus_1702003338643/work\nprotobuf==3.20.3\npsutil==5.9.3\nptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\npudb==2024.1\nPuLP==2.8.0\npure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\npy-cpuinfo==9.0.0\npy-spy==0.3.14\npy4j==0.10.9.7\npyaml==23.12.0\nPyArabic==0.6.15\npyarrow==11.0.0\npyasn1 @ file:///home/conda/feedstock_root/build_artifacts/pyasn1_1701287008248/work\npyasn1-modules @ file:///home/conda/feedstock_root/build_artifacts/pyasn1-modules_1695107857548/work\nPyAstronomy==0.20.0\npybind11==2.11.1\npyclipper==1.3.0.post5\npycodestyle==2.11.1\npycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\npycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\npycryptodome==3.20.0\npyct==0.5.0\npycuda==2024.1\npydantic==2.5.3\npydantic_core==2.14.6\npydegensac==0.1.2\npydicom==2.4.4\npydocstyle==6.3.0\npydot==1.4.2\npydub==0.25.1\npyemd==1.0.0\npyerfa==2.0.1.1\npyexcel-io==0.6.6\npyexcel-ods==0.6.0\npyfasttext==0.4.6\npyflakes==3.2.0\npygltflib==1.16.1\nPygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1700607939962/work\nPyJWT==2.8.0\npykalman==0.9.5\npyLDAvis==3.4.1\npylibraft @ file:///opt/conda/conda-bld/work/python/pylibraft\npylint==3.0.3\npymc3==3.11.4\nPyMeeus==0.5.12\npymongo==3.13.0\nPympler==1.0.1\npynndescent==0.5.11\npynvml @ file:///home/conda/feedstock_root/build_artifacts/pynvml_1639061605391/work\npynvrtc==9.2\npyocr==0.8.5\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1698795453264/work\npyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1690737849915/work\npypdf==4.0.2\npyproj @ file:///home/conda/feedstock_root/build_artifacts/pyproj_1702028071709/work\npysal==24.1\npyshp @ file:///home/conda/feedstock_root/build_artifacts/pyshp_1659002966020/work\nPySocks @ file:///home/builder/ci_310/pysocks_1640793678128/work\npytesseract==0.3.10\npytest==8.0.1\npython-bidi==0.4.2\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\npython-dotenv==1.0.0\npython-json-logger @ file:///home/conda/feedstock_root/build_artifacts/python-json-logger_1677079630776/work\npython-Levenshtein==0.25.0\npython-louvain==0.16\npython-lsp-jsonrpc==1.1.2\npython-lsp-server==1.10.0\npython-slugify==8.0.4\npython-utils==3.8.2\npythreejs==2.4.2\npytoolconfig==1.3.1\npytools==2023.1.1\npytorch-ignite==0.4.13\npytorch-lightning==2.2.0.post0\npytz==2023.3.post1\npyu2f @ file:///home/conda/feedstock_root/build_artifacts/pyu2f_1604248910016/work\nPyUpSet==0.1.1.post7\npyviz_comms==3.0.1\nPyWavelets==1.5.0\nPyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1695373428874/work\npyzmq==24.0.1\nqgrid==1.3.1\nqtconsole==5.5.1\nQtPy==2.4.1\nquantecon==0.7.1\nquantities==0.15.0\nqudida==0.0.4\nraft-dask @ file:///opt/conda/conda-bld/work/python/raft-dask\nrapidfuzz==3.6.1\nrasterio==1.3.9\nrasterstats==0.19.0\nray==2.9.0\nray-cpp==2.9.0\nreferencing @ file:///home/conda/feedstock_root/build_artifacts/referencing_1704489226496/work\nregex==2023.12.25\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\nrequests-oauthlib==1.3.1\nrequests-toolbelt==0.10.1\nresponses==0.18.0\nretrying==1.3.3\nrfc3339-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3339-validator_1638811747357/work\nrfc3986-validator @ file:///home/conda/feedstock_root/build_artifacts/rfc3986-validator_1598024191506/work\nrgf-python==3.12.0\nrich @ file:///home/conda/feedstock_root/build_artifacts/rich-split_1700160075651/work/dist\nrich-click==1.7.3\nrmm @ file:///opt/conda/conda-bld/work/python\nrope==1.12.0\nrpds-py @ file:///home/conda/feedstock_root/build_artifacts/rpds-py_1703822618592/work\nrsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1658328885051/work\nRtree==1.2.0\nruamel-yaml-conda @ file:///home/builder/ci_310/ruamel_yaml_1640794439226/work\nruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1698138615000/work\nruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\ns2sphere==0.2.5\ns3fs==2024.2.0\ns3transfer==0.6.2\nsafetensors==0.4.2\nscattertext==0.1.19\nscikit-image==0.22.0\nscikit-learn==1.2.2\nscikit-learn-intelex==2024.1.0\nscikit-multilearn==0.2.0\nscikit-optimize==0.9.0\nscikit-plot==0.3.7\nscikit-surprise==1.1.3\nscipy==1.11.4\nseaborn==0.12.2\nSecretStorage==3.3.3\nsegment_anything @ git+https://github.com/facebookresearch/segment-anything.git@6fdee8f2727f4506cfbbe553e23b895e27956588\nsegregation==2.5\nsemver==3.0.2\nSend2Trash @ file:///home/conda/feedstock_root/build_artifacts/send2trash_1682601222253/work\nsentencepiece==0.2.0\nsentry-sdk==1.40.5\nsetproctitle==1.3.3\nsetuptools-git==1.2\nsetuptools-scm==8.0.4\nshap==0.44.1\nShapely==1.8.5.post1\nshellingham @ file:///home/conda/feedstock_root/build_artifacts/shellingham_1698144360966/work\nShimmy==1.3.0\nsimpervisor==1.0.0\nSimpleITK==2.3.1\nsimplejson==3.19.2\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\nsklearn-pandas==2.2.0\nslicer==0.0.7\nsmart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_split_1694066705667/work/dist\nsmhasher==0.150.1\nsmmap==5.0.1\nsniffio @ file:///home/conda/feedstock_root/build_artifacts/sniffio_1662051266223/work\nsnowballstemmer==2.2.0\nsnuggs==1.4.7\nsortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1621217038088/work\nsoundfile==0.12.1\nsoupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1693929250441/work\nsoxr==0.3.7\nspacy @ file:///home/conda/feedstock_root/build_artifacts/spacy_1699194962107/work\nspacy-legacy @ file:///home/conda/feedstock_root/build_artifacts/spacy-legacy_1674550301837/work\nspacy-loggers @ file:///home/conda/feedstock_root/build_artifacts/spacy-loggers_1694527114282/work\nspaghetti==1.7.5.post1\nspectral==0.23.1\nspglm==1.1.0\nsphinx-rtd-theme==0.2.4\nspint==1.0.7\nsplot==1.1.5.post1\nspopt==0.6.0\nspreg==1.4.2\nspvcm==0.3.0\nSQLAlchemy==2.0.25\nsqlparse==0.4.4\nsquarify==0.4.3\nsrsly @ file:///home/conda/feedstock_root/build_artifacts/srsly_1695653949688/work\nstable-baselines3==2.1.0\nstack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\nstanio==0.3.0\nstarlette==0.32.0.post1\nstatsmodels==0.14.1\nstemming==1.0.1\nstop-words==2018.7.23\nstopit==1.1.2\nstumpy==1.12.0\nsympy==1.12\ntables==3.9.2\ntabulate==0.9.0\ntangled-up-in-unicode==0.2.0\ntbb==2021.11.0\ntblib @ file:///home/conda/feedstock_root/build_artifacts/tblib_1702066284995/work\ntenacity==8.2.3\ntensorboard==2.15.1\ntensorboard-data-server==0.7.2\ntensorboard-plugin-profile==2.15.0\ntensorboardX==2.6.2.2\ntensorflow==2.15.0\ntensorflow-cloud==0.1.16\ntensorflow-datasets==4.9.4\ntensorflow-decision-forests==1.8.1\ntensorflow-estimator==2.15.0\ntensorflow-hub==0.16.1\ntensorflow-io==0.35.0\ntensorflow-io-gcs-filesystem==0.35.0\ntensorflow-metadata==0.14.0\ntensorflow-probability==0.23.0\ntensorflow-serving-api==2.14.1\ntensorflow-text==2.15.0\ntensorflow-transform==0.14.0\ntensorpack==0.11\ntensorstore==0.1.53\ntermcolor==2.4.0\nterminado @ file:///home/conda/feedstock_root/build_artifacts/terminado_1699810101464/work\ntestpath==0.6.0\ntext-unidecode==1.3\ntextblob==0.18.0.post0\ntexttable==1.7.0\ntf-keras==2.15.0\ntfp-nightly @ git+https://github.com/tensorflow/probability.git@fbc5ebe9b1d343113fb917010096cfd88b32eecf\nTheano==1.0.5\nTheano-PyMC==1.1.2\nthinc @ file:///home/conda/feedstock_root/build_artifacts/thinc_1703842165913/work\nthreadpoolctl==3.2.0\ntifffile==2023.12.9\ntimm==0.9.16\ntinycss2 @ file:///home/conda/feedstock_root/build_artifacts/tinycss2_1666100256010/work\ntobler==0.11.2\ntokenizers==0.15.2\ntoml==0.10.2\ntomli==2.0.1\ntomlkit==0.12.3\ntoolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1706112571092/work\ntorch @ file:///tmp/torch/torch-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=ae3259980b8d6551608b32fde2695baca64c72ed15ab2332023a248c113815a8\ntorchaudio @ file:///tmp/torch/torchaudio-2.1.2-cp310-cp310-linux_x86_64.whl#sha256=10966b20361b49bc41b6c6ba842d3ea842320fb8c589823b4120f24a98013b4a\ntorchdata==0.7.1\ntorchinfo==1.8.0\ntorchmetrics==1.3.1\ntorchtext @ file:///tmp/torch/torchtext-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=a2a382655a08e1f6eeab6a307d0c8d78139cfa04cc329a7dc15a3f7c1e6e7a19\ntorchvision @ file:///tmp/torch/torchvision-0.16.2-cp310-cp310-linux_x86_64.whl#sha256=105901a20924f652ee62df0bb57580c67725eb21f11a349658952c4be2050d94\ntornado @ file:///home/conda/feedstock_root/build_artifacts/tornado_1695373560918/work\nTPOT==0.12.1\ntqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1691671248568/work\ntraceml==1.0.8\ntraitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1675110562325/work\ntraittypes==0.2.1\ntransformers==4.38.1\ntreelite==3.2.0\ntreelite-runtime==3.2.0\ntrueskill==0.4.5\ntruststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\ntrx-python==0.2.9\ntsfresh==0.20.2\ntypeguard==4.1.5\ntyper @ file:///home/conda/feedstock_root/build_artifacts/typer_1683029246636/work\ntypes-python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/types-python-dateutil_1704512562698/work\ntyping-inspect==0.9.0\ntyping-utils @ file:///home/conda/feedstock_root/build_artifacts/typing_utils_1622899189314/work\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1702176139754/work\ntzdata==2023.4\ntzlocal==5.2\nuc-micro-py==1.0.3\nucx-py @ file:///opt/conda/conda-bld/work\nujson==5.9.0\numap-learn==0.5.5\nunicodedata2 @ file:///home/conda/feedstock_root/build_artifacts/unicodedata2_1695847980273/work\nUnidecode==1.3.8\nupdate-checker==0.18.0\nuri-template @ file:///home/conda/feedstock_root/build_artifacts/uri-template_1688655812972/work/dist\nuritemplate==3.0.1\nurllib3==1.26.18\nurwid==2.6.4\nurwid_readline==0.13\nuvicorn==0.25.0\nuvloop==0.19.0\nvaex==4.17.0\nvaex-astro==0.9.3\nvaex-core==4.17.1\nvaex-hdf5==0.14.1\nvaex-jupyter==0.8.2\nvaex-ml==0.18.3\nvaex-server==0.9.0\nvaex-viz==0.5.4\nvec_noise==1.1.4\nvecstack==0.4.0\nvirtualenv==20.21.0\nvisions==0.7.5\nvowpalwabbit==9.9.0\nvtk==9.3.0\nWand==0.6.13\nwandb==0.16.3\nwasabi @ file:///home/conda/feedstock_root/build_artifacts/wasabi_1686131297168/work\nwatchfiles==0.21.0\nwavio==0.0.8\nwcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1704731205417/work\nweasel @ file:///home/conda/feedstock_root/build_artifacts/weasel_1699295455892/work\nwebcolors @ file:///home/conda/feedstock_root/build_artifacts/webcolors_1679900785843/work\nwebencodings @ file:///home/conda/feedstock_root/build_artifacts/webencodings_1694681268211/work\nwebsocket-client @ file:///home/conda/feedstock_root/build_artifacts/websocket-client_1701630677416/work\nwebsockets==12.0\nWerkzeug==3.0.1\nwfdb==4.1.2\nwhatthepatch==1.0.5\nwidgetsnbextension==3.6.6\nwitwidget==1.8.1\nwoodwork==0.28.0\nwordcloud==1.9.3\nwordsegment==1.3.1\nwrapt==1.14.1\nxarray==2024.2.0\nxarray-einstats==0.7.0\nxgboost==2.0.3\nxvfbwrapper==0.2.9\nxxhash==3.4.1\nxyzservices @ file:///home/conda/feedstock_root/build_artifacts/xyzservices_1698325309404/work\ny-py==0.6.2\nyapf==0.40.2\nyarl @ file:///home/conda/feedstock_root/build_artifacts/yarl_1701168553642/work\nydata-profiling==4.6.4\nyellowbrick==1.5\nypy-websocket==0.8.4\nzict @ file:///home/conda/feedstock_root/build_artifacts/zict_1681770155528/work\nzipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1695255097490/work\nzstandard==0.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"def model_weights_equal(model1, model2):\n    # Check if models have the same number of parameters\n    if sum(p.numel() for p in model1.parameters()) != sum(p.numel() for p in model2.parameters()):\n        return False\n    \n    # Check if parameters are the same\n    for p1, p2 in zip(model1.parameters(), model2.parameters()):\n        if not torch.all(torch.eq(p1.data, p2.data)):\n            return False\n    \n    return True","metadata":{"execution":{"iopub.status.busy":"2024-04-13T13:24:25.892067Z","iopub.execute_input":"2024-04-13T13:24:25.892740Z","iopub.status.idle":"2024-04-13T13:24:25.898837Z","shell.execute_reply.started":"2024-04-13T13:24:25.892707Z","shell.execute_reply":"2024-04-13T13:24:25.897756Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"### Visual Attention Network ###","metadata":{"id":"O57xJG03K7-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#############################################################\n##### Own Implementation of the Visual Attention Network ####\n#############################################################\n'''\nNotes on the architecture from the paper:\n- Simple hierarchical structure\n  -> Sequence of four stages e.g\n  -> Decreasig output spatial resolution:\n    H/4 x W/4 -> H/8 x W/8 -> H/16 x W/16 -> H/32 x W/32 - Maybe start a 2**1??\n  -> With decreasing resolution, number of channels increases.\n  -> Each stage: First downsample the input with the stride number (-> Convolution)\n     --- In this step, we decrease the resolution and increase the dimensions\n         -> (First iteration: 100x100x1 as input and ?x?xdim[0] as output)\n         -> (Second iteration: 25x25xdim[0] as input and ?x?xdim[1] as output)\n  -> During each stage, the resolution (H & W) and the channels (C) remain the same and do not change\n     until the next stage starts\n  -> At each stage L-Groups (Blocks) of:\n    - Batch Norm\n    - 1x1 Conv\n    - GELU Activation\n    - LKA ()\n    - FFN (1x1 Conv. depthwise, 3x3 Conv, GELU, 1x1 Conv.)\n'''\n\nclass Downsampling(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.FFN = FFN(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.FFN(x)\n\n    return x\n\n\nclass FFN(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\n\nclass LKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    '''\n    When groups == in_channels and out_channels == K * in_channels,\n    where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    '''\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=kernel_size, groups=in_channels)#DWConv\n    self.conv2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=kernel_size,\n                           dilation=dilation, groups=in_channels, padding=8)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n    attn = self.conv2(attn)\n    attn = self.conv3(attn)\n\n    return input * attn\n\n\nclass VAN(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], image_channels=1, dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler = Downsampling(in_channels=image_channels if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block = nn.ModuleList([Block(channels=self.channels[j],\n                                   expansion_ratio=self.expansion_ratio[j],\n                                   dropout=dropout)\n                                   for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler)\n      setattr(self, f'block_{j+1}', block)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711009784026,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"},"user_tz":-60},"id":"mYJOZ10DUg-P","execution":{"iopub.status.busy":"2024-04-19T12:02:31.209294Z","iopub.execute_input":"2024-04-19T12:02:31.209745Z","iopub.status.idle":"2024-04-19T12:02:31.235954Z","shell.execute_reply.started":"2024-04-19T12:02:31.209704Z","shell.execute_reply":"2024-04-19T12:02:31.234981Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nvan_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_optimizer = optim.AdamW(van_model.parameters(), lr=1e-3)\nvan_trainer = Trainer(model=van_model, optimizer=van_optimizer,\n                      train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                      num_epochs=30, save_checkpoints=True, path=f'VAN()')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:03:15.576090Z","iopub.execute_input":"2024-04-19T12:03:15.576479Z","iopub.status.idle":"2024-04-19T12:03:15.594482Z","shell.execute_reply.started":"2024-04-19T12:03:15.576450Z","shell.execute_reply":"2024-04-19T12:03:15.593648Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"van_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T13:50:36.640470Z","iopub.execute_input":"2024-04-19T13:50:36.641161Z","iopub.status.idle":"2024-04-19T14:52:10.202946Z","shell.execute_reply.started":"2024-04-19T13:50:36.641128Z","shell.execute_reply":"2024-04-19T14:52:10.201954Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/20, Batch 0/422, Train Loss: 0.0288\nEpoch 1/20, Batch 100/422, Train Loss: 0.0150\nEpoch 1/20, Batch 200/422, Train Loss: 0.0641\nEpoch 1/20, Batch 300/422, Train Loss: 0.0881\nEpoch 1/20, Batch 400/422, Train Loss: 0.0229\nModel VAN at epoch 1/20: Avg Train Loss: 0.0316, Avg Val Loss: 0.0269\nEpoch 2/20, Batch 0/422, Train Loss: 0.0049\nEpoch 2/20, Batch 100/422, Train Loss: 0.0223\nEpoch 2/20, Batch 200/422, Train Loss: 0.0256\nEpoch 2/20, Batch 300/422, Train Loss: 0.0138\nEpoch 2/20, Batch 400/422, Train Loss: 0.0539\nModel VAN at epoch 2/20: Avg Train Loss: 0.0296, Avg Val Loss: 0.0240\nEpoch 3/20, Batch 0/422, Train Loss: 0.0117\nEpoch 3/20, Batch 100/422, Train Loss: 0.0115\nEpoch 3/20, Batch 200/422, Train Loss: 0.0688\nEpoch 3/20, Batch 300/422, Train Loss: 0.0487\nEpoch 3/20, Batch 400/422, Train Loss: 0.0297\nModel VAN at epoch 3/20: Avg Train Loss: 0.0303, Avg Val Loss: 0.0256\nEpoch 4/20, Batch 0/422, Train Loss: 0.0031\nEpoch 4/20, Batch 100/422, Train Loss: 0.0505\nEpoch 4/20, Batch 200/422, Train Loss: 0.0216\nEpoch 4/20, Batch 300/422, Train Loss: 0.0252\nEpoch 4/20, Batch 400/422, Train Loss: 0.0426\nModel VAN at epoch 4/20: Avg Train Loss: 0.0302, Avg Val Loss: 0.0256\nEpoch 5/20, Batch 0/422, Train Loss: 0.0255\nEpoch 5/20, Batch 100/422, Train Loss: 0.0234\nEpoch 5/20, Batch 200/422, Train Loss: 0.0085\nEpoch 5/20, Batch 300/422, Train Loss: 0.0823\nEpoch 5/20, Batch 400/422, Train Loss: 0.0093\nModel VAN at epoch 5/20: Avg Train Loss: 0.0270, Avg Val Loss: 0.0238\nEpoch 6/20, Batch 0/422, Train Loss: 0.0247\nEpoch 6/20, Batch 100/422, Train Loss: 0.0102\nEpoch 6/20, Batch 200/422, Train Loss: 0.0954\nEpoch 6/20, Batch 300/422, Train Loss: 0.0185\nEpoch 6/20, Batch 400/422, Train Loss: 0.0065\nModel VAN at epoch 6/20: Avg Train Loss: 0.0300, Avg Val Loss: 0.0254\nEpoch 7/20, Batch 0/422, Train Loss: 0.0461\nEpoch 7/20, Batch 100/422, Train Loss: 0.0201\nEpoch 7/20, Batch 200/422, Train Loss: 0.0099\nEpoch 7/20, Batch 300/422, Train Loss: 0.0088\nEpoch 7/20, Batch 400/422, Train Loss: 0.0046\nModel VAN at epoch 7/20: Avg Train Loss: 0.0285, Avg Val Loss: 0.0262\nEpoch 8/20, Batch 0/422, Train Loss: 0.0179\nEpoch 8/20, Batch 100/422, Train Loss: 0.0426\nEpoch 8/20, Batch 200/422, Train Loss: 0.1272\nEpoch 8/20, Batch 300/422, Train Loss: 0.0128\nEpoch 8/20, Batch 400/422, Train Loss: 0.0120\nModel VAN at epoch 8/20: Avg Train Loss: 0.0294, Avg Val Loss: 0.0227\nEpoch 9/20, Batch 0/422, Train Loss: 0.0303\nEpoch 9/20, Batch 100/422, Train Loss: 0.0172\nEpoch 9/20, Batch 200/422, Train Loss: 0.0048\nEpoch 9/20, Batch 300/422, Train Loss: 0.0197\nEpoch 9/20, Batch 400/422, Train Loss: 0.0222\nModel VAN at epoch 9/20: Avg Train Loss: 0.0267, Avg Val Loss: 0.0225\nEpoch 10/20, Batch 0/422, Train Loss: 0.0228\nEpoch 10/20, Batch 100/422, Train Loss: 0.0084\nEpoch 10/20, Batch 200/422, Train Loss: 0.0503\nEpoch 10/20, Batch 300/422, Train Loss: 0.0091\nEpoch 10/20, Batch 400/422, Train Loss: 0.0423\nModel VAN at epoch 10/20: Avg Train Loss: 0.0269, Avg Val Loss: 0.0215\nEpoch 11/20, Batch 0/422, Train Loss: 0.0084\nEpoch 11/20, Batch 100/422, Train Loss: 0.0011\nEpoch 11/20, Batch 200/422, Train Loss: 0.0100\nEpoch 11/20, Batch 300/422, Train Loss: 0.0107\nEpoch 11/20, Batch 400/422, Train Loss: 0.0312\nModel VAN at epoch 11/20: Avg Train Loss: 0.0188, Avg Val Loss: 0.0151\nEpoch 12/20, Batch 0/422, Train Loss: 0.0075\nEpoch 12/20, Batch 100/422, Train Loss: 0.0435\nEpoch 12/20, Batch 200/422, Train Loss: 0.0080\nEpoch 12/20, Batch 300/422, Train Loss: 0.0069\nEpoch 12/20, Batch 400/422, Train Loss: 0.0029\nModel VAN at epoch 12/20: Avg Train Loss: 0.0149, Avg Val Loss: 0.0134\nEpoch 13/20, Batch 0/422, Train Loss: 0.0256\nEpoch 13/20, Batch 100/422, Train Loss: 0.0810\nEpoch 13/20, Batch 200/422, Train Loss: 0.0088\nEpoch 13/20, Batch 300/422, Train Loss: 0.0094\nEpoch 13/20, Batch 400/422, Train Loss: 0.0125\nModel VAN at epoch 13/20: Avg Train Loss: 0.0158, Avg Val Loss: 0.0166\nEpoch 14/20, Batch 0/422, Train Loss: 0.0242\nEpoch 14/20, Batch 100/422, Train Loss: 0.0023\nEpoch 14/20, Batch 200/422, Train Loss: 0.0374\nEpoch 14/20, Batch 300/422, Train Loss: 0.0033\nEpoch 14/20, Batch 400/422, Train Loss: 0.0103\nModel VAN at epoch 14/20: Avg Train Loss: 0.0159, Avg Val Loss: 0.0155\nEpoch 15/20, Batch 0/422, Train Loss: 0.0494\nEpoch 15/20, Batch 100/422, Train Loss: 0.0175\nEpoch 15/20, Batch 200/422, Train Loss: 0.0057\nEpoch 15/20, Batch 300/422, Train Loss: 0.0067\nEpoch 15/20, Batch 400/422, Train Loss: 0.0173\nModel VAN at epoch 15/20: Avg Train Loss: 0.0138, Avg Val Loss: 0.0181\nEpoch 16/20, Batch 0/422, Train Loss: 0.0172\nEpoch 16/20, Batch 100/422, Train Loss: 0.0081\nEpoch 16/20, Batch 200/422, Train Loss: 0.0006\nEpoch 16/20, Batch 300/422, Train Loss: 0.0166\nEpoch 16/20, Batch 400/422, Train Loss: 0.0031\nModel VAN at epoch 16/20: Avg Train Loss: 0.0138, Avg Val Loss: 0.0154\nEpoch 17/20, Batch 0/422, Train Loss: 0.0244\nEpoch 17/20, Batch 100/422, Train Loss: 0.0268\nEpoch 17/20, Batch 200/422, Train Loss: 0.0020\nEpoch 17/20, Batch 300/422, Train Loss: 0.0187\nEpoch 17/20, Batch 400/422, Train Loss: 0.0212\nModel VAN at epoch 17/20: Avg Train Loss: 0.0148, Avg Val Loss: 0.0132\nEpoch 18/20, Batch 0/422, Train Loss: 0.0105\nEpoch 18/20, Batch 100/422, Train Loss: 0.0140\nEpoch 18/20, Batch 200/422, Train Loss: 0.0056\nEpoch 18/20, Batch 300/422, Train Loss: 0.0204\nEpoch 18/20, Batch 400/422, Train Loss: 0.0294\nModel VAN at epoch 18/20: Avg Train Loss: 0.0149, Avg Val Loss: 0.0134\nEpoch 19/20, Batch 0/422, Train Loss: 0.0103\nEpoch 19/20, Batch 100/422, Train Loss: 0.0053\nEpoch 19/20, Batch 200/422, Train Loss: 0.0009\nEpoch 19/20, Batch 300/422, Train Loss: 0.0028\nEpoch 19/20, Batch 400/422, Train Loss: 0.0026\nModel VAN at epoch 19/20: Avg Train Loss: 0.0125, Avg Val Loss: 0.0149\nEpoch 20/20, Batch 0/422, Train Loss: 0.0069\nEpoch 20/20, Batch 100/422, Train Loss: 0.0027\nEpoch 20/20, Batch 200/422, Train Loss: 0.0151\nEpoch 20/20, Batch 300/422, Train Loss: 0.0034\nEpoch 20/20, Batch 400/422, Train Loss: 0.0072\nModel VAN at epoch 20/20: Avg Train Loss: 0.0145, Avg Val Loss: 0.0150\nModel VAN took 158.58 minutes to run on 20 epochs.\n","output_type":"stream"}]},{"cell_type":"code","source":"van_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:52:10.204576Z","iopub.execute_input":"2024-04-19T14:52:10.204896Z","iopub.status.idle":"2024-04-19T14:52:40.364649Z","shell.execute_reply.started":"2024-04-19T14:52:10.204869Z","shell.execute_reply":"2024-04-19T14:52:40.363712Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN: 0.9922 - in 30.151325941085815 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"ckpt = torch.load('/kaggle/working/VAN().pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:56:55.061542Z","iopub.execute_input":"2024-04-19T14:56:55.061943Z","iopub.status.idle":"2024-04-19T14:56:55.089302Z","shell.execute_reply.started":"2024-04-19T14:56:55.061914Z","shell.execute_reply":"2024-04-19T14:56:55.088601Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"ckpt['loss']","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:57:30.195898Z","iopub.execute_input":"2024-04-19T14:57:30.196280Z","iopub.status.idle":"2024-04-19T14:57:30.202302Z","shell.execute_reply.started":"2024-04-19T14:57:30.196251Z","shell.execute_reply":"2024-04-19T14:57:30.201389Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0.014491620752601818"},"metadata":{}}]},{"cell_type":"code","source":"### Check reproducability","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"van_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:58:16.204296Z","iopub.execute_input":"2024-04-19T14:58:16.204665Z","iopub.status.idle":"2024-04-19T14:58:46.234582Z","shell.execute_reply.started":"2024-04-19T14:58:16.204637Z","shell.execute_reply":"2024-04-19T14:58:46.233655Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN: 0.9943 - in 30.02241325378418 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nvan_optimizer = optim.AdamW(van_model.parameters(), lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.keys()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:02:25.092595Z","iopub.execute_input":"2024-04-19T15:02:25.093506Z","iopub.status.idle":"2024-04-19T15:02:25.099207Z","shell.execute_reply.started":"2024-04-19T15:02:25.093472Z","shell.execute_reply":"2024-04-19T15:02:25.098223Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss', 'running_loss_train', 'running_loss_val', 'test_accuracy', 'inference_time'])"},"metadata":{}}]},{"cell_type":"code","source":"ckpt['scheduler_state_dict']","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:10:44.840597Z","iopub.execute_input":"2024-04-19T15:10:44.841527Z","iopub.status.idle":"2024-04-19T15:10:44.847559Z","shell.execute_reply.started":"2024-04-19T15:10:44.841492Z","shell.execute_reply":"2024-04-19T15:10:44.846717Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'factor': 0.1,\n 'min_lrs': [0],\n 'patience': 10,\n 'verbose': False,\n 'cooldown': 0,\n 'cooldown_counter': 0,\n 'mode': 'min',\n 'threshold': 0.0001,\n 'threshold_mode': 'rel',\n 'best': 0.013240438364328274,\n 'num_bad_epochs': 3,\n 'mode_worse': inf,\n 'eps': 1e-08,\n 'last_epoch': 50,\n '_last_lr': [0.0001]}"},"metadata":{}}]},{"cell_type":"code","source":"### Wrap checkpoint loading into a function.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt_model = VAN(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nckpt_model.load_state_dict(ckpt['model_state_dict'])\nckpt_optimizer = optim.AdamW(ckpt_model.parameters(), lr=1e-3)\nckpt_optimizer.load_state_dict(ckpt['optimizer_state_dict'])\nckpt_trainer = Trainer(model=ckpt_model, optimizer=ckpt_optimizer,\n                       train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                       num_epochs=30, save_checkpoints=False, path=f'Ckpt_VAN()')\nckpt_trainer.scheduler.load_state_dict(ckpt['scheduler_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:03:28.440024Z","iopub.execute_input":"2024-04-19T15:03:28.440886Z","iopub.status.idle":"2024-04-19T15:03:28.459943Z","shell.execute_reply.started":"2024-04-19T15:03:28.440852Z","shell.execute_reply":"2024-04-19T15:03:28.459215Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"ckpt_trainer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T15:03:42.736612Z","iopub.execute_input":"2024-04-19T15:03:42.737562Z","iopub.status.idle":"2024-04-19T15:04:12.939083Z","shell.execute_reply.started":"2024-04-19T15:03:42.737528Z","shell.execute_reply":"2024-04-19T15:04:12.938119Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Test Accuracy for VAN: 0.9936 - in 30.193816661834717 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"######################\n### ABLATION STUDY ###\n######################","metadata":{"id":"euX4LKFiCmla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implementation of the VAN without an Attention Mechanism\nclass Downsampling_ablation(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size, stride):\n    super().__init__()\n\n    self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=1, bias=False)\n\n  def forward(self, x):\n\n    x = self.conv(x)\n\n    return x\n\n\nclass Block_ablation(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.batch_norm1 = nn.BatchNorm2d(channels) # Set running statistics off in testing? -> Check if done using model.eval()\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels ,kernel_size=1)\n    self.act1 = nn.GELU()\n    #self.LKA = LKA(in_channels=channels, out_channels=channels)\n    self.batch_norm2 = nn.BatchNorm2d(channels)\n    self.abl_FFN = FFN_ablation(channels=channels, expansion_ratio=expansion_ratio, dropout=dropout)\n\n  def forward(self, x):\n    x = self.batch_norm1(x)\n    x = self.conv1(x)\n    x = self.act1(x)\n    #x = self.LKA(x)\n    x = self.batch_norm2(x)\n    x = self.abl_FFN(x)\n\n    return x\n\n\nclass FFN_ablation(nn.Module):\n  def __init__(self, channels, expansion_ratio, dropout):\n    super().__init__()\n\n    self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels*expansion_ratio, kernel_size=1)\n    self.conv2 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels*expansion_ratio,\n                           kernel_size=3, stride=1, padding=1, groups=channels*expansion_ratio)  #DW3x3Conv\n    self.act1 = nn.GELU()\n    self.conv3 = nn.Conv2d(in_channels=channels*expansion_ratio, out_channels=channels, kernel_size=1)\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    x = self.act1(x)\n    x = self.conv3(x)\n    x = self.dropout(x)\n\n    return x\n\nclass VAN_ablation(nn.Module):\n  def __init__(self, num_classes=10, stages=4, l=[2, 2, 1, 1], channels=[32, 64, 128, 256],\n               expansion_ratio=[2, 2, 2, 2], dropout=0.5):\n    super().__init__()\n    '''\n    The block and downsampler need to be initialized within the __init__ method in order to\n    determine the number of parameters correctly. This also makes the moving to device easier,\n    as moving the whole model will move the blocks and downsamplers aswell.\n    '''\n    self.stages = stages\n    self.channels = channels\n    self.expansion_ratio = expansion_ratio\n    self.l = l\n    self.num_classes = num_classes\n    self.classifier = nn.Linear(in_features=channels[-1], out_features=num_classes)\n\n    for j in range(self.stages):\n      downsampler_ablation = Downsampling_ablation(in_channels=1 if j == 0 else self.channels[j-1],\n                                 out_channels=self.channels[j],\n                                 kernel_size=3, stride=2)\n      block_ablation = nn.ModuleList([Block_ablation(channels=self.channels[j],\n                                      expansion_ratio=self.expansion_ratio[j],\n                                      dropout=dropout)\n                                      for _ in range(self.l[j])])\n\n      setattr(self, f'downsampler_{j+1}', downsampler_ablation)\n      setattr(self, f'block_{j+1}', block_ablation)\n\n  def forward(self, x):\n\n    for j in range(self.stages):\n\n      downsampler = getattr(self, f'downsampler_{j+1}')\n      block = getattr(self, f'block_{j+1}')\n      x = downsampler(x)\n      for blk in block:\n        x = blk(x)\n\n    x = x.flatten(2).transpose(1, 2)\n    x = x.mean(dim=1)\n    x = self.classifier(x)\n\n    return x","metadata":{"id":"PfX0_Pu6Cmei","executionInfo":{"status":"ok","timestamp":1711012063764,"user_tz":-60,"elapsed":208,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"execution":{"iopub.status.busy":"2024-03-26T19:42:01.421882Z","iopub.execute_input":"2024-03-26T19:42:01.422639Z","iopub.status.idle":"2024-03-26T19:42:01.440940Z","shell.execute_reply.started":"2024-03-26T19:42:01.422607Z","shell.execute_reply":"2024-03-26T19:42:01.440077Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Initialize Baseline model\nabl_model = VAN_ablation(channels=[64, 128], stages=2, l=[1, 1], expansion_ratio=[2, 4])\nabl_optimizer = optim.AdamW(abl_model.parameters(), lr=1e-3)\nabl_trainer = Trainer(model=vabl_model, optimizer=abl_optimizer,\n                      train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n                      num_epochs=30, save_checkpoints=True, path=f'VAN_Ablation()')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abl_trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abl_trainer.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########################\n### ACCURACY COMPARISON ###\n###########################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#####################################\n### COMPUTATIONAL COST COMPARISON ###\n#####################################","metadata":{"id":"q80dXxsWAsh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nTODO: Check torchinfo Profiler\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare number of modueles\n\ndef count_modules(model):\n    # Use model.modules() for all modules including nested ones,\n    # or model.children() for immediate children only.\n    num_modules = sum(1 for _ in model.modules())\n    return num_modules\n\nbaseline = BaselineCNN()\nvan = VAN()\n\nnum_modules_cnn = count_modules(baseline)\nnum_modules_van = count_modules(van)\n\nprint(\"Number of modules in CNN:\", num_modules_cnn)\nprint(\"Number of modules in VAN:\", num_modules_van)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6a5e_FegAoGs","executionInfo":{"status":"ok","timestamp":1711019998475,"user_tz":-60,"elapsed":336,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"85dbf9d1-b18e-46b1-b7d1-4ff66b5b309c","execution":{"iopub.status.busy":"2024-03-21T11:39:11.847181Z","iopub.execute_input":"2024-03-21T11:39:11.847897Z","iopub.status.idle":"2024-03-21T11:39:11.924267Z","shell.execute_reply.started":"2024-03-21T11:39:11.847864Z","shell.execute_reply":"2024-03-21T11:39:11.923437Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of modules in CNN: 11\nNumber of modules in VAN: 92\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of parameters for the baseline CNN model\ntrainable_params = sum(p.numel() for p in baseline.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in baseline.parameters())\n\"{:,}\".format(trainable_params), \"{:,}\".format(total_params)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95prYojcBLah","executionInfo":{"status":"ok","timestamp":1711020097212,"user_tz":-60,"elapsed":230,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"857675c9-8beb-4fea-a514-810f8645a599","execution":{"iopub.status.busy":"2024-03-21T11:39:16.161026Z","iopub.execute_input":"2024-03-21T11:39:16.161748Z","iopub.status.idle":"2024-03-21T11:39:16.168610Z","shell.execute_reply.started":"2024-03-21T11:39:16.161715Z","shell.execute_reply":"2024-03-21T11:39:16.167723Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"('5,140,234', '5,140,234')"},"metadata":{}}]},{"cell_type":"code","source":"# Number of parameters for VAN\ntotal_params_van = sum(p.numel() for p in van.parameters())\nprint(f' Total parameters of the VAN model are: {\"{:,}\".format(total_params_van)}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJIg4rfgBNHh","executionInfo":{"status":"ok","timestamp":1711020070331,"user_tz":-60,"elapsed":407,"user":{"displayName":"Tobias Jedlicka","userId":"10721733797122281021"}},"outputId":"50aedc59-dcc0-4ee5-ec32-f1a56f34eae6","execution":{"iopub.status.busy":"2024-03-21T11:39:18.306852Z","iopub.execute_input":"2024-03-21T11:39:18.307471Z","iopub.status.idle":"2024-03-21T11:39:18.313188Z","shell.execute_reply.started":"2024-03-21T11:39:18.307441Z","shell.execute_reply":"2024-03-21T11:39:18.312277Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":" Total parameters of the VAN model are: 988,394\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install deepspeed\nfrom deepspeed.profiling.flops_profiler import FlopsProfiler","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5npplbR9v-vu","outputId":"3c1e8282-709e-4771-ae20-ee0d3d59ae2c","execution":{"iopub.status.busy":"2024-03-26T18:06:35.292615Z","iopub.execute_input":"2024-03-26T18:06:35.293076Z","iopub.status.idle":"2024-03-26T18:07:19.351944Z","shell.execute_reply.started":"2024-03-26T18:06:35.293044Z","shell.execute_reply":"2024-03-26T18:07:19.350905Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting deepspeed\n  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting hjson (from deepspeed)\n  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.11.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed) (9.0.0)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from deepspeed) (2.5.3)\nCollecting pynvml (from deepspeed)\n  Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from deepspeed) (2.1.2+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed) (4.66.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->deepspeed) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic->deepspeed) (4.9.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->deepspeed) (1.3.0)\nDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: deepspeed\n  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400366 sha256=d1a418cecfeaa6323e2a6bcf0db48db75f3091952a87d8c94d6132bab1167426\n  Stored in directory: /root/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\nSuccessfully built deepspeed\nInstalling collected packages: hjson, pynvml, deepspeed\nSuccessfully installed deepspeed-0.14.0 hjson-3.1.0 pynvml-11.5.0\n[2024-03-26 18:07:16,067] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","output_type":"stream"}]},{"cell_type":"code","source":"m1 = VAN(num_classes=14, stages=2, channels=[64, 128], image_channels=3, l=[1,1], expansion_ratio=[2,4])\nprofile_model(input_model=m1, data_loader=pc_train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:52:16.531727Z","iopub.execute_input":"2024-03-25T17:52:16.532454Z","iopub.status.idle":"2024-03-25T17:52:19.048782Z","shell.execute_reply.started":"2024-03-25T17:52:16.532421Z","shell.execute_reply":"2024-03-25T17:52:19.047886Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[2024-03-25 17:52:18,877] [INFO] [profiler.py:80:start_profile] Flops profiler started\n\n-------------------------- DeepSpeed Flops Profiler --------------------------\nProfile Summary at step 5:\nNotations:\ndata parallel size (dp_size), model parallel size(mp_size),\nnumber of parameters (params), number of multiply-accumulate operations(MACs),\nnumber of floating-point operations (flops), floating-point operations per second (FLOPS),\nfwd latency (forward propagation latency), bwd latency (backward propagation latency),\nstep (weights update latency), iter latency (sum of fwd, bwd and step latency)\n\nparams per GPU:                                                         283.66 K\nparams of model = params per GPU * mp_size:                             0       \nfwd MACs per GPU:                                                       97.1 GMACs\nfwd flops per GPU:                                                      196.11 G\nfwd flops of model = fwd flops per GPU * mp_size:                       196.11 G\nfwd latency:                                                            104.24 ms\nfwd FLOPS per GPU = fwd flops per GPU / fwd latency:                    1.88 TFLOPS\n\n----------------------------- Aggregated Profile per GPU -----------------------------\nTop 1 modules in terms of params, MACs or fwd latency at different model depths:\ndepth 0:\n    params      - {'VAN': '283.66 K'}\n    MACs        - {'VAN': '97.1 GMACs'}\n    fwd latency - {'VAN': '104.24 ms'}\ndepth 1:\n    params      - {'ModuleList': '206.4 K'}\n    MACs        - {'ModuleList': '75.96 GMACs'}\n    fwd latency - {'ModuleList': '97.32 ms'}\ndepth 2:\n    params      - {'Block': '206.4 K'}\n    MACs        - {'Block': '75.96 GMACs'}\n    fwd latency - {'Block': '97.32 ms'}\ndepth 3:\n    params      - {'FFN': '154.69 K'}\n    MACs        - {'FFN': '53.96 GMACs'}\n    fwd latency - {'LKA': '44.8 ms'}\n\n------------------------------ Detailed Profile per GPU ------------------------------\nEach module profile is listed after its name in the following order: \nparams, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS\n\nNote: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.\n2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.\n\nVAN(\n  283.66 K = 100% Params, 97.1 GMACs = 100% MACs, 104.24 ms = 100% latency, 1.88 TFLOPS\n  (classifier): Linear(1.81 K = 0.64% Params, 114.69 KMACs = 0% MACs, 146.87 us = 0.14% latency, 1.56 GFLOPS, in_features=128, out_features=14, bias=True)\n  (downsampler_1): Downsampling(\n    1.73 K = 0.61% Params, 1.81 GMACs = 1.87% MACs, 1.28 ms = 1.23% latency, 2.83 TFLOPS\n    (conv): Conv2d(1.73 K = 0.61% Params, 1.81 GMACs = 1.87% MACs, 1.19 ms = 1.14% latency, 3.06 TFLOPS, 3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  )\n  (block_1): ModuleList(\n    (0): Block(\n      29.63 K = 10.45% Params, 30.23 GMACs = 31.13% MACs, 55.39 ms = 53.14% latency, 1.11 TFLOPS\n      (batch_norm1): BatchNorm2d(128 = 0.05% Params, 0 MACs = 0% MACs, 2.04 ms = 1.95% latency, 164.66 GFLOPS, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv1): Conv2d(4.16 K = 1.47% Params, 4.29 GMACs = 4.42% MACs, 2.64 ms = 2.54% latency, 3.27 TFLOPS, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n      (act1): GELU(0 = 0% Params, 0 MACs = 0% MACs, 1.05 ms = 1.01% latency, 64.02 GFLOPS, approximate='none')\n      (LKA): LKA(\n        7.49 K = 2.64% Params, 7.55 GMACs = 7.77% MACs, 29.64 ms = 28.43% latency, 515.95 GFLOPS\n        (conv1): Conv2d(1.66 K = 0.59% Params, 1.57 GMACs = 1.62% MACs, 11.81 ms = 11.33% latency, 271.95 GFLOPS, 64, 64, kernel_size=(5, 5), stride=(1, 1), groups=64)\n        (conv2): Conv2d(1.66 K = 0.59% Params, 1.68 GMACs = 1.73% MACs, 12.46 ms = 11.96% latency, 274.61 GFLOPS, 64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(8, 8), dilation=(3, 3), groups=64)\n        (conv3): Conv2d(4.16 K = 1.47% Params, 4.29 GMACs = 4.42% MACs, 2.65 ms = 2.54% latency, 3.27 TFLOPS, 64, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (FFN): FFN(\n        17.86 K = 6.29% Params, 18.39 GMACs = 18.94% MACs, 19.79 ms = 18.98% latency, 1.88 TFLOPS\n        (conv1): Conv2d(8.32 K = 2.93% Params, 8.59 GMACs = 8.85% MACs, 5.4 ms = 5.18% latency, 3.2 TFLOPS, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n        (conv2): Conv2d(1.28 K = 0.45% Params, 1.21 GMACs = 1.24% MACs, 8.54 ms = 8.19% latency, 298.71 GFLOPS, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n        (act1): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.04 ms = 1.95% latency, 65.95 GFLOPS, approximate='none')\n        (conv3): Conv2d(8.26 K = 2.91% Params, 8.59 GMACs = 8.85% MACs, 3.59 ms = 3.45% latency, 4.8 TFLOPS, 128, 64, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n  )\n  (downsampler_2): Downsampling(\n    73.73 K = 25.99% Params, 19.33 GMACs = 19.9% MACs, 4.95 ms = 4.75% latency, 7.81 TFLOPS\n    (conv): Conv2d(73.73 K = 25.99% Params, 19.33 GMACs = 19.9% MACs, 4.89 ms = 4.69% latency, 7.91 TFLOPS, 64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n  )\n  (block_2): ModuleList(\n    (0): Block(\n      176.77 K = 62.32% Params, 45.73 GMACs = 47.1% MACs, 41.93 ms = 40.22% latency, 2.2 TFLOPS\n      (batch_norm1): BatchNorm2d(256 = 0.09% Params, 0 MACs = 0% MACs, 1.03 ms = 0.99% latency, 162.4 GFLOPS, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv1): Conv2d(16.51 K = 5.82% Params, 4.29 GMACs = 4.42% MACs, 1.94 ms = 1.86% latency, 4.46 TFLOPS, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n      (act1): GELU(0 = 0% Params, 0 MACs = 0% MACs, 541.21 us = 0.52% latency, 62 GFLOPS, approximate='none')\n      (LKA): LKA(\n        23.17 K = 8.17% Params, 5.87 GMACs = 6.05% MACs, 15.17 ms = 14.55% latency, 780.63 GFLOPS\n        (conv1): Conv2d(3.33 K = 1.17% Params, 737.28 MMACs = 0.76% MACs, 5.58 ms = 5.36% latency, 269.4 GFLOPS, 128, 128, kernel_size=(5, 5), stride=(1, 1), groups=128)\n        (conv2): Conv2d(3.33 K = 1.17% Params, 838.86 MMACs = 0.86% MACs, 6.25 ms = 6% latency, 273.8 GFLOPS, 128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(8, 8), dilation=(3, 3), groups=128)\n        (conv3): Conv2d(16.51 K = 5.82% Params, 4.29 GMACs = 4.42% MACs, 1.93 ms = 1.85% latency, 4.46 TFLOPS, 128, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (FFN): FFN(\n        136.83 K = 48.24% Params, 35.57 GMACs = 36.63% MACs, 23.04 ms = 22.1% latency, 3.11 TFLOPS\n        (conv1): Conv2d(66.05 K = 23.28% Params, 17.18 GMACs = 17.69% MACs, 7.39 ms = 7.09% latency, 4.66 TFLOPS, 128, 512, kernel_size=(1, 1), stride=(1, 1))\n        (conv2): Conv2d(5.12 K = 1.8% Params, 1.21 GMACs = 1.24% MACs, 8.47 ms = 8.12% latency, 301.19 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n        (act1): GELU(0 = 0% Params, 0 MACs = 0% MACs, 2.04 ms = 1.96% latency, 65.73 GFLOPS, approximate='none')\n        (conv3): Conv2d(65.66 K = 23.15% Params, 17.18 GMACs = 17.69% MACs, 4.95 ms = 4.75% latency, 6.94 TFLOPS, 512, 128, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n  )\n)\n------------------------------------------------------------------------------\n[2024-03-25 17:52:19,038] [INFO] [profiler.py:226:end_profile] Flops profiler finished\n","output_type":"stream"}]},{"cell_type":"code","source":"def profile_model(input_model, data_loader=train_loader):\n    # Profile a model to get the FLOPS and Latency\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model = input_model\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n    prof = FlopsProfiler(model)\n    # Profile at step 5 to warmup\n    profile_step = 5\n    for batch_idx, (data, target) in enumerate(data_loader):\n      if batch_idx == profile_step:\n        prof.start_profile()\n\n      data, target = data.to(device), target.to(device)\n      optimizer.zero_grad()\n      output = model(data)\n      loss = criterion(output, target)\n\n      if batch_idx == profile_step:\n        prof.stop_profile()\n        flops = prof.get_total_flops()\n        macs = prof.get_total_macs()\n        params = prof.get_total_params()\n        prof.print_model_profile(profile_step=profile_step)\n        prof.end_profile()\n\n      loss.backward()\n      optimizer.step()\n\n      if batch_idx == profile_step:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-03-25T17:47:37.606860Z","iopub.execute_input":"2024-03-25T17:47:37.607618Z","iopub.status.idle":"2024-03-25T17:47:37.616235Z","shell.execute_reply.started":"2024-03-25T17:47:37.607586Z","shell.execute_reply":"2024-03-25T17:47:37.615214Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# FLOPs for VAN\nfor data, target in augmented_loader:\n  input_data, input_target = data.to(device), target.to(device)\n  break\n\nflops_van, params = profile(van, inputs=(input_data,))\nprint(f'Estimated Params for VAN:, {(\"{:,}\".format(params))}')\nprint(f'Estimated FLOPs for VAN:, {(\"{:,}\".format(flops_van))}')","metadata":{"id":"zqHb0WdSA3Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for Baseline CNN\n\n# Define your model and input data\nbaseline = BaselineCNN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = baseline(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"6vf3Yhg3BFbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect bottlenecks for VAN\n\n# Define your model and input data\nvan = VAN().to(device) # Your PyTorch model\ninput_data = input_data  # Your input data\n\n# Perform forward pass while profiling\nwith profile(profile_memory=True, record_shapes=True, use_cuda=True) as prof:\n    with record_function(\"model_inference\"):\n        output = van(input_data)\n\n# Print profiling results\nprint(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))","metadata":{"id":"jvtS_uZKBFSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare convolution speed ###\nfrom torch.autograd import profiler\ninput = torch.randn((128, 32, 50, 50), device=\"cuda\")\nm1 = LKA(32, 32).to(\"cuda\")\nm2 = LSKA(32, 32).to(\"cuda\")\nm3 = KA(32, 32).to(\"cuda\")\n\nwith profiler.profile(record_shapes=True, use_cuda=True) as prof:\n    with profiler.record_function(\"model_inference\"):\n        # Your PyTorch operations here\n        output = m3(input)\nprint(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))","metadata":{"id":"_rsVqxX4BFIW","execution":{"iopub.status.busy":"2024-03-22T09:19:14.996033Z","iopub.execute_input":"2024-03-22T09:19:14.996978Z","iopub.status.idle":"2024-03-22T09:19:15.029116Z","shell.execute_reply.started":"2024-03-22T09:19:14.996939Z","shell.execute_reply":"2024-03-22T09:19:15.028133Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                     model_inference         6.24%     504.000us        14.97%       1.208ms       1.208ms     110.000us         1.36%       8.117ms       8.117ms             1  \n                        aten::conv2d         0.17%      14.000us         6.65%     537.000us     537.000us       5.000us         0.06%       7.074ms       7.074ms             1  \n             aten::_convolution_mode         0.24%      19.000us         6.48%     523.000us     523.000us       5.000us         0.06%       7.069ms       7.069ms             1  \n                   aten::convolution         0.43%      35.000us         6.24%     504.000us     504.000us      11.000us         0.14%       7.064ms       7.064ms             1  \n                  aten::_convolution         0.79%      64.000us         5.81%     469.000us     469.000us      24.000us         0.30%       7.053ms       7.053ms             1  \n             aten::cudnn_convolution         2.70%     218.000us         4.32%     349.000us     349.000us       6.652ms        81.95%       6.652ms       6.652ms             1  \n                           aten::mul         0.42%      34.000us         0.52%      42.000us      42.000us     493.000us         6.07%     493.000us     493.000us             1  \n                         aten::clone         0.84%      68.000us         1.55%     125.000us     125.000us      48.000us         0.59%     440.000us     440.000us             1  \n                          aten::add_         0.37%      30.000us         0.51%      41.000us      41.000us     370.000us         4.56%     370.000us     370.000us             1  \n                         aten::copy_         0.17%      14.000us         0.46%      37.000us      37.000us     363.000us         4.47%     363.000us     363.000us             1  \n------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 8.072ms\nSelf CUDA time total: 8.117ms\n\n","output_type":"stream"},{"name":"stderr","text":"STAGE:2024-03-22 09:19:15 35:35 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\nSTAGE:2024-03-22 09:19:15 35:35 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-03-22 09:19:15 35:35 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n","output_type":"stream"}]},{"cell_type":"code","source":"#######################################################\n### Compare difference in speed using fp32 and fp16 ###\n#######################################################","metadata":{"execution":{"iopub.status.busy":"2024-03-26T18:14:10.948549Z","iopub.execute_input":"2024-03-26T18:14:10.948985Z","iopub.status.idle":"2024-03-26T18:14:10.954385Z","shell.execute_reply.started":"2024-03-26T18:14:10.948955Z","shell.execute_reply":"2024-03-26T18:14:10.953437Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"cuda_loader = torch.utils.data.DataLoader(dataset=augmented_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T20:02:06.293855Z","iopub.execute_input":"2024-03-26T20:02:06.294762Z","iopub.status.idle":"2024-03-26T20:02:06.300379Z","shell.execute_reply.started":"2024-03-26T20:02:06.294726Z","shell.execute_reply":"2024-03-26T20:02:06.299351Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4]).cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T19:22:35.929570Z","iopub.execute_input":"2024-03-26T19:22:35.930169Z","iopub.status.idle":"2024-03-26T19:22:35.951426Z","shell.execute_reply.started":"2024-03-26T19:22:35.930136Z","shell.execute_reply":"2024-03-26T19:22:35.950730Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"### FP32\n\n# Creates model and optimizer in default precision\nmodel = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4])\nmodel.to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\nwith torch.autograd.profiler.profile(use_cuda=True) as prof:\n    for epoch in range(1):\n        print(f'Epoch {epoch+1} started')\n\n        for i, (input, target) in enumerate(cuda_loader):\n            #input, target = input.to('cuda'), target.to('cuda')\n            optimizer.zero_grad()\n\n            output = model(input)\n            loss = criterion(output, target)\n\n            loss.backward()\n\n            optimizer.step()\n            if i == 10:\n                break\n        print(f'Epoch {epoch+1} finished')\nprint(prof.key_averages())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T20:02:09.897192Z","iopub.execute_input":"2024-03-26T20:02:09.898064Z","iopub.status.idle":"2024-03-26T20:02:14.591720Z","shell.execute_reply.started":"2024-03-26T20:02:09.898009Z","shell.execute_reply":"2024-03-26T20:02:14.590115Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1 started\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cuda_loader):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#input, target = input.to('cuda'), target.to('cuda')\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[12], line 177\u001b[0m, in \u001b[0;36mVAN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m downsampler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownsampler_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    176\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdownsampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m block:\n\u001b[1;32m    179\u001b[0m   x \u001b[38;5;241m=\u001b[39m blk(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[12], line 36\u001b[0m, in \u001b[0;36mDownsampling.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 36\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"],"ename":"RuntimeError","evalue":"Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor","output_type":"error"}]},{"cell_type":"code","source":"from torch import autocast\nfrom torch.cuda.amp import GradScaler\n\n### FP16\n\n# Creates model and optimizer in default precision\nmodel = VAN(channels=[64,128], stages=2, l=[2,2], expansion_ratio=[2,4])\nmodel.to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=1e-3)\n\n# Creates a GradScaler once at the beginning of training.\nscaler = GradScaler()\nwith torch.autograd.profiler.profile(use_cuda=True) as prof:\n    for epoch in range(1):\n        print(f'Epoch {epoch+1} started')\n\n        for i, (input, target) in enumerate(train_loader):\n            input, target = input.to('cuda'), target.to('cuda')\n            optimizer.zero_grad()\n\n            # Runs the forward pass with autocasting.\n            with autocast(device_type='cuda', dtype=torch.float16):\n                output = model(input)\n                loss = criterion(output, target)\n\n            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n            # Backward passes under autocast are not recommended.\n            # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n            scaler.scale(loss).backward()\n\n            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n            # otherwise, optimizer.step() is skipped.\n            scaler.step(optimizer)\n\n            # Updates the scale for next iteration.\n            scaler.update()\n            if i == 10 :\n                break\n                \n        print(f'Epoch {epoch+1} finished')\nprint(prof.key_averages())","metadata":{"execution":{"iopub.status.busy":"2024-03-26T19:49:18.065962Z","iopub.execute_input":"2024-03-26T19:49:18.066371Z","iopub.status.idle":"2024-03-26T19:50:37.974789Z","shell.execute_reply.started":"2024-03-26T19:49:18.066341Z","shell.execute_reply":"2024-03-26T19:50:37.973862Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"STAGE:2024-03-26 19:49:18 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 started\nEpoch 1 finished\n","output_type":"stream"},{"name":"stderr","text":"STAGE:2024-03-26 19:49:31 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-03-26 19:49:32 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n","output_type":"stream"},{"name":"stdout","text":"-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                            aten::empty         0.40%      45.438ms         0.40%      45.438ms       1.367us     228.792ms         2.00%     228.792ms       6.884us         33236  \n                                          aten::random_         0.33%      36.830ms         0.33%      36.830ms       1.539us     171.850ms         1.51%     171.850ms       7.179us         23938  \n                                             aten::item         7.02%     795.180ms         9.49%        1.074s      16.230us     792.716ms         6.95%        1.144s      17.284us         66189  \n                              aten::_local_scalar_dense         0.08%       9.482ms         2.46%     279.082ms       4.216us     351.296ms         3.08%     351.296ms       5.307us         66189  \nenumerate(DataLoader)#_SingleProcessDataLoaderIter._...        52.89%        5.991s        92.96%       10.528s     957.105ms        4.489s        39.34%       10.529s     957.139ms            11  \n                                         aten::randperm         0.05%       5.999ms         0.10%      11.327ms       5.663ms       4.764ms         0.04%      12.134ms       6.067ms             2  \n                                    aten::scalar_tensor         0.00%     374.000us         0.00%     374.000us     374.000us     794.000us         0.01%     794.000us     794.000us             1  \n                                          aten::resize_         0.01%     803.000us         0.01%     803.000us       5.538us       1.095ms         0.01%       1.095ms       7.552us           145  \n                                     aten::resolve_conj         0.00%     148.000us         0.00%     148.000us       0.019us      40.016ms         0.35%      40.016ms       5.167us          7745  \n                                      aten::resolve_neg         0.00%      46.000us         0.00%      46.000us       0.007us      32.543ms         0.29%      32.543ms       5.135us          6337  \n                                           aten::select         2.81%     318.758ms         2.88%     325.784ms      15.957us     318.857ms         2.79%     443.989ms      21.747us         20416  \n                                       aten::as_strided         0.33%      37.676ms         0.33%      37.676ms       0.444us     505.231ms         4.43%     505.231ms       5.950us         84909  \n                                           aten::detach         0.91%     102.774ms         1.10%     124.253ms      17.540us      88.614ms         0.78%     144.248ms      20.363us          7084  \n                                                 detach         0.19%      21.479ms         0.19%      21.479ms       3.032us      55.634ms         0.49%      55.634ms       7.853us          7084  \n                                               aten::to         1.76%     199.710ms         6.51%     737.611ms      25.256us     255.554ms         2.24%     809.348ms      27.713us         29205  \n                                       aten::lift_fresh         0.07%       7.586ms         0.07%       7.586ms       0.897us      58.884ms         0.52%      58.884ms       6.961us          8459  \n                                             aten::view         0.31%      34.666ms         0.31%      34.666ms       2.285us     122.098ms         1.07%     122.098ms       8.049us         15169  \n                                          aten::permute         0.92%     104.544ms         0.96%     109.220ms      17.238us     105.804ms         0.93%     144.617ms      22.825us          6336  \n                                         aten::_to_copy         3.74%     424.019ms         4.75%     537.901ms      36.330us     302.555ms         2.65%     553.794ms      37.403us         14806  \n                                    aten::empty_strided         0.37%      41.511ms         0.37%      41.511ms       2.795us     109.720ms         0.96%     109.720ms       7.389us         14850  \n                                            aten::copy_         0.71%      80.018ms         0.85%      96.394ms       4.266us     213.603ms         1.87%     213.603ms       9.454us         22594  \n                                              aten::div         1.22%     138.733ms         3.52%     399.037ms      56.593us     145.290ms         1.27%     439.793ms      62.373us          7051  \n                                         aten::uniform_         0.03%       2.947ms         0.03%       2.947ms       4.186us       7.612ms         0.07%       7.612ms      10.812us           704  \n                                          aten::detach_         0.29%      33.019ms         0.31%      35.081ms      16.524us      33.147ms         0.29%      48.687ms      22.933us          2123  \n                                                detach_         0.02%       2.062ms         0.02%       2.062ms       0.971us      15.540ms         0.14%      15.540ms       7.320us          2123  \n                                          aten::reshape         0.71%      80.357ms         0.75%      85.480ms      12.930us      75.472ms         0.66%     115.590ms      17.484us          6611  \n                                         aten::linspace         0.42%      47.546ms         0.48%      54.146ms      19.228us      47.290ms         0.41%      73.153ms      25.978us          2816  \n                                       aten::unsqueeze_         0.11%      11.937ms         0.12%      13.452ms      19.108us      12.553ms         0.11%      18.784ms      26.682us           704  \n                                      aten::as_strided_         0.03%       3.808ms         0.03%       3.808ms       1.803us      16.186ms         0.14%      16.186ms       7.664us          2112  \n                                            aten::fill_         0.04%       4.144ms         0.04%       4.379ms       3.035us      13.336ms         0.12%      13.336ms       9.242us          1443  \n                                        aten::transpose         0.13%      14.567ms         0.14%      15.786ms      20.213us      13.695ms         0.12%      19.948ms      25.542us           781  \n                                              aten::bmm         0.25%      28.172ms         0.25%      28.172ms      40.017us      25.482ms         0.22%      32.245ms      45.803us           704  \n                                        aten::unsqueeze         0.11%      11.947ms         0.11%      12.628ms      17.662us      11.825ms         0.10%      16.736ms      23.407us           715  \n                                             aten::ones         0.18%      20.921ms         0.21%      24.016ms      34.114us      16.416ms         0.14%      28.192ms      40.045us           704  \n                                              aten::cat         0.10%      11.403ms         0.10%      11.726ms      16.400us      16.104ms         0.14%      16.480ms      23.049us           715  \n                                     aten::grid_sampler         0.09%      10.604ms         0.26%      29.307ms      41.629us      10.173ms         0.09%      33.353ms      47.376us           704  \n                                  aten::grid_sampler_2d         0.16%      17.729ms         0.17%      18.703ms      26.567us      17.098ms         0.15%      23.180ms      32.926us           704  \n                                            aten::slice         6.86%     777.421ms         7.07%     800.166ms      15.152us     776.178ms         6.80%        1.085s      20.544us         52811  \n                                        aten::expand_as         0.16%      18.600ms         0.37%      42.052ms      29.866us      18.327ms         0.16%      49.855ms      35.408us          1408  \n                                           aten::expand         0.20%      22.754ms         0.21%      23.626ms      16.650us      22.087ms         0.19%      31.587ms      22.260us          1419  \n                                               aten::lt         0.15%      17.481ms         0.44%      49.920ms      70.909us      17.826ms         0.16%      54.088ms      76.830us           704  \n                                            aten::index         0.85%      96.468ms         1.71%     194.054ms     275.645us      64.770ms         0.57%     198.413ms     281.837us           704  \n                                          aten::nonzero         0.42%      47.688ms         0.45%      50.652ms      35.974us      39.725ms         0.35%      58.084ms      41.253us          1408  \n                                       aten::index_put_         0.10%      10.781ms         1.69%     191.193ms     271.581us      10.242ms         0.09%     194.826ms     276.741us           704  \n                                 aten::_index_put_impl_         0.79%      89.136ms         1.59%     180.412ms     256.267us      57.992ms         0.51%     184.584ms     262.193us           704  \n                                          aten::squeeze         0.10%      11.137ms         0.10%      11.198ms      15.906us      11.043ms         0.10%      14.912ms      21.182us           704  \n                                            aten::zeros         0.16%      18.313ms         0.22%      24.409ms      34.672us      14.051ms         0.12%      27.925ms      39.666us           704  \n                                            aten::zero_         0.04%       4.009ms         0.04%       4.178ms       5.843us       7.737ms         0.07%       7.774ms      10.873us           715  \n                                          aten::randint         5.50%     622.631ms         6.02%     681.773ms      28.483us     483.734ms         4.24%     807.424ms      33.733us         23936  \n                                              aten::add         0.45%      50.667ms         0.45%      50.667ms       3.998us     125.065ms         1.10%     125.065ms       9.869us         12672  \n                                             aten::add_         0.31%      35.361ms         0.33%      37.136ms       6.206us     137.550ms         1.21%     137.550ms      22.986us          5984  \n                                            aten::clamp         1.26%     142.593ms         1.26%     142.684ms      25.335us     148.167ms         1.30%     176.029ms      31.255us          5632  \n                                            aten::stack         0.01%     713.000us         0.06%       6.905ms     627.727us     416.000us         0.00%       6.963ms     633.000us            11  \n                                           aten::narrow         0.00%     170.000us         0.00%     323.000us      29.364us     166.000us         0.00%     376.000us      34.182us            11  \n                                        cudaMemcpyAsync         2.44%     276.731ms         2.44%     276.731ms       2.795ms       0.000us         0.00%       0.000us       0.000us            99  \n                                  cudaStreamSynchronize         0.00%     547.000us         0.00%     547.000us      16.576us       0.000us         0.00%       0.000us       0.000us            33  \n                      Optimizer.zero_grad#SGD.zero_grad         0.03%       3.054ms         0.03%       3.054ms     277.636us       3.280ms         0.03%       3.280ms     298.182us            11  \n                                           aten::conv2d         0.15%      16.735ms         1.34%     151.835ms     230.053us       4.626ms         0.04%     496.855ms     752.811us           660  \n                                       cudaLaunchKernel         0.66%      74.184ms         0.66%      74.184ms      18.724us       0.000us         0.00%       0.000us       0.000us          3962  \n                                      aten::convolution         0.05%       6.209ms         0.40%      45.500ms     137.879us       1.529ms         0.01%     238.963ms     724.130us           330  \n                                     aten::_convolution         0.11%      12.822ms         0.35%      39.291ms     119.064us       2.830ms         0.02%     237.434ms     719.497us           330  \n                                aten::cudnn_convolution         0.12%      13.942ms         0.14%      16.299ms      56.990us     118.777ms         1.04%     118.777ms     415.304us           286  \n                                  cudaStreamIsCapturing         0.00%      83.000us         0.00%      83.000us       0.089us       0.000us         0.00%       0.000us       0.000us           935  \n                                  cudaStreamGetPriority         0.00%      72.000us         0.00%      72.000us       0.077us       0.000us         0.00%       0.000us       0.000us           935  \n                       cudaDeviceGetStreamPriorityRange         0.00%      14.000us         0.00%      14.000us       0.015us       0.000us         0.00%       0.000us       0.000us           935  \n                                        cudaMemsetAsync         0.03%       3.175ms         0.03%       3.175ms      14.432us       0.000us         0.00%       0.000us       0.000us           220  \n                                       aten::batch_norm         0.01%     571.000us         0.08%       8.871ms     201.614us     214.000us         0.00%      19.803ms     450.068us            44  \n                           aten::_batch_norm_impl_index         0.01%     742.000us         0.07%       8.300ms     188.636us     238.000us         0.00%      19.589ms     445.205us            44  \n                                 aten::cudnn_batch_norm         0.04%       5.061ms         0.07%       7.558ms     171.773us      18.090ms         0.16%      19.351ms     439.795us            44  \n                                       aten::empty_like         0.01%     798.000us         0.01%       1.348ms      24.509us     323.000us         0.00%     565.000us      10.273us            55  \ncudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.01%     732.000us         0.01%     732.000us       1.358us       0.000us         0.00%       0.000us       0.000us           539  \n                                             aten::gelu         0.02%       1.751ms         0.02%       2.241ms      25.466us      20.572ms         0.18%      20.572ms     233.773us            88  \n                                            aten::clone         0.01%       1.307ms         0.02%       2.498ms      56.773us     301.000us         0.00%       6.086ms     138.318us            44  \n                                aten::_conv_depthwise2d         0.01%       1.638ms         0.02%       2.472ms      56.182us      47.881ms         0.42%      47.999ms       1.091ms            44  \n                                              aten::mul         0.02%       2.630ms         0.03%       3.603ms      23.396us      23.976ms         0.21%      23.976ms     155.688us           154  \n                                    cudaLaunchKernelExC         0.02%       2.343ms         0.02%       2.343ms      23.667us       0.000us         0.00%       0.000us       0.000us            99  \n                                          aten::flatten         0.00%     134.000us         0.00%     201.000us      18.273us      43.000us         0.00%      60.000us       5.455us            11  \n                                             aten::mean         0.00%     505.000us         0.01%     575.000us      52.273us     764.000us         0.01%     780.000us      70.909us            11  \n                                           aten::linear         0.01%     797.000us         0.04%       4.527ms     205.773us     170.000us         0.00%     986.000us      44.818us            22  \n                                                aten::t         0.03%       3.510ms         0.04%       4.212ms      76.582us     236.000us         0.00%     534.000us       9.709us            55  \n                                            aten::addmm         0.01%     615.000us         0.01%     737.000us      67.000us      73.000us         0.00%      73.000us       6.636us            11  \n                               aten::cross_entropy_loss         0.00%     346.000us         0.03%       2.981ms     271.000us     120.000us         0.00%     710.000us      64.545us            11  \n                                      aten::log_softmax         0.00%     432.000us         0.01%     805.000us      73.182us      71.000us         0.00%     132.000us      12.000us            11  \n                                     aten::_log_softmax         0.00%     289.000us         0.00%     373.000us      33.909us      46.000us         0.00%      46.000us       4.182us            11  \n                                      aten::nll_loss_nd         0.00%     182.000us         0.02%       1.830ms     166.364us      44.000us         0.00%     458.000us      41.636us            11  \n                                         aten::nll_loss         0.00%     439.000us         0.02%       2.305ms     104.773us     116.000us         0.00%     558.000us      25.364us            22  \n                                 aten::nll_loss_forward         0.00%     400.000us         0.00%     493.000us      44.818us      85.000us         0.00%     100.000us       9.091us            11  \n                                             aten::full         0.00%     354.000us         0.01%     661.000us      50.846us      92.000us         0.00%     173.000us      13.308us            13  \n                                        aten::ones_like         0.00%     296.000us         0.01%     718.000us      65.273us      76.000us         0.00%     172.000us      15.636us            11  \n      autograd::engine::evaluate_function: MulBackward0         0.06%       6.788ms         0.09%      10.418ms     189.418us     237.000us         0.00%      16.320ms     296.727us            55  \n                                           MulBackward0         0.01%       1.510ms         0.03%       3.630ms      66.000us     350.000us         0.00%      16.083ms     292.418us            55  \nautograd::engine::evaluate_function: NllLossBackward...         0.00%     260.000us         0.01%       1.198ms     108.909us      45.000us         0.00%     247.000us      22.455us            11  \n                                       NllLossBackward0         0.00%     177.000us         0.01%     938.000us      85.273us      46.000us         0.00%     202.000us      18.364us            11  \n                                aten::nll_loss_backward         0.00%     361.000us         0.01%     761.000us      69.182us      74.000us         0.00%     156.000us      14.182us            11  \nautograd::engine::evaluate_function: ToCopyBackward0...         0.11%      12.424ms         0.67%      75.347ms     112.291us       2.893ms         0.03%      18.241ms      27.185us           671  \n                                        ToCopyBackward0         0.10%      11.590ms         0.56%      62.923ms      93.775us       2.841ms         0.02%      15.348ms      22.873us           671  \nautograd::engine::evaluate_function: LogSoftmaxBackw...         0.00%     197.000us         0.01%     661.000us      60.091us      45.000us         0.00%     133.000us      12.091us            11  \n                                    LogSoftmaxBackward0         0.00%     209.000us         0.00%     464.000us      42.182us      44.000us         0.00%      88.000us       8.000us            11  \n                       aten::_log_softmax_backward_data         0.00%     185.000us         0.00%     255.000us      23.182us      44.000us         0.00%      44.000us       4.000us            11  \n    autograd::engine::evaluate_function: AddmmBackward0         0.01%     614.000us         0.05%       6.207ms     564.273us     103.000us         0.00%     863.000us      78.455us            11  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 11.325s\nSelf CUDA time total: 11.411s\n\n","output_type":"stream"}]},{"cell_type":"code","source":"################## ARCHIVE CODE ##########################\n'''\ndef evaluate_significance(model_1, model_2, test_loader):\n    accuracy_m1 = {}\n    accuracy_m2 = {}\n    # For model_1\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model_1.to(device)\n    model_2.to(device)\n    with torch.no_grad():\n        for i, (data, target) in enumerate(test_loader):\n            data, target = data.to(device), target.to(device)\n            output_1 = model_1(data)\n            output_2 = model_2(data)\n            _, predicted_1 = torch.max(output_1.data, 1)\n            _, predicted_2 = torch.max(output_2.data, 1)\n            total = target.size(0)\n            correct_1 = (predicted_1 == target).sum().item()\n            correct_2 = (predicted_2 == target).sum().item()\n            test_accuracy_1 = correct_1 / total\n            test_accuracy_2 = correct_2 / total\n            accuracy_m1[i] = test_accuracy_1\n            accuracy_m2[i] = test_accuracy_2\n    return accuracy_m1, accuracy_m2\n\nimport numpy as np\nmean_m1 = np.mean(list(acc_m1.values())).round(4)\nmean_m2 = np.mean(list(acc_m2.values())).round(4)\nmean_m1, mean_m2\n\nstd_m1 = np.std(list(acc_m1.values())).round(4)\nstd_m2 = np.std(list(acc_m2.values())).round(4)\nstd_m1, std_m2\n\nimport scipy\nscipy.stats.ttest_rel(list(acc_m1.values()), list(acc_m2.values()))\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#############################\n### Create Baseline Model ###\n#############################\n\nclass BaselineCNN(nn.Module):\n  def __init__(self,):\n    super().__init__()\n    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n    self.relu1 = nn.ReLU()\n    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n    self.relu2 = nn.ReLU()\n    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    self.flatten = nn.Flatten()\n    self.fc1 = nn.Linear(64 * 25 * 25, 128) # TODO: Make input size dynamic\n\n    self.relu3 = nn.ReLU()\n    self.fc2 = nn.Linear(128, 10)\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.relu1(x)\n    x = self.pool1(x)\n\n    x = self.conv2(x)\n    x = self.relu2(x)\n    x = self.pool2(x)\n\n    x = self.flatten(x)\n    x = self.fc1(x)\n    x = self.relu3(x)\n    x = self.fc2(x)\n    return x\n    '''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nFURTHER ATTENTION BLOCKS\n------------------------------------\nclass LSKA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    \n    # When groups == in_channels and out_channels == K * in_channels,\n    # where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    self.conv1_1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=(1, kernel_size), groups=in_channels)#DWConv\n    self.conv1_2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels*k, kernel_size=(kernel_size, 1), groups=in_channels)#DWConv\n    self.conv2_1 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=(1, kernel_size),\n                             dilation=dilation, groups=in_channels, padding=4)#DWDilationConv\n    self.conv2_2 = nn.Conv2d(in_channels=in_channels*k, out_channels=in_channels*k, kernel_size=(kernel_size, 1),\n                             dilation=dilation, groups=in_channels, padding=4)#DWDilationConv\n    self.conv3 = nn.Conv2d(in_channels=in_channels*k, out_channels=out_channels, kernel_size=1)\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1_1(x)\n    attn = self.conv1_2(attn)\n    attn = self.conv2_1(attn)\n    attn = self.conv2_2(attn)\n    attn = self.conv3(attn)\n    print(attn.shape)\n    return input * attn\n-----------------------------------\nclass KA(nn.Module):\n  def __init__(self, in_channels, out_channels, kernel_size=5, dilation=3, k=1):\n    super().__init__()\n    # When groups == in_channels and out_channels == K * in_channels,\n    # where K is a positive integer, this operation is also known as a “depthwise convolution”.\n    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=13, padding='same')\n\n\n  def forward(self, x):\n    input = x.clone()\n    attn = self.conv1(x)\n\n    return input * attn\n    \n'''","metadata":{},"execution_count":null,"outputs":[]}]}